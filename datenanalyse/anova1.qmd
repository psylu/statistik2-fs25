# Einfaktorielle Varianzanalyse ohne Messwiederholung {#sec-anova1-ind}

```{r}
#| include: false
# Set working directory of R
knitr::opts_knit$set(root.dir = '../')
```

## Anwendungsbereich

Mit der einfaktoriellen Varianzanalyse (ohne Messwiederholung) wird untersucht, ob sich mehrere unabhängige Gruppen unterscheiden bzw. ob die Gruppenvariable (UV) einen "Einfluss" oder "Effekt" auf die abhänigige metrische Variable (AV) hat. 
Dabei ist wichtig, dass mit "Effekt" kein kausaler Zusammenhang gemeint ist. 
Die einfaktorielle Varianzanalyse ohne Messwiederholung stellt eine Erweiterung des _t_-Tests für unabhängige Stichproben bei mehr als zwei Stichproben dar. 

Dies bedeutet, dass die _abhängige Variable_ (AV) als Merkmal mit der Varianzanalyse untersucht wird. Die _unabhängige Variable_ (UV) ist die erklärende Variable - auch _Faktor_ genannt. Eine Varianzanalyse, die den Einfluss _einer_ unabhängigen Variable (ein Faktor) untersucht, wird als _einfaktorielle_ Varianzanalyse bezeichnet. Ein Faktor kann zwei oder mehr Stufen haben. Dabei muss die unabhängige Variable metrisch und der Faktor kategorial sein. 

Sind in jeder Gruppe gleich viele Personen bzw. Datenpunkte, spricht man von einem _balancierten Design_. Bei ungleichgrossen Gruppen handelt es sich um ein _unablanciertes Design_.

Die Varianzanalyse wird häufig auch ANOVA gennannt (engl. ANalysis Of VAriance, kurz ANOVA).


__Die einfaktorielle Varianzanalyse überprüft somit die Auswirkung einer gestuften, unabhängigen Variable (= Faktor) auf eine abhängige Variable.__


__Typische Fragestellungen__:

- *Unterscheiden sich die Symptome auf einer Angstskala von Patient:innen in verschiedenen Therapierichtung (Kognitive Verhaltenstherapie, Psychoanalyse, Systemische Therapie?*

- *Unterscheiden sich Studierende in ihrer Konzentrationsfähigkeit Y, wenn sie 4, 6, 8 oder 10 Stunden geschlafen haben?*

- *Hat die verwendetet Lerntechnik (keine Technik, Wiederholen, Mnemotechnik) einen Einfluss auf die Anzahl richtig gelöster Prüfungsaufgaben?*


## Voraussetzungen

TODO/Check Eid

| Voraussetzung | Beschreibung | Vorgehen bei Verletzung |
|---|---|---|
| Abhängige Variable | Eine abhängige Variable mit metrischem Skalenniveau. Die AV muss in den den Teilpopulationen stetig und normalverteilt sein (bei genügend grosser Stichprobe ist der _F_-Test robust). | Transformieren der Variable oder Verwenden von non-parametrischen Verfahren: Falls die AV ordinalskaliert ist, kann ein non-parametrisches (verteilungsfreies) Verfahren gewählt werden; z.B. Kruskal-Wallis-Test. |
| Unabhängige Variable | Eine unabhängige Variable mit zwei oder mehr Stufen (kategoriale Gruppenvariable). | Verwenden eines anderen statistischen Verfahrens (z.B. Regression) oder Kategorisierung der UV. |
| Unabhängigkeit der Messwerte | Die Messwerte _innerhalb_ der beiden Stichproben sind voneinander unabhängig. Es handelt sich um einfache, innerhalb der Stichprobe voneinander unabhängigen, Zufallsstichproben. |  |
| Unabhängigkeit der Gruppen/Stichproben | Die Messwerte _zwischen_ den Stichproben sind voneinander unabhängig (unabhängige Gruppen). Eine _Verletzung der Unabhängigkeitsannahme_ liegt vor, wenn die Annahme, dass die Messwerte zwischen den Stichproben unabhängig sind, nicht zutrifft, d.h. die Messwerte mit Messwiederholung vorliegen. | Für die Abhängigkeit der Gruppen kann kontrolliert werden, indem z.B. ein Varianzanalyse für abhängige Stichproben verwendet wird |
| Varianzhomogenität / Homoskedastizität | Die Varianzen innerhalb??? der Teilpopulationen sind _homogen_ (Homoskedastizität). Vor allem wenn die Stichproben unterschiedlich gross sind, bietet sich eine empirische Überprüfung der Varianzhomogenitätsannahme an.  | _Überprüfung der Varianzhomogenitätsannahme_: <br> Der Vergleich  Stichprobenvarianzen mittels _F_-Test oder Levene-Test (robuste Variante zum _F_-Test). <br> Bei _Verletzung der Varianzhomogenitätsannahme (Heteroskedastizität)_, kann als Alternative auf robuste Verfahren zurückgegriffen werden oder der Welch-Test/Brown-Forsythe-Test verwendet werden, welcher nicht die gepoolten Innerhalb-Varianzen, sondern die jeweiligen Stichprobenvarianzen $\hat \sigma^2_1$ und $\hat \sigma^2_2$ verwendet. Bei Aussreissern robuste Verfahren|

: __Voraussetzungen einfaktorielle Varianzanalyse ohne Messwiederholung__, Überprüfung und mögliche Alternativen bei Verletzung der Annahmen {.hover}


Unabhängigkeit der Residuen, Homoskedastizität und Normalverteilung.

- Die Unabhängigkeit der Residuen bedeutet, dass die Residualwerte innerhalb einer Bedingung voneinander unabhängig sind, aber auch die Residualwerte zwischen den Bedingungen. 

<br>

<aside> Auf alternative statistische Verfahren bei Verletzung der Annahmen (z.B. Transformationen oder non-parametrische Verfahren) wird in diesem Semester nicht eingegangen. </aside>
                                                                                          

## Grundkonzepte und Vorgehen

![Allgemeiner Workflow der Datenanalyse](../imgs/flowchart_analysis.png)

### Planung

#### __1. Statistische Hypothesen und Signifikanzniveau festlegen__

__Ungerichtete Hypothesen:__

Mit der einfaktoriellen Varianzanalyse wird die Nullhypothese, dass die Mittelwerte in der Population für jede Gruppen gleich sind, überprüft. 

$H_0$: Die Populationsmittelwerte der Gruppen 1, 2 und 3 unterscheiden sich nicht (d.h. haben eine Differenz gleich 0): $\mu_1= \mu_2= \mu_3$ bzw. $\mu_i= \mu_j$ für alle Paare ($i$, $j$), $i \neq j$

$H_1$: Mindestens zwei Populationsmittelwerte der Gruppen 1, 2 und 3 unterscheiden sich (d.h. haben eine Differenz ungleich 0): $\mu_i \neq\mu_j$ für mindestens ein Paar ($i$,$j$), $i \neq j$ 

__HIER ALLE MÖGLICHKEITEN AUSFORMULIEREN?__

also beispielsweise:

- $\mu_1 \neq \mu_2 = \mu_3$
- $\mu_1 = \mu_2 \neq \mu_3$
- $\mu_1 \neq \mu_2 \neq \mu_3$


__EVTL TTEST HINZUFUEGEN?__

Bei $J = 2$ Faktorstufen ist der _F_-Test äquivalent zu einem _t_-Test für unabhängige Stichproben.
  
Bei $J>2$ Faktorstufen ist der _F_-Test ein Omnibus-Test, mit dem lediglich ermittelt werden kann, ob die Unterschiede zwischen den Bedingungsmittelwerten signifikant von 0 abweichen, daher werden auch die Hypothesen entsprechend formuliert. 
Häufig ist man jedoch daran interessiert, ob sich bestimmte Mittelwertspaare signifikant unterscheiden. Eine Möglichkeit dazu bieten Paarvergleiche, sogenannte Post-hoc-Tests. Bei drei Bedingungen gibt es drei (nicht-redundante) Paarvergleiche: $\mu_1-\mu_2$, $\mu_1-\mu_3$ und $\mu_2-\mu_3$.

<!-- ### Post-hoc Tests (ANOVA) 

Auf welche Strategie sollte man zurückgreifen?

Der Einsatz des Tukey- und des Dunnett-Tests ist klar, da vorher festliegt, dass man entweder alle möglichen Mittel- wertspaare vergleichen will (Tukey-Test) oder gezielt J – 1 Paarvergleiche (Dunnett-Test) vornehmen will.

Hat man a priori keine gezielten Hypothesen, sollte man die Mittelwertsvergleiche aufgrund der höheren Power anhand des Tukey-Tests vornehmen.

Kontrastanalyse und Paarvergleiche

__Gerichtete Hypothesen:__

-->

__Signifikanzniveau:__

Wird ein Signifikanzniveau von $\alpha = 0.05$ festgelegt, bedeutet dies, dass bei der Verwerfung der Nullhypothese eine 5% Wahrscheinlichkeit besteht, dass eigentlich kein Unterschied besteht und irrtümlicherweise einer angenommen wurde.

#### __2. A-priori Poweranalyse durchführen__

Mit einer a-priori Poweranalyse kann im Vornherein die Planung des optimalen Stichprobenumfangs vorgenommen werden. Dies wird hier im Rahmen dieser Veranstaltung nicht weiter vertieft.

Für experimentellen Studien ist es jedoch sinnvoll gleich grosse Bedingungsstichproben zu wählen, da die Varianzanalyse unter dieser Bedingung robuster gegen Verletzungen ihrer Annahmen ist.

### Vorverarbeitung

#### __3. Daten einlesen, vorverarbeiten und visualisieren__

Zuerst müssen die Daten eingelesen und bereinigt werden. 
Daten können diagnostisch visualisiert werden, um z.B. fehlende Werte zu entdecken oder Verteilungen der Daten visuell beurteilen und Extremwerte zu identifizieren.

Für die einfaktorielle Varianzanalyse bzw. den _F_-Test mit dem Package {afex} werden die Daten  in einem `long`-Format benötigt. 

#### __4. Voraussetzungen überprüfen__

- __Varianzhomogenität__

Der _F_-Test für unabhängige Stichproben setzt Varianzhomogenität voraus. Dies kann in _R_ mit dem Levene-Test `car::leveneTest` überprüft werden.  

Der Levene-Test geht von der Nullhypothese aus, dass sich die beiden Varianzen nicht unterscheiden. Ein nicht signifikantes Ergebnis bedeutet daher, dass sich die Varianzen nicht unterscheiden und somit Varianzhomogenität (sogenannte Heteroskedastizität) besteht. Wenn der Test signifikant ist, wird Varianzheterogenität angenommen.

Falls die Varianzen heterogen (unterschiedlich) sind , müssen die Freiheitsgrade des _F_-Wertes entsprechend angepasst werden. In diesem Fall kann ein Welch-Test/Brown-Forsythe-Test verwendet werden, der zur Berechnung der Teststatistik die beiden unterschiedlichen Populationsvarianzen anstatt die gepoolte Innerhalbvarianz nimmt.  


### Analyse

#### __5. Deskriptivstatistik und Visualisierung__

Bei Gruppenunterschieden wird für jede Gruppe ein Lagemass (z.B. Mittelwert oder Median) sowie ein Streumass (z.B. Standardabweichung, Standardfehler, Konfidenzintervall) berechnet. Das Lagemass stellt die durchschnittliche Merkmalsausprägung pro Bedingung dar. Das Streumass zeigt den Streubereich der Daten pro Bedingung auf.

<aside> Genauere Informationen zu Lage- und Streumassen sind im [Kapitel: Deskriptive Statistik](descriptive.qmd) zu finden. </aside>

Zur Visualisierung von Unterschieden eignen sich Lagemasse mit Fehlerbalken. Boxplots eignen sich beispielsweise gut, um Grösse der Unterschiede (Effekte) und die Kohärenz der Datenpunkte (Ähnlichkeit der Werte innerhalb einer Bedingung/Gruppe) zu beurteilen.

Durch die Visualisierung der Rohwerte, kann die Verteilung der Messungen gut eingeschätzt werden und Extremwerte werden deutlich sichtbar. Bei zu vielen Datenpunkten führt das Visualisieren der Rohwerte zu unübersichtlichen Grafiken.

#### __6. Teststatistik berechnen__

Um zu überprüfen, ob mindestens zwei Mittelwerte signifikant unterschiedlich sind, muss die Teststatistik berechnet werden. 

__Notation__

$n$: Stichprobengrösse insgesamt

$J$: Anzahl Faktorstufen (Gruppen oder Bedingungen)

__ $m$ müsste hier auch erklärt werden__

__Quadratsummenzerlegung__ 

$QS_{tot}=QS_{zw}+QS_{inn}$ mit

- Totale Quadratsumme (Prädiktionsfehler __ohne__ Berücksichtigung der UV): $QS_{tot}=\sum^J_{j=1} \sum^{n_j}_{m=1} (x_{mj}- \overline{x})^2$

- Fehlerquadratsumme (Prädiktionsfehler __mit__ Berücksichtigung der UV): $QS_{inn}=\sum^J_{j=1} \sum^{n_j}_{m=1} (x_{mj}- \overline{x}_j)^2$
      
- Treatmentquadratsumme (Reduktion des Prädiktionsfehlers __durch__ die Berücksichtigung der UV: $QS_{zw}=\sum^J_{j=1} \sum^{n_j}_{m=1} (\overline{x}_j- \overline{x})^2=\sum^J_{j=1} n_j\cdot (\overline{x}_j- \overline{x})^2$


__Mittlere Quadratesummen und ihre Freiheitsgrade__ 

$MQS_{tot}=\frac{QS_{tot}}{n-1}$

$MQS_{zw}=\frac{QS_{zw}}{J-1}$

$MQS_{inn}=\frac{QS_{inn}}{n-J}$


__*F*_-Test__

Um die Nullhypothese zu prüfen, verwenden wir den _F_-Test als Prüfgrösse. Der _F_-Wert ist immer $> 0$, da die quadrierten Abweichungen in die Berechnung einfliessen. Die ungerichtete $H_1$ wird somit einseitig getestet.

$F=\frac{MQS_{zw}}{MQS_{inn}}$

- Die $H_0$ wird beibehalten, wenn die empirische Prüfgrösse _F_ __kleiner__ als der kritische Wert ist. Die Gruppen unterscheiden sich nicht signifikant bzw. es konnte kein Einfluss der Gruppenvariablen auf die AV gefunden werden. 

- Die $H_0$ wird abgelehnt, wenn die empirische Prüfgrösse _F_ __grösser__ als der kritische Wert ist. Die Gruppen unterscheiden sich signifikant bzw. es konnte ein Einfluss der Gruppenvariablen auf die AV gefunden werden. 

Ein _F_-Test mit zwei Stufen und ein zweiseitiger _t_-Test sind äquivalent. Es gilt $t^2=F$.


#### __7. Effektstärke bestimmen__

Die Effektgrösse beim _F_-Test sagt etwas darüber aus, wie gross der Unterschied zwischen den beiden Populationsmittelwerten ist.

ADD: Es gibt verschiedene Masse!

Die standardisierte Effektgrösse für eine einfaktorielle Varianzanalyse ohne Messwiederholung $\eta^2$ lässt sich anhand des Quotienten aus der Zwischen-Quadratsumme und der Gesamtquadratsumme berechnen:

$\hat \eta^2=\frac{QS_{tot}-QS_{inn}}{QS_{tot}}=\frac{QS_{zw}}{QS_{tot}}=\frac{F \cdot {df}_{zw}}{F \cdot df_{zw} + df_{inn}}$

Die Konventionen für $\eta^2$ lauten in Anlehnung an Cohen (1988):

- $\eta^2=\approx 0.01$: kleiner Effekt

- $\eta^2=\approx 0.06$: mittlerer Effekt

- $\eta^2=\approx 0.14$: grosser Effekt

In R kann hierfür die Funktion `eta_squared` aus dem Package {effectsize} verwendet werden. 

Die Effektgrösse $\eta^2$ lässt sich anhand des Quotienten aus der Zwischen-Quadratsumme und der Gesamtquadratsumme berechnen. In R kann dieses Mass mit der Funktion `eta_squared` aus dem Package {effectsize} berechnet werden. 

### Schlussfolgerungen

#### __8. Ergebnisse interpretieren und berichten__

Die Ergebnisse der Varianzanalyse werden in der Regel mit dem empirischen __FEHLT ETWAS?__

Inferenzstatistische Kennwerte (z.B. _t_ und _F_) werden mit zwei Dezimalen berichtet.^[[https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf)] In den Klammern werden die Freiheitsgrade des Zählers und des Nenners angegeben. Als Effektgrössenschätzer wird meistens $\eta^2$ angegeben. 

> Die einfaktorielle Varianzanalyse ergab, dass sich die Gruppen  signifikant in ihrer kognitiven Leistung unterscheiden, _F_(2, 12) = 10.87, _p_ = .002, $\eta^2$ = 0.64.

> One-way ANOVA revealed a significant effect of condition on performance, _F_(2, 12) = 10.87, _p_ = .002, $\eta^2$ = 0.64.

## Anwendungsbeispiel in R

::: {.callout-note appearance="default" title="Beispiel: Therapiemethoden bei Angstsymptomatik" icon=false}
In einem fiktiven Experiment wurden drei verschiedene Therapiemethoden verglichen und untersucht, welchen Effekt die Therapiemethode auf die Angstsymptomatik hat. Die 15 Personen wurden zufällig den drei Bedingungen zugewiesen.

- Die _unabhängige Variable_ sind die Therapiemethoden mit 3 Stufen (Mindfulness, Entspannung, Kognitive Umstrukturierung)
- Die _abhängige Variable_ sind die Höhe der Angstsymptomatik nach dem Treatment (metrisch). 

:::


### Planung

#### __1. Statistische Hypothesen und Signifikanzniveau festlegen__

$H_0$: Die Therapiemethode hat keinen Einfluss auf die Symptome: $\mu_1=\mu_2=\mu_3$ 

$H_1$: Die Therapiemethode hat einen Einfluss auf die Symptome: $\mu_i \neq\mu_j$ für mindestens ein Paar ($i$,$j$), $i \neq j$ 

Das Alphaniveau wird auf $5 \%$ festgelegt. Es handelt sich um eine ungerichtete Hypothese, die Testung erfolgt mit dem _F_-test jedoch einseitig.

#### __2. A-priori Poweranalyse durchführen__


### Vorverarbeitung

#### __3. Daten einlesen und vorverarbeiten__

::: {.callout-caution appearance="default" title="Hands-on: Beispieldatensatz Therapiemethode" collapse=true}

__Daten herunterladen und einlesen__

[Hier](../data/anova.zip) kann der Projektordner mit den Daten heruntergeladen werden. Vor dem ersten Verwenden muss der Ordner entzippt werden, dann kann das _RProject_ namens `anova.Rproj` geöffnet werden. Der Ordner enthält

- _RProject_ namens `anova.Rproj`

- Datensatz `anova_therapy.csv` und `anova_music.csv` in `data`-Ordner

- _RNotebook_ namens `einfaktorielleanova.Rmd`

- Es werden folgende Packages verwendet:  {tidyverse}, {afex}, {emmeans}, {beeswarm??}, {effectsize??}

- Datensatz einlesen: 

```{r, message=FALSE}
# Package laden
library(tidyverse)

# Daten laden und anschauen
d_therapy3 <- read.csv("data/anova_therapy.csv") |>
    glimpse() 

```

__Datensatz transformieren__

Die Daten sind bereits im `long` Format. Die Variablen `id` und `condition` müssen zu einem Faktor konvertiert werden.

```{r}
# Faktoren definieren 
d_therapy3 <- d_therapy3 |>
  mutate(id = as.factor(id)) |>
  mutate(condition = as.factor(condition)) |>
  glimpse()
  
```

:::

#### __4. Voraussetzungen überprüfen__

Der _F_-Test für eine einfaktorielle Varianzanalyse setzt voraus, dass die AV in der Population stetig und normalverteilt ist und die Populationsvarianzen homogen sind.

<aside>Die Voraussetzung der Normalverteilung wird in diesem Semester nicht überprüft. </aside>

Die Varianzhomogenität (Homoskedastizität) kann mit dem Levene-Test `leveneTest(y ~ x, data = dataset)` überprüft werden. Ein Levene-Test mit $p < 0.05$ bedeutet, dass der Varianzunterschied  signifikant ist. Die Nullhypothese, dass die beiden Varianzen auf Populationsebene identisch sind, muss in diesem Fall verworfen werden.

```{r, message=FALSE}
# Levene-Test mit dem package {car}
car::leveneTest(symptoms ~ condition, # av ~ uv
                data = d_therapy3) # Datensatz
```

Der Test ist hier nicht signifikant ($p = .779$), daher wird davon ausgegangen, dass die Varianzen in den Gruppen homogen sind und die Voraussetzung der Varianzhomogenität erfüllt ist.   


### Analyse

#### __5. Deskriptivstatistik und Visualisierungn__

Für die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden. 

```{r}
# Nach condition gruppieren und symptoms zusammenfassen
d_summary <- d_therapy3 |>
  group_by(condition) |> # Gruppieren
  summarise(mean_symptoms = mean(symptoms), # Mittelwert
            sd_symptoms = sd(symptoms)) # Standardabweichung
d_summary
```


```{r}
#| echo: false

# Plot 
ggplot(d_therapy3, aes(x = condition, y = symptoms, colour = condition)) +
  geom_jitter(size = 2, width = 0, height = 0.2) +  
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 2)) +  
  labs(title = "symptomes per condition", y = "symptoms", x = "condition") +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

```


#### __6. Teststatistik berechnen__

__a. Berechnung Teststatistik von Hand__ 

Im Folgenden wird ein _F_-Test unter der Annahme von homogenen Varianzen "von Hand" berechnet. 

```{r}

#qf(0.95, 2, 12)

#oder auch nicht... :)

```

Falls der empirische _F_-Wert grösser als der kritische _F_-Wert ist, wird von einem signifikanten Unterschied zwischen den Gruppen ausgegangen.


__b. Berechnung Teststatistik in R mit der Funktion `aov_4()`__

Eine einfaktorielle Varianzanalyse kann mit der Funktion `aov_4(av ~ uv, + (1 | id), data)` aus dem Package {afex} berechnet werden.

<aside> Beim ersten Verwenden muss das Package {afex} heruntergeladen/installiert werden, z.B. in der Konsole mit `install.packages("afex")`. </aside>

- `av`: Abhängige Variable (metrisch)
- `uv`: Unabhängige Variable (Bedingung oder Gruppenvariable)
- `(1 | id)`: Die Funktion benötigt eine Identifikationsvariable, d.h. eine Variable in der jede Person einen einzigartige Wert hat. Da wir hier keine Messwiederholung haben, wird hier `1` verwendet. Bei Messwiederholung wird hier spezifiziert, welche Variable sich innerhalb von `id` wiederholt. 

```{r, message=FALSE, warning=FALSE}
library(afex)

# Einfaktorielle Anova ohne Messwiederholung berechnen
m_anova1 <- aov_4(symptoms ~ condition + (1 | id), # av ~ uv + (1 | Identifikationsvariable)
                data = d_therapy3) # dataset

summary(m_anova1) 
m_anova1$Anova
```

Die Mittelwerte der Bedingungen unterscheiden sich signifikant auf dem $5 \%$-Niveau. Die Nullhypothese, wonach sich die Mittelwerte nicht unterscheiden, kann verworfen werden. Die Therapiemethode hat somit einen Einfluss auf die Angstsymptomatik. Aufgrund dieser Analyse ist hingegen (noch) nicht klar, welche Bedingungen sich unterscheiden. Dies wird in einem weiteren Schritt mit sogenannten Post-hoc-Vergleichen überprüft. 


```{r}
# Plot
plot_anova <- afex_plot(object = m_anova1, # Objekt mit Anovamodell
          x = "condition",  # uv (Faktor)
          error_ci = FALSE) + # Anzeigen von Standardfehler der Mittelwerte
          theme_minimal()
plot_anova
```

__c. Post-hoc-Vergleiche__

(folgt)

__d. Kontrastanalyse__

(folgt)

#### __7. Effektstärke bestimmen__

__Berechnung der Effektgrösse $\eta^2$__

Die Effektgrösse $\eta^2$ lässt sich anhand des Quotienten aus der Zwischen-Quadratsumme und der Gesamtquadratsumme berechnen. In R kann dieses Mass direkt mit der Funktion `eta_squared` aus dem Package {effectsize} berechnet werden. 

```{r}
# Effektgrösse berechnen
effectsize::eta_squared(m_anova1)
```

Die Effektgrösse liegt bei $\eta^2=0.62$. Es handelt sich nach der Taxonomie von Cohen (1988) um einen __grossen__ Effekt.


### Schlussfolgerungen

#### __8. Ergebnisse interpretieren und berichten__

__a. Ergebnisse der einfaktoriellen Varianzanalyse ohne Messwiederholung__

Das Ergebnis ist auf dem $5 \%$-Niveau signifikant und die Nullhypothese kann somit verworfen werden: Die Therapiemethode beeinflusst die Höhe der Angstsymptomatik. Es handelt sich nach der Taxonomie von Cohen (1988) um einen grossen (oder auch sehr grossen) Effekt ($\eta^2=0.62$). 

>"We examined whether the three therapy methods had an __different???__ effect on anxiety symptoms. The one-way ANOVA revealed a significant effect of the therapy condition on anxiety symtoms, _F_(2, 12) = 10.00, _p_ = .003, $\eta^2$ = 0.62). This indicates a large effect of the therapy condition on anxiety symptoms according to Cohen’s convention (1988)."

__b. Ergebnisse der Post-hoc und Kontrastanalyse__

