# *t*-Test für unabhängige Stichproben {#sec-t-test-ind}

```{r}
#| include: false
# Set working directory of R
knitr::opts_knit$set(root.dir = '../')
```

## Anwendungsbereich

Mit _t_-Tests für unabhängige Stichproben wird untersucht, wie sich zwei voneinander unabhängige Gruppen in einem intervallskalierten Mass unterscheiden, wenn die Populationsvarianz unbekannt ist.  

__Typische Fragestellungen__:

- *Wie unterscheiden sich Personen mit der Diagnose von Personen ohne Diagnose X in der Fähigkeit Y?*

- *Wie unterscheiden sich Personen mit einer hohen Ausprägung eines Persönlichkeitsmerkmals von Personen mit einer tiefen Ausprägung in Fähigkeit Y?*

- *Wie unterscheiden sich ältere Personen von jüngeren Personen in der Einschätzung von Y (z.B. Lebenszufriedenheit)?*

- *Wie unterscheiden sich Personen, die ein Treatment erhalten haben, von Personen, welche dieses Treatment nicht erhalten haben (Kontrollgruppe) in der Symptomausprägung Y?*


__Beispiele__:

- [Martin & Kerns (2011)](https://pmc.ncbi.nlm.nih.gov/articles/PMC3051364/)
  - Fragestellung: Welchen Einfluss hat eine positive Stimmung auf die kognitive Leistung gemessen im Stroop Task oder im Running Span Task?
  - Typische Aussage: The results revealed that the positive mood group performed significantly worse on the running span task, $t(174) = 2.14, p < .05$, but there were no differences between the groups on the Stroop task, $t(173) = 0.54, p = .590$.


## Voraussetzungen

| Voraussetzung | Beschreibung | Vorgehen bei Verletzung |
|---|---|---|
| Abhängige Variable | Eine abhängige Variable mit metrischem Skalenniveau. Die AV muss in den beiden Teilpopulationen stetig und normalverteilt sein (bei genügend grosser Stichprobe ist der _t_-Test robust). | Transformieren der Variable oder Verwenden von non-parametrischen Verfahren: Falls die AV ordinalskaliert ist, kann ein non-parametrisches (verteilungsfreies) Verfahren gewählt werden; z.B. Vergleich von zwei unabhängigen Stichproben mit dem Wilcoxon-Vorzeichen-Rangtest bzw. _U_-Test von Mann-Whitney. |
| Unabhängige Variable | Eine unabhängige Variable mit zwei Stufen (dichotome Gruppenvariable). | Verwenden eines anderen statistischen Verfahrens (z.B. Regression) oder Dichotomisierung der UV mittels Mediansplit (z.B. Alter von Zahl zu "jung" und "alt"). |
| Unabhängigkeit der Messwerte | Die Messwerte _innerhalb_ der beiden Stichproben sind voneinander unabhängig. Es handelt sich um einfache, innerhalb der Stichprobe voneinander unabhängigen, Zufallsstichproben. |  |
| Unabhängigkeit der Gruppen/Stichproben | Die Messwerte _zwischen_ den beiden Stichproben sind voneinander unabhängig (unabhängige Gruppen). Eine _Verletzung der Unabhängigkeitsannahme_ liegt vor, wenn die Annahme, dass die Messwerte zwischen den beiden Stichproben unabhängig nicht zutrifft, d.h. die Messwerte in natürlichen Paaren (z.B. Geschwister, Messwiederholung) vorliegen. | Für die Abhängigkeit der Gruppen kann kontrolliert werden, indem z.B. ein _t_-Test für abhängige Stichproben verwendet wird (siehe [Kapitel: t-Test für abhängige Stichproben](ttest_abhaengig.qmd)) |
| Varianzhomogenität / Homoskedastizität | Die Varianzen innerhalb der beiden Teilpopulationen sind _homogen_ (Homoskedastizität). Vor allem wenn die Stichproben unterschiedlich gross sind, bietet sich eine empirische Überprüfung der Varianzhomogenitätsannahme an.  | _Überprüfung der Varianzhomogenitätsannahme_: <br> Der Vergleich von zwei Stichprobenvarianzen mittels _F_-Test oder Levene-Test (robuste Variante zum _F_-Test). <br> Bei _Verletzung der Varianzhomogenitätsannahme (Heteroskedastizität)_, kann als Alternative der Welch-Test verwendet werden, welcher nicht die gepoolten Innerhalb-Varianzen, sondern die beiden unterschiedlichen Stichprobenvarianzen $\hat \sigma^2_1$ und $\hat \sigma^2_2$ verwendet. |

: __Voraussetzungen _t_-Test für unabhängige Stichproben__, Überprüfung und mögliche Alternativen bei Verletzung der Annahmen {.hover}


<br>

<aside> Auf alternative statistische Verfahren bei Verletzung der Annahmen (z.B. Transformationen oder non-parametrische Verfahren) wird in diesem Semester nicht eingegangen. </aside>


<!-- BORTZ: Die Varianzen σ1 und σ2 der zu vergleichen- den Populationen sind gleich. Ist dies der Fall, so darf man für die Stichprobenvarianzen erwarten, dass s21 ≈ s2. Verfahren zur Überprü-
- BORTZ: Das untersuchte Merkmal muss in beiden Po- pulationen, denen die Stichproben entnommen wurden, normalverteilt sein. Sind die Verteilungsformen der Grundgesamtheiten unbekannt, kann die Normalverteilungsannahme mit einem Verfahren überprüft werden, das in Abschnitt 9.2 besprochen wird.
- ... -> non-parametrische Tests (Eid...)
BORTZ: Alle drei besprochenen t-Tests lassen sich unabhängig vom Stichprobenumfang anwenden, wenn die gemachten Annahmen erfüllt sind. Mit ande- ren Worten, selbst bei kleinen Stichprobenumfängen gewährleisten die Tests, dass das festgelegte Signifikanzniveau eingehalten wird. Natürlich sind trotzdem grosse Stichprobenumfänge wünschenswert, da dadurch die Teststärke entsprechend hoch ist und es damit zunehmend wahrscheinlich wird, eine falsche Nullhypothese verwerfen zu können. -->

<!-- BORTZ: t-Tests sollten nicht eingesetzt werden, wenn – insbesondere bei kleineren Stichprobenumfängen – die jeweiligen Voraussetzungen (normalverteilte Grundgesamtheit und ggf. Varianzhomogenität) nicht erfüllt sind. -->
                                                                                          

## Grundkonzepte und Vorgehen

![Allgemeiner Workflow der Datenanalyse](../imgs/flowchart_analysis.png)

### Planung

#### __Statistische Hypothesen und Signifikanzniveau festlegen__

__Ungerichtete Hypothesen:__

$H_0$: Die Populationsmittelwerte der Gruppe 1 und 2 unterscheiden sich nicht (d.h. haben eine Differenz gleich 0) $\mu_1 = \mu_2$

$H_1$: Die Populationsmittelwerte der Gruppe 1 und 2 unterscheiden sich (d.h. haben eine Differenz ungleich 0) $\mu_1 \neq \mu_2$

__Gerichtete Hypothesen:__

Die Hypothesen können auch gerichtet formuliert werden (die Populationsmittelwerte sind grösser/kleiner in einer Gruppe):

$H_0$: Der Mittelwert der Gruppe 1 ist kleiner oder gleich gross wie der Mittelwert der Gruppe 2 $\quad \mu_1 \leq \mu_2$ 

$H_1$: Der Mittelwert der Gruppe 1 ist grösser als der Mittelwert der Gruppe 2 $\quad \mu_1 > \mu_2$.

oder

$H_0$: Der Mittelwert der Gruppe 1 ist grösser oder gleich gross wie der Mittelwert der Gruppe 2 $\quad \mu_1 \geq \mu_2$ 

$H_1$: Der Mittelwert der Gruppe 1 ist kleiner als der Mittelwert der Gruppe 2 $\quad \mu_1 < \mu_2$.

__Signifikanzniveau:__

Wird ein Signifikanzniveau von $\alpha = 0.05$ festgelegt, bedeutet dies, dass bei der Verwerfung der Nullhypothese eine 5% Wahrscheinlichkeit besteht, dass eigentlich kein Unterschied besteht und irrtümlicherweise einer angenommen wurde.

#### __A-priori Poweranalyse durchführen__

Vor der Datenerhebung soll eine a-priori Poweranalyse durchgeführt werden. Einerseits kann damit  ermittelt werden, wie viel Power (Teststärke) der Test hat, um einen Effekt von vordefinierter Grösse (z.B. einen grossen Effekt von $d=0.8$) zu entdecken. Andererseits kann berechnet werden, wie gross die Stichprobe sein sollte, um einen Effekt bestimmter Grösse und eine festgelegte Teststärke zu erreichen. 

<aside> Ein Wert über $0.8$ gilt gemäss den Konventionen für $\delta$ -Masse nach Cohen (1988) für den Zweistichprobentest als _grosser_ Effekt.^[Eid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 338] </aside>

### Vorverarbeitung

#### __Daten einlesen, vorverarbeiten und visualisieren__

Zuerst müssen die Daten eingelesen und bereinigt werden. 
Daten können diagnostisch visualisiert werden, um z.B. fehlende Werte zu entdecken oder Verteilungen der Daten visuell beurteilen und Extremwerte zu identifizieren.

Für den _t_-Test für unabhängige Stichproben werden die Daten hier in einem `long`-Format benötigt. 

<aside> Es ist auch möglich Daten im _Wide_-Format zu verwenden, da sich das _Long_-Format aber für die Deskriptivstatistik und Visualisierung besser eignen, wird in diesem Kapitel durchgehend mit einem _Long_-Format gearbeitet. </aside>

#### __Voraussetzungen überprüfen__

- __Varianzhomogenität__

Der _t_-Test für unabhängige Stichproben setzt Varianzhomogenität voraus. Dies kann mit dem __Levene-Test__  (in _R_ mit der Funktion `leveneTest()`) überprüft werden.  

Der Levene-Test geht von der Nullhypothese aus, dass sich die beiden Varianzen nicht unterscheiden. Ein nicht signifikantes Ergebnis bedeutet daher, dass sich die Varianzen nicht unterscheiden und somit Varianzhomogenität (sogenannte Homoskedastizität) besteht. Wenn der Test signifikant ist, wird Varianzheterogenität angenommen. Konventionell wird hierfür ein $\alpha = 0.05$ angenommen. 

<aside> Teilweise wird ein konservativerer Cut-off von $\alpha = 0.1$ verwendet. </aside>

Falls die Varianzen heterogen (unterschiedlich) sind , müssen die Freiheitsgrade des _t_-Wertes entsprechend angepasst werden. In diesem Fall kann ein Welch-Test (Welch's _t_-Test) verwendet werden, der zur Berechnung der Teststatistik die beiden unterschiedlichen Populationsvarianzen anstatt die gepoolte Innerhalbvarianz nimmt. Dazu wird in _R_ die Funktion `t.test()`mit der Option `var.equal = FALSE` genutzt. 


### Analyse

#### __Deskriptivstatistik und Visualisierung__

Bei Gruppenunterschieden wird für jede Gruppe ein Lagemass (z.B. Mittelwert oder Median) sowie ein Streumass (z.B. Standardabweichung, Standardfehler, Konfidenzintervall) berechnet. Das Lagemass stellt die durchschnittliche Merkmalsausprägung in den beiden Gruppen dar. Das Streumass zeigt den Streubereich der Daten auf.

<aside> Genauere Informationen zu Lage- und Streumassen sind im [Kapitel: Deskriptive Statistik](descriptive.qmd) zu finden. </aside>

Zur Visualisierung von Gruppenunterschieden eignen sich Lagemasse mit Fehlerbalken. Boxplots eignen sich beispielsweise gut, um Grösse des Gruppenunterschiedes (Effekts) und die Kohärenz der Datenpunkte (Ähnlichkeit der Werte innerhalb einer Bedingung/Gruppe) zu beurteilen.

Durch die Visualisierung der Rohwerte, kann die Verteilung der Messungen gut eingeschätzt werden und Extremwerte werden deutlich sichtbar. Bei zu vielen Datenpunkten führt das Visualisieren der Rohwerte zu unübersichtlichen Grafiken.

#### __Teststatistik berechnen__

Um zu überprüfen, ob die beiden Mittelwerte signifikant unterschiedlich sind, muss die Teststatistik berechnet werden. Die Verteilung der Teststatistik folgt bei homogenen Varianzen einer sogenannten _t_-Verteilung (auch Student's _t_-Verteilung genannt^[[https://www.scientificamerican.com/article/how-the-guinness-brewery-invented-the-most-important-statistical-method-in/](https://www.scientificamerican.com/article/how-the-guinness-brewery-invented-the-most-important-statistical-method-in/)]), die durch die Anzahl Freiheitsgrade (df) definiert ist.

Um die empirische Prüfgrösse zu berechen, wird die Mittelwertsdifferenz durch den Standardfehler der Mittelwertsdifferenz geteilt:

$t_{\overline{x}_1-\overline{x}_2}=\frac{\overline{x}_1-\overline{x}_2}{\hat\sigma_{\overline{x}_1-\overline{x}_2}}$

Der Standardfehler der Mittelwertsdifferenz wird wie folgt geschätzt:

$\hat \sigma_{\overline{x}_1-\overline{x}_2}=\sqrt {\frac {\hat\sigma_{inn}^2}{n_1}+ \frac{\hat\sigma_{inn}^2}{n_2}}$

Die dafür nötige gepoolte (gemeinsame) Innerhalbvarianz kann folgendermassen berechnet werden:

$\hat\sigma_{inn}^2=\frac{\hat\sigma^2_1 \cdot (n_1-1) +\hat\sigma^2_2 \cdot (n_2-1) }{n_1+n_2-2}$

Die Freiheitsgrad lassen sich für einen unabhängigen _t_-Test berechnen:

$df=n_1+n_2-2$

Nun muss die berechnete empirische Prüfgrösse _t_ auf Signifikanz überprüft werden. Dazu wird der Wert mit dem kritischen Wert der durch die Freiheitsgrade bestimmten _t_-Verteilung verglichen. Der kritische Wert kann in dieser [Tabelle](https://www.beltz.de/fileadmin/beltz/downloads/OnlinematerialienPVU/28201_Eid/05_Verteilungstabellen/Tab.A.03.pdf) abgelesen werden. 

- Die $H_0$ wird beibehalten, wenn die empirische Prüfgrösse _t_ __kleiner__ als der kritische Wert ist. Die Gruppen unterscheiden sich nicht signifikant bzw. es konnte kein Einfluss der Gruppenvariablen auf die AV gefunden werden. 

- Die $H_0$ wird abgelehnt, wenn die empirische Prüfgrösse _t_ __grösser__ als der kritische Wert ist. Die Gruppen unterscheiden sich signifikant bzw. es konnte ein Einfluss der Gruppenvariablen auf die AV gefunden werden. 


<aside> Bei gerichteten Hypothesen müssen die Aussagen entsprechend angepasst werden.</aside>


#### __Effektstärke bestimmen__

Die Effektgrösse beim _t_-Test für unabhängige Stichproben sagt etwas darüber aus, wie gross der Unterschied zwischen den beiden Populationsmittelwerten ist. 

Die standardisierte Effektgrösse kann folgendermassen berechnet werden: 

$d=\frac{\overline{x}_1-\overline{x}_2}{\hat\sigma_{inn}}$

Die Effektgrösse $d$ kann auch direkt über den _t_-Wert bestimmt werden:

$d=t \cdot \sqrt {\frac{n_1 + n_2}{n_1 \cdot n_2}}$

Die Konventionen nach Cohen (1988) lauten hier:

$|d|=\approx 0.2$: kleiner Effekt

$|d|=\approx 0.5$: mittelgrosser Effekt

$|d|=\approx 0.8$: grosser Effekt


### Schlussfolgerungen

#### __Ergebnisse interpretieren und berichten__

Je grösser der empirische _t_-Wert ist, desto stärker spricht dies gegen die Nullhypothese. 

Meistens werden in psychologischen Publikationen die Stichprobenmittelwerte und ihre geschätzten Populationsstandardabweichungen (Stichprobenstandardabweichungen) sowie die _t_-Statistik, ihre Freiheitsgrade und der _p_-Wert (also der Wahrscheinlichkeit dieses oder eines noch extremeren _t_-Wertes unter Annahme der Nullhypothese) berichtet. 

Falls der exakte _p_-Wert sehr klein ist, beispielsweise  $p=0.00000012$ bzw. kleiner als $0.001$, wird dies folgendermassen notiert: $p < .001$.^[[https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf)]

> Personen mit dem Treatment _X_ unterscheiden sich signifikant in ihrer kognitiven Leistung von Personen ohne Treatment _X_, _t_(40)=-2.63, _p_ < .001, _d_ = 0.34.

> Personen mit der Diagnose _X_ unterscheiden sich nicht in ihrer Schmerzempfindlichkeit von Personen ohne Diagnose _X_, _t_(40)=-0.13,) _p_ = .641).



## Anwendungsbeispiel in R

::: {.callout-note appearance="default" title="Beispiel: Stimmungsexperiment" icon=false}
In einem Experiment^[Eid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 366] wurden Versuchspersonen entweder in positive Stimmung (Gruppe 1) oder in negative Stimmung (Gruppe 2) versetzt und mussten danach Rechenaufgaben lösen. 
Gemessen wurde, wie viele Rechenaufgaben die Versuchspersonen im Anschluss korrekt lösen konnten. 

- Die _unabhängige Variable_ war die Stimmungsinduktion mit 2 Stufen (dichotom): positiv und negativ.
- Die _abhängige Variable_ war die Anzahl korrekt gelöster Rechenaufgaben (metrisch). Es handelt es sich hierbei um einen Indikator für die stetige Variable kognitive Leistungsfähigkeit.

:::


### Planung

#### __Statistische Hypothesen und Signifikanzniveau festlegen__

$H_0$: Die Stimmung hat keinen Einfluss auf die Leistung: $\mu_1=\mu_2$ 

$H_1$: Die Stimmung hat einen Einfluss auf die Leistung: $\mu_1 \neq\mu_2$ 

Das Alphaniveau wird auf $5 \%$ festgelegt. Da es sich um eine ungerichtete Hypothese handelt, wird zweiseitig getestet. 

#### __A-priori Poweranalyse durchführen__

- `n1`: Anzahl Messwerte Stichprobe 1
- `n2`: Anzahl Messwerte Stichprobe 2
- `d`: Effektgrösse
- `sig.level`: $\alpha$ (Fehler 1. Art)
- `alternative`: $H_1$ gerichtet (`greater`oder `less`) oder ungerichtet (`two-sided`)

```{r}
# Package laden
library(pwr)

# A-priori Poweranalyse 
# Power berechnen
pwr.t2n.test(n1 = 40, n2 = 40, d = 0.8,
             sig.level = 0.05,
             alternative = "two.sided")

# Stichprobengrösse berechnen
pwr.t.test(d = 0.8, power = 0.8, sig.level = 0.05, type = "two.sample")


```

<aside> Vor dem ersten Verwenden muss das Package {pwr} heruntergeladen/installiert werden, z.B. in der Konsole mit `install.packages("pwr")`. </aside>

Eine Teststärke (Power) von 0.94 bedeutet, dass die Wahrscheinlichkeit 94 % beträgt, einen tatsächlich vorhandenen Effekt mit einer Effektstärke von $d = 0.8$ zu entdecken.

Um mit einer Teststärke von 80% einen grossen Effekt von $d=0.8$ zu finden, wird eine Stichprobe von mindestens $n=26$ pro Gruppe benötigt.

### Vorverarbeitung

#### __Daten einlesen und vorverarbeiten__

::: {.callout-caution appearance="default" title="Hands-on: Beispieldatensatz Stimmungsexperiment" collapse="false"}


__Daten herunterladen und einlesen__

[Hier](../data/ttests.zip) kann der Projektordner mit den Daten heruntergeladen werden. Vor dem ersten Verwenden muss der Ordner entzippt werden, dann kann das _RProject_ namens `ttests.Rproj` geöffnet werden. Der Ordner enthält

- _RProject_ namens `ttest.Rproj`
- Datensatz `mood.csv` in `data`-Ordner
- _RNotebook_ namens `independent_ttest.Rmd`
- (die weiteren Dateien werden für den _t_-Test für abhängige Stichproben und die Übung 4 verwendet.)

```{r, message=FALSE}
# Package laden
library(tidyverse)

# Daten laden und anschauen
d_mood <- read.csv("data/mood.csv") |>
    glimpse() 

```

__Datensatz transformieren__

Für den _t_-Test werden die Daten in einem `long` Format benötigt. Daher müssen die Daten vom bisherigen `wide` Format in ein `long` Format umstrukturiert werden und eine Variable `id` ergänzt werden.

```{r}
# Datenformat von wide zu long transformieren
d_mood_long <- d_mood  |>
  pivot_longer(cols = c(mood_neg, mood_pos),
               names_to = "condition",
               values_to = "performance") |>
  mutate(id = row_number()) |>
  select(id, condition, performance)

# id (Subjekt-ID) und condition (Gruppenvariable) als Faktor definieren
d_mood_long <- d_mood_long |> 
  mutate(id = as.factor(id)) |> 
  mutate(condition = as.factor(condition))
print(d_mood_long)
```

:::

#### __Voraussetzungen überprüfen__

Der _t_-Test setzt voraus, dass das Merkmal $X$ in der Population stetig und normalverteilt ist und die beiden Populationsvarianzen gleich (homogen) sind.

<aside>Die Voraussetzung der Normalverteilung wird in diesem Semester nicht überprüft. </aside>

Die Varianzhomogenität (Homoskedastizität) kann mit dem Levene-Test `leveneTest(y ~ x, data = data)` überprüft werden. 
Es wird ein konventionelles Signifikanzniveau von $\alpha = 0.05$ angenommen. 
Ein Levene-Test mit $p < 0.05$ bedeutet, dass der Varianzunterschied  signifikant ist. 
Die Nullhypothese, dass die beiden Varianzen auf Populationsebene identisch sind, muss in diesem Fall verworfen werden.

<aside> In dieser Veranstaltung verwenden wir $\alpha = 0.05$. Teilweise wird ein konservativerer Cut-off von $\alpha = 0.1$ verwendet. Das würde im aktuellen Beispiel dazu führen, dass die Varianzen nicht als homogen angenommen werden. Im unten dargestellten Plot kann gut erkannt werden, dass die Streuung ähnlich, aber nicht exakt gleich ist. </aside>


```{r, message=FALSE}
# Levene-Test mit dem package {car}
car::leveneTest(performance ~ condition, # av ~ uv
                data = d_mood_long) # Datensatz
```

Der Test ist hier nicht signifikant ($p = .071$), daher wird davon ausgegangen, dass die Varianzen in beiden Gruppen homogen sind. Somit kann ein Student's _t_-Test verwenden werden.  

### Analyse

#### __Deskriptivstatistik und Visualisierungn__

Für die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden. 

```{r}
# Nach condition gruppieren und performance zusammenfassen
d_summary <- d_mood_long |>
  group_by(condition) |> # Gruppieren
  summarise(mean_performance = mean(performance), # Mittelwert
            sd_performance = sd(performance)) # Standardabweichung
d_summary
```

Mit einem Boxplot kann die Verteilung der Werte noch genauer angeschaut und die beiden Gruppen visuell miteinander verglichen werden.   

```{r}
# Boxplot
p_boxplot <- d_mood_long |> 
  ggplot(aes(x = condition, y = performance)) +
  geom_jitter(aes(colour = condition), alpha = 0.3, width = 0.1) + # Datenpunkte
  geom_boxplot(alpha = 0, width = 0.2, color = "black") + # Boxplot
  scale_colour_manual(values = c("mood_neg" = "red4", # Farben
                               "mood_pos" = "blue4")) +
  labs(title = "Effect of Mood on Performance", # Beschriftungen
      subtitle = "Independent t-Test",
       x = "Mood Condition",
       y = "Performance Score") +
  theme_minimal(base_size = 12) + # Theme
  theme(legend.position = "none") 

p_boxplot # Plot anzeigen
```


#### __Teststatistik berechnen__

__a. Berechnung Teststatistik von Hand__ 

Im Folgenden wird ein _t_-Test für unabhängige Stichproben unter der Annahme von homogenen Varianzen "von Hand" berechnet. 

```{r}
n1 <- 40 # Stichprobengrösse: negative Stimmung
n2 <- 40 # Stichprobengrösse: positive Stimmung
x1 <- 12.40 # Mittelwert: negative Stimmung
sd1 <- 5.61 # Standardabweichung: negative Stimmung
x2 <- 10.15 # Mittelwert: positive Stimmung
sd2 <- 4.32 # Standardabweichung: positive Stimmung

# Berechnung der empirischen Prüfgrösse
var_inn <- (sd1^2*(n1 - 1) + sd2^2*(n2 - 1))/((n1 - 1) + (n2 - 1))
sd_meandiff <- sqrt(var_inn/n1 + var_inn/n2)
(x1 - x2)/sd_meandiff # empirischer t-Wert

# Ausgabe der kritischen Werte
qt(0.025, 78) # kritischer t-Wert unterhalb
qt(0.975, 78) # kritischer t-Wert oberhalb
```

Nach dieser Berechnung liegt der empirische _t_-Wert bei $2.01$ leicht über dem kritischen Wert von $1.99$. Die Mittelwerte unterscheiden sich daher signifikant auf dem $5 \%$-Niveau. 

__b. Berechnung Teststatistik in R mit der Funktion `t.test`__

Viel einfacher kann den _t_-Test für unabhängige Stichproben mit `t.test(formula = y ~ x, alternative, var.equal, data)` berechnet werden.

- `y`: Abhängige Variable (metrisch)
- `x`: Unabhängige Variable (Bedingung oder Gruppenvariable)
- `alternative`: festlegen, ob die $H_1$ gerichtet (`greater`oder `less`) oder ungerichtet (`two-sided`) ist
- `var.equal`: festlegen, ob die Annahme homogener Varianzen zutrifft (`TRUE`) oder nicht (`FALSE`)

```{r}
# t-Test für unabhängige Stichproben durchführen
t.test(formula = performance ~ condition, # av ~ uv
       alternative = "two.sided",
       var.equal = TRUE,
       data = d_mood_long)

```
Die Mittelwerte der beiden Gruppen unterscheiden sich signifikant auf dem $5 \%$-Niveau. Die Nullhypothese, wonach sich die beiden Mittelwerte nicht unterscheiden kann verworfen werden. Die Stimmung beeinflusst somit die kognitive Leistung.


#### __Effektstärke bestimmen__

__Berechnung der Effektgrösse (Cohen's _d_)__

Nun kann noch die Effektgrösse mit `cohen.d(formula = y ~ x, data)` aus dem Package {effsize} berechnet werden. 

```{r}
# Effektgrösse berechnen
effsize::cohen.d(formula = performance ~ condition, # av ~ uv
                 data = d_mood_long) # Datensatz
```

Die Effektgrösse liegt bei $d=0.45$. Es handelt sich nach der Taxonomie von Cohen (1988) um einen __kleinen__ Effekt.

### Schlussfolgerungen

#### __Ergebnisse interpretieren und berichten__

Das Ergebnis ist auf dem $5 \%$-Niveau signifikant und die Nullhypothese kann somit verworfen werden: Die Stimmung beeinflusst die kognitive Leistungsfähigkeit. Es handelt sich nach der Taxonomie von Cohen (1988) um einen kleinen Effekt ($d=0.45$). 

>"We examined whether the mood condition had an effect on cognitive performance. There was a significant difference between the positive and negative mood condition, _t_(78) = 2.01, _p_ = .048, _d_ = 0.45). Participants in the negative mood condition (_M_ = 12.40, _SD_ = 5.61) performed significantly better on the task than those in the positive mood condition (_M_ = 10.15, _SD_ = 4.32). This indicates a small effect of mood on cognitive performance according to Cohen’s convention (1988)."

