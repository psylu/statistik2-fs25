# *t*-Test für unabhängige Stichproben {#sec-t-test-ind}

```{r}
#| include: false
# Set working directory of R
knitr::opts_knit$set(root.dir = '../')
```

## Anwendungsbereich

Mit _t_-Tests für unabhängige Stichproben wird untersucht, wie sich zwei voneinander unabhängige Gruppen in einem intervallskalierten Mass unterscheiden, wenn die Populationsvarianz unbekannt ist.  

__Typische Fragestellungen__:

- *Wie unterscheiden sich Personen mit der Diagnose von Personen ohne Diagnose X in der Fähigkeit Y?*

- *Wie unterscheiden sich Personen mit einer hohen Ausprägung eines Persönlichkeitsmerkmals von Personen mit einer tiefen Ausprägung in Fähigkeit Y?*

- *Wie unterscheiden sich ältere Personen von jüngeren Personen in der Einschätzung von Y (z.B. Lebenszufriedenheit)?*

- *Wie unterscheiden sich Personen, die ein Treatment erhalten haben, von Personen, welche dieses Treatment nicht erhalten haben (Kontrollgruppe) in der Symptomausprägung Y?*


__Beispiele__:

- [Martin & Kerns, 2011](https://pmc.ncbi.nlm.nih.gov/articles/PMC3051364/)
  - Fragestellung: Welchen Einfluss hat eine positive Stimmung auf die kognitive Leistung gemessen im Stroop Task oder im Running Span Task?
  - Typische Aussage: The results revealed that the positive mood group performed significantly worse on the running span task, $t(174) = 2.14, p < .05$, but there were no differences between the groups on the Stroop task, $t(173) = 0.54, p = .59$.


## Voraussetzungen

| Voraussetzung | Erklärung | Vorgehen bei Verletzung |
|-------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Unabhängigkeit der Messwerte | Die Messwerte _innerhalb_ der beiden Stichproben müssen voneinander unabhängig sein. Das bedeutet, bei beiden Stichproben muss es sich um einfache, voneinander unabhängige Zufallsstichproben handeln. |  |
| Unabhängigkeit der Gruppen/Stichproben  | Die Messwerte müssen _zwischen_ den beiden Stichproben unabhängig sein (unabhängige Gruppen).  | Verletzung der Unabhängigkeitsannahme: Die Annahme, dass die Messwerte zwischen den beiden Stichproben  unabhängig sind, ist z.B. dann verletzt, wenn die Messwerte in natürlichen Paaren (Geschwister, Messwiederholung) vorliegen. Eine solche Abhängigkeit kann jedoch durch entsprechende Tests kontrolliert werden, indem beispielsweise ein _t_-Test für abhängige Stichproben verwendet wird, siehe [Kapitel: t-Test für abhängige Stichproben](https://psylu.github.io/statistik2-fs25/datenanalyse/ttest.html) |
| Metrisches Skalenniveau und Normalverteilung (der AV) | Das Merkmal _Y_, also die AV, muss in den beiden Teilpopulationen stetig und normalverteilt sein. Bei der UV handelt es sich um eine dichotome Gruppenvariable. | Non-parametrische Verfahren: Falls die AV ordinalskaliert ist oder die Voraussetzungen der Normalverteilung nicht erfüllt ist, kann ein non-parametrisches (verteilungsfreies) Verfahren gewählt werden; z.B. Vergleich von zwei unabhängigen Stichproben mit dem _U_-Test von Mann-Whitney. |
| Varianzhomogenität / Homoskedastizität | Die Varianzen innerhalb der beiden Teilpopulationen müssen _homogen_ sein. Ist diese Annahme erfüllt, liegt Homoskedastizität vor. Vor allem wenn die Stichproben unterschiedlich gross sind, bietet sich eine empirische Überprüfung der Varianzhomogenitätsannahme an. | - Überprüfung der Varianzhomogenitätsannahme: Der Vergleich von zwei Stichprobenvarianzen kann mit dem _F_-Test oder dem Levene-Test erfolgen. Da der Levene-Test eine robuste Variante zum _F_-Test darstellt, werden wir hier diesen verwenden. |
|  | | - Verletzung der Varianzhomogenitätsannahme: Ist die Annahme der Varianzhomogenität verletzt (Heteroskedastizität), kann als Alternative der Welch-Test verwendet werden, welcher nicht die gepoolten Innerhalb-Varianzen, sondern die beiden unterschiedlichen Stichprobenvarianzen $\hat \sigma^2_1$ und $\hat \sigma^2_2$ verwendet. |

### Unabhängigkeit der Messwerte

Die Messwerte _innerhalb_ der beiden Stichproben müssen voneinander unabhängig sein. Das bedeutet, bei beiden Stichproben muss es sich um einfache, voneinander unabhängige Zufallsstichproben handeln. 


### Unabhängigkeit der Gruppen / Stichproben

Die Messwerte müssen _zwischen_ den beiden Stichproben unabhängig sein (unabhängige Gruppen). 

- Verletzung der Unabhängigkeitsannahme: Die Annahme, dass die Messwerte zwischen den beiden Stichproben  unabhängig sind, ist z.B. dann verletzt, wenn die Messwerte in natürlichen Paaren (Geschwister, Messwiederholung) vorliegen. Eine solche Abhängigkeit kann jedoch durch entsprechende Tests kontrolliert werden, indem beispielsweise ein _t_-Test für abhängige Stichproben verwendet wird, siehe [Kapitel: t-Test für abhängige Stichproben](https://psylu.github.io/statistik2-fs25/datenanalyse/ttest.html).


### Metrisches Skalenniveau und Normalverteilung (der AV)

Das Merkmal _Y_, also die AV, muss in den beiden Teilpopulationen stetig und normalverteilt sein. Bei der UV handelt es sich um eine dichotome Gruppenvariable. 

- Non-parametrische Verfahren: Falls die AV ordinalskaliert ist oder die Voraussetzungen der Normalverteilung nicht erfüllt ist, kann ein non-parametrisches (verteilungsfreies) Verfahren gewählt werden; z.B. Vergleich von zwei unabhängigen Stichproben mit dem _U_-Test von Mann-Whitney.

- Auf die Verletzung der Normalverteilungsannahme und die non-parametrischen Verfahren wird in diesem Semester nicht weiter eingegangen.


### Homogenität der Populationsvarianzen (Homoskedastizität)

Die Varianzen innerhalb der beiden Teilpopulationen müssen _homogen_ sein. Ist diese Annahme erfüllt, liegt Homoskedastizität vor. Vor allem wenn die Stichproben unterschiedlich gross sind, bietet sich eine empirische Überprüfung der Varianzhomogenitätsannahme an. 

- Überprüfung der Varianzhomogenitätsannahme: Der Vergleich von zwei Stichprobenvarianzen kann mit dem _F_-Test oder dem Levene-Test erfolgen. Da der Levene-Test eine robuste Variante zum _F_-Test darstellt, werden wir hier diesen verwenden. 

- Verletzung der Varianzhomogenitätsannahme: Ist die Annahme der Varianzhomogenität verletzt (Heteroskedastizität), kann als Alternative der Welch-Test verwendet werden, welcher nicht die gepoolten Innerhalb-Varianzen, sondern die beiden unterschiedlichen Stichprobenvarianzen $\hat \sigma^2_1$ und $\hat \sigma^2_2$ verwendet. 

<!-- BORTZ: Die Varianzen σ1 und σ2 der zu vergleichen- den Populationen sind gleich. Ist dies der Fall, so darf man für die Stichprobenvarianzen erwarten, dass s21 ≈ s2. Verfahren zur Überprü-
- BORTZ: Das untersuchte Merkmal muss in beiden Po- pulationen, denen die Stichproben entnommen wurden, normalverteilt sein. Sind die Verteilungsformen der Grundgesamtheiten unbekannt, kann die Normalverteilungsannahme mit einem Verfahren überprüft werden, das in Abschnitt 9.2 besprochen wird.
- ... -> non-parametrische Tests (Eid...)
BORTZ: Alle drei besprochenen t-Tests lassen sich unabhängig vom Stichprobenumfang anwenden, wenn die gemachten Annahmen erfüllt sind. Mit ande- ren Worten, selbst bei kleinen Stichprobenumfängen gewährleisten die Tests, dass das festgelegte Signifikanzniveau eingehalten wird. Natürlich sind trotzdem grosse Stichprobenumfänge wünschenswert, da dadurch die Teststärke entsprechend hoch ist und es damit zunehmend wahrscheinlich wird, eine falsche Nullhypothese verwerfen zu können. -->

<!-- BORTZ: t-Tests sollten nicht eingesetzt werden, wenn – insbesondere bei kleineren Stichprobenumfängen – die jeweiligen Voraussetzungen (normalverteilte Grundgesamtheit und ggf. Varianzhomogenität) nicht erfüllt sind. -->

### Zusammenfassung

| Voraussetzung                                         | Erklärung                                                                                                                                                                                                                                                                | Vorgehen bei Verletzung                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|-------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Unabhängigkeit der Messwerte                          | Messwerte _innerhalb_ der Stichproben müssen voneinander unabhängig sein. |  |
| Unabhängigkeit der Gruppen/Stichproben                | Messwerte müssen _zwischen_ den beiden Stichproben sind unabhängig (unabhängige Gruppen) | Verwendung [_t_-Test für abhängige Stichproben](https://psylu.github.io/statistik2-fs25/datenanalyse/ttest.html) |
| Metrisches Skalenniveau und Normalverteilung (der AV) | Bei der UV handelt es sich um eine dichotome Gruppenvariable. Das Merkmal _Y_, also die AV, muss in den beiden Teilpopulationen stetig und normalverteilt sein. Bei der UV handelt es sich um eine dichotome Gruppenvariable.                                                                                                          | Verwenden von non-parametrischen Verfahren: Falls die AV ordinalskaliert ist oder die Voraussetzungen der Normalverteilung nicht erfüllt ist, kann ein non-parametrisches (verteilungsfreies) Verfahren gewählt werden; z.B. Vergleich von zwei unabhängigen Stichproben mit dem _U_-Test von Mann-Whitney.                                                                                                                                                                                                                            |
| Varianzhomogenität / Homoskedastizität | Die Varianzen innerhalb der beiden Teilpopulationen müssen _homogen_ sein (Homoskedastizität). | <ul><li>Überprüfung der Varianzhomogenitätsannahme: Der Vergleich von zwei Stichprobenvarianzen mittels _F_-Test oder Levene-Test (robuste Variante zum _F_-Test).</li> <li>Verletzung der Varianzhomogenitätsannahme: Ist die Annahme der Varianzhomogenität verletzt (Heteroskedastizität), kann als Alternative der Welch-Test verwendet werden, welcher nicht die gepoolten Innerhalb-Varianzen, sondern die beiden unterschiedlichen Stichprobenvarianzen $\hat \sigma^2_1$ und $\hat \sigma^2_2$ verwendet.</li></ul> | 

## Grundkonzepte und Vorgehen

![Allgemeiner Workflow der Datenanalyse](../imgs/flowchart_analysis.png)

### Planung

__1. Statistische Hypothesen und Signifikanzniveau festlegen__

$H_0$: Die Populationsmittelwerte unterscheiden sich nicht (d.h. haben eine Differenz gleich 0) $\mu_1 = \mu_2$

$H_1$: Die Populationsmittelwerte unterscheiden sich (d.h. haben eine Differenz ungleich 0) $\mu_1 \neq \mu_2$

Die Hypothesen können auch gerichtet formuliert werden, z.B. die Populationsmittelwerte sind grösser/kleiner.


__2. A-priori Poweranalyse durchführen__

Vor der Datenerhebung soll eine a-priori Poweranalyse durchgeführt werden. Einerseits kann damit  ermittelt werden, wie viel Power (Teststärke) der Test hat, um einen Effekt von vordefinierter Grösse (z.B. einen grossen Effekt von $d=0.8$) zu entdecken. Andererseits kann berechnet werden, wie gross die Stichprobe sein sollte, um einen Effekt bestimmter Grösse und eine festgelegte Teststärke zu erreichen. 

<aside> Ein Wert über $0.8$ gilt gemäss den Konventionen für $\delta$ -Masse nach Cohen (1988) für den Zweistichprobentest als _grosser_ Effekt.^[Eid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 338] </aside>

### Analyse

__1. Daten einlesen und vorverarbeiten__

Zuerst müssen die Daten eingelesen und bereinigt werden. Für den _t_-Test werden die Daten hier in einem `long`-Format benötigt. 

__2. Daten visualiseren__

Daten können diagnostisch visualisiert werden, um 

- fehlende Werte zu entdecken
- Verteilungen der Daten visuell beurteilen
- die Grösse des Effekts und die Kohärenz der Datenpunkte (Ähnlichkeit der Werte innerhalb einer Bedingung) zu beurteilen

Zur Visualisierung eignen sich Boxplots oder Lagemasse mit Fehlerbalken. Das Lagemass (z.B. Mittelwert oder Median) stellt dabei die durchschnittliche Merkmalsausprägung in den beiden Stichproben dar. Das Streumass (Standardabweichung, Standardfehler, Quartile) zeigt den Streubereich der Daten auf.

<aside> Genauere Informationen zu Lage- und Streumassen sind im [Kapitel: Deskriptive Statistik](descriptive.qmd) zu finden. </aside>

__3. Voraussetzungen überprüfen__


- __Varianzhomogenität__

Der _t_-Test für unabhängige Stichproben setzt Varianzhomogenität voraus. Dies kann in _R_ mit dem __Levene-Test__ überprüft werden.  

Der Levene-Test geht von der Nullhypothese aus, dass sich die beiden Varianzen nicht unterscheiden. Ein nicht signifikantes Ergebnis bedeutet daher, dass sich die Varianzen nicht unterscheiden und somit Varianzhomogenität (sogenannte Heteroskedastizität) besteht. Wenn der Test signifikant ist, wird Varianzheterogenität angenommen.

Falls die Varianzen heterogen (unterschiedlich) sind , müssen die Freiheitsgrade des _t_-Wertes entsprechend angepasst werden. In diesem Fall kann ein Welch-Test (Welch's _t_-Test) verwendet werden, der zur Berechnung der Teststatistik die beiden unterschiedlichen Populationsvarianzen anstatt die gepoolte Innerhalbvarianz nimmt. Dazu wird in _R_ die Funktion `t.test()`mit der Option `var.equal = FALSE` genutzt. 


__4. Teststatistik berechnen__

Um zu überprüfen, ob die beiden Mittelwerte signifikant unterschiedlich sind, muss die Teststatistik berechnet werden. Die Verteilung der Teststatistik folgt bei homogenen Varianzen einer sogenannten _t_-Verteilung (auch Student's _t_-Verteilung genannt^[https://www.scientificamerican.com/article/how-the-guinness-brewery-invented-the-most-important-statistical-method-in/]), die durch die Anzahl Freiheitsgrade (df) definiert ist.

Um die empirische Prüfgrösse zu berechen, wird die Mittelwertsdifferenz durch den Standardfehler der Mittelwertsdifferenz geteilt:

$t_{\overline{x}_1-\overline{x}_2}=\frac{\overline{x}_1-\overline{x}_2}{\hat\sigma_{\overline{x}_1-\overline{x}_2}}$

Der Standardfehler der Mittelwertsdifferenz wird wie folgt geschätzt:

$\hat \sigma_{\overline{x}_1-\overline{x}_2}=\sqrt {\frac {\hat\sigma_{inn}^2}{n_1}+ \frac{\hat\sigma_{inn}^2}{n_2}}$

Die dafür nötige gepoolte (gemeinsame) Innerhalbvarianz kann folgendermassen berechnet werden:

$\hat\sigma_{inn}^2=\frac{\hat\sigma^2_1 \cdot (n_1-1) +\hat\sigma^2_2 \cdot (n_2-1) }{n_1+n_2-2}$

Die Freiheitsgrad lassen sich für einen unabhängigen _t_-Test berechnen:

$df=n_1+n_2-2$

Nun muss die berechnete empirische Prüfgrösse _t_ auf Signifikanz überprüft werden. Dazu wird der Wert mit dem kritischen Wert der durch die Freiheitsgrade bestimmten _t_-Verteilung verglichen. Der kritische Wert kann in einer [Tabelle](https://www.beltz.de/fileadmin/beltz/downloads/OnlinematerialienPVU/28201_Eid/05_Verteilungstabellen/Tab.A.03.pdf) abgelesen werden. 

Die $H_0$ wird beibehalten, wenn die empirische Prüfgrösse __kleiner__ als der kritische Wert ist. Die Gruppen unterscheiden sich nicht signifikant bzw. die Gruppenvariable hat keinen Einfluss auf die AV. 

Die $H_0$ wird abgelehnt, wenn die empirische Prüfgrösse __grösser__ als der kritische Wert ist. Die Gruppen unterscheiden sich  signifikant bzw. die Gruppenvariable hat einen Einfluss auf die AV. 


__5. Effektstärke__

Die Effektgrösse beim _t_-Test für unabhängige Stichproben sagt etwas darüber aus, wie gross der Unterschied zwischen den beiden Populationsmittelwerten ist. 

Die standardisierte Effektgrösse kann folgendermassen berechnet werden: 

$d=\frac{\overline{x}_1-\overline{x}_2}{\hat\sigma_{inn}}$

Die Effektgrösse $d$ kann auch direkt über den _t_-Wert bestimmt werden:

$d=t \cdot \sqrt {\frac{n_1 + n_2}{n_1 \cdot n_2}}$

Die Konventionen nach Cohen (1988) lauten hier:

$|d|=\approx 0.2$: kleiner Effekt

$|d|=\approx 0.5$: mittelgrosser Effekt

$|d|=\approx 0.8$: grosser Effekt


### Schlussfolgerungen

__Ergebnisse interpretieren und berichten__

Je grösser der _t_-Wert ist, desto stärker spricht dies grundsätzlich gegen die Nullhypothese. 

Meistens werden in psychologischen Publikationen die Stichprobenmittelwerte und ihre geschätzten Populationsstandardabweichungen (Stichprobenstandardabweichungen) sowie die _t_-Statistik, ihre Freiheitsgrade und ihr _p_-Wert (also der Wahrscheinlichkeit dieses oder eines noch extremeren Wertes unter der Nullhypothese) berichtet. 

Falls der exakte _p_-Wert sehr klein ist, beispielsweise  $p=0.00000012$ bzw. unter $0.001$, wird dies folgendermassen notiert: $p < .001$.^[https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf]

> Personen mit dem Treatment _X_ unterscheiden sich signifikant in ihrer kognitiven Leistung von den Personen ohne Treatment _X_, $t(40)=-2.63, p < .001$.


## Anwendungsbeispiel in R

::: {.callout-tip appearance="default" title="Beispiel: Stimmungesexperiment" icon=false}
In einem Experiment wurden Versuchspersonen entweder in positive Stimmung (Gruppe 1) oder in negative Stimmung (Gruppe 2) versetzt und mussten danach verschiedene Rechenaufgaben lösen. Gezählt wurde, wie viele Rechenaufgaben die Versuchspersonen im Anschluss lösen konnten. Bei der abhängigen Variablen handelt es sich hierbei um einen Indikator für die stetige Variable kognitive Leistungsfähigkeit.^[Eid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 366]
:::


### Planung

__1. Statistische Hypothesen und Signifikanzniveau festlegen__

$H_0$: Die Stimmung hat keinen Einfluss auf die Leistung: $\mu_1=\mu_2$ 

$H_1$: Die Stimmung hat einen Einfluss auf die Leistung: $\mu_1 \neq\mu_2$ 

Das Alphaniveau wird auf $5 \%$ festgelegt. Da es sich um eine ungerichtete Hypothese handelt, wird zweiseitig getestet. 

__2. A-priori Poweranalyse durchführen__

- `n1`: Anzahl Messwerte Stichprobe 1
- `n2`: Anzahl Messwerte Stichprobe 2
- `d`: Effektgrösse
- `sig.level`: $\alpha$ (Fehler 1. Art)
- `alternative`: $H_1$ gerichtet (`greater`oder `less`) oder ungerichtet (`two-sided`)

```{r}
# Package laden
library(pwr)

# A-priori Poweranalyse 
# Effektstärke d: 
pwr.t2n.test(n1 = 40, n2 = 40, d = 0.8,
             sig.level = 0.05,
             alternative = "two.sided")

# Stichprobengrösse berechnen
pwr.t.test(d = 0.8, power = 0.8, sig.level = 0.05, type = "two.sample")


```
Eine Teststärke (Power) von 0.94 bedeutet, dass die Wahrscheinlichkeit, einen tatsächlich vorhandenen Effekt (mit einer Effektstärke von 0.8) zu entdecken, 94 % beträgt.

Um mit einer Teststärke von 80% einen grossen Effekt von $d=0.8$ zu finden, benötiget es eine Stichprobe von mindestens $n=26$ pro Gruppe.

### Datenanalyse


__1. Daten einlesen und vorverarbeiten__

::: {.callout-caution appearance="default" title="Hands-on: Beispieldatensatz Stimmungsexperiment" collapse=true}


__Daten herunterladen und einlesen__

Hier können die Daten innerhalb eines RProjects heruntergeladen werden: [Download](https://psylu.github.io/....zip) 

```{r, message=FALSE}
# Packages laden
library(tidyverse)

# Daten laden und anschauen
d_mood <- read.csv("data/mood.csv") |>
    glimpse() 

```

__Datensatz umstruktrieren__

Für den _t_-Test werden die Daten in einem `long` Format benötigt. Daher müssen die Daten vom bisherigen `wide` Format in ein `long` Format umstrukturiert werden und eine Variable `id` ergänzt werden.

```{r}
# Datenformat long erstellen
d_mood_long <- d_mood  |>
  pivot_longer(cols = c(mood_neg, mood_pos),
               names_to = "condition",
               values_to = "performance") |>
  mutate(id= row_number()) |>
  select(id, condition, performance)

# ID und Gruppenvariable als Faktor definieren
d_mood_long <- d_mood_long |> 
  mutate(id = as.factor(id)) |> 
  mutate(condition = as.factor(condition))
print(d_mood_long)
```

:::

Für die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden. 

```{r}
# Nach condition gruppieren und performance zusammenfassen
d_summary <- d_mood_long |>
  group_by(condition) |>
  summarise(mean_performance = mean(performance),
            sd_performance = sd(performance))
d_summary
```


__2. Daten visualiseren__

Mit einem Boxplot kann die Verteilung der Werte noch genauer angeschaut und die beiden Gruppen visuell miteinander verglichen werden.   

```{r}
library(ggplot2)

# Boxplot
p_boxplot <- d_mood_long |> 
  ggplot(aes(x = condition, y = performance)) +
  geom_jitter(aes(colour = condition), alpha = 0.25, width = 0.2) +
  geom_boxplot(alpha = 0, width = 0.2, color = "black") +
  scale_colour_manual(values = c("mood_neg" = "red4",
                               "mood_pos" = "blue4")) +
  labs(title = "Boxplot Effect of Mood on Performance",
       x = "Mood Condition",
       y = "Performance Score") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none")

p_boxplot
```


__3. Voraussetzungen überprüfen__

Der _t_-Test setzt voraus, dass das Merkmal $X$ in der Population stetig und normalverteilt ist und die beiden Populationsvarianzen gleich (homogen) sind.

<aside>: Die Voraussetzung der Normalverteilung wird in diesem Semester nicht überprüft. </aside>

Die Varianzhomogenität (Homoskedastizität) kann mit dem Levene-Test `leveneTest(y ~ x, data = data)` überprüft werden. Ein Levene-Test mit $p < 0.05$ bedeutet, dass der Varianzunterschied  signifikant ist. Die Nullhypothese, dass die beiden Varianzen auf Populationsebene identisch sind, muss in diesem Fall verworfen werden.

```{r, message=FALSE}
#Levene-Test mit dem package {car}
car::leveneTest(performance ~ condition, data = d_mood_long)

```

Der Test ist hier nicht signifikant ($p=.071$), daher wird davon ausgegangen, dass die Varianzen in beiden Gruppen homogen sind. Somit kann ein Student's _t_-Test verwenden werden.  


__4. Teststatistik__

__a. Berechnung Teststatistik von Hand__ 

Im Folgenden wird ein _t_-Test für unabhängige Stichproben unter der Annahme von homogenen Varianzen "von Hand" berechnet. 

```{r}
n1 <- 40 # Stichprobengrösse: negative Stimmung
n2 <- 40 # Stichprobengrösse: positive Stimmung
x1 <- 12.40 # Mittelwert: negative Stimmung
sd1 <- 5.61 # Standardabweichung: negative Stimmung
x2 <- 10.15 # Mittelwert: positive Stimmung
sd2 <- 4.32 # Standardabweichung: positive Stimmung

# Berechnung der empirischen Prüfgrösse
var_inn <- (sd1^2*(n1 - 1) + sd2^2*(n2 - 1))/((n1 - 1) + (n2 - 1))
sd_meandiff <- sqrt(var_inn/n1 + var_inn/n2)
(x1 - x2)/sd_meandiff # empirischer t-Wert

# Ausgabe der kritischen Werte
qt(0.025, 78) # kritischer t-Wert unterhalb
qt(0.975, 78) # Kritischer t-Wert oberhalb
```

Nach dieser Berechnung liegt der empirische _t_-Wert bei $2.01$ leicht über dem kritischen Wert von $1.99$. Die Mittelwerte unterscheiden sich daher signifikant auf dem $5 \%$-Niveau. 

__b. Berechnung Teststatistik in R mit der Funktion `t.test`__

Viel einfacher kann den _t_-Test für unabhängige Stichproben mit `t.test(formula = y ~ x, alternative, var.equal, data)` berechnet werden.

- `y`: Abhängige Variable (metrisch)
- `x`: Unabhängige Variable (Bedingung oder Gruppenvariable)
- `alternative`: festlegen, ob die $H_1$ gerichtet (`greater`oder `less`) oder ungerichtet (`two-sided`) ist
- `var.equal`: festlegen, ob die Annahme homogener Varianzen zutrifft (`TRUE`) oder nicht (`FALSE`)

```{r}
# t-Test für unabhängige Stichproben durchführen
t.test(formula = performance ~ condition,
       alternative = "two.sided",
       var.equal = TRUE,
       data = d_mood_long)

```
Die Mittelwerte der beiden Gruppen unterscheiden sich signifikant auf dem $5 \%$-Niveau. Die Nullhypothese, wonach sich die beiden Mittelwerte nicht unterscheiden kann verworfen werden. Die Stimmung beeinflusst somit die kognitive Leistung.


### Effektstärke

__Berechnung der Effektgrösse (Cohen's _d_)__

Nun kann noch die Effektgrösse mit `cohen.d(formula = y ~ x, data)` aus dem Package {effsize} berechnet werden. 

```{r}
# Effektgrösse berechnen
effsize::cohen.d(formula = performance ~ condition, data = d_mood_long)
```

Die Effektgrösse liegt bei $d=0.45$. Es handelt sich nach der Taxonomie von Cohen (1988) um einen __kleinen__ (bis mittelgrossen) Effekt.


### Interpretation der Ergebnisse

Das Ergebnis ist auf dem $5 \%$-Niveau signifikant und die Nullhypothese kann somit verworfen werden: Die Stimmung beeinflusst die kognitive Leistungsfähigkeit. Es handelt sich nach der Taxonomie von Cohen (1988) um einen kleinen Effekt ($d=0.45$). 


### Ergebnisse berichten

"We examined whether the mood condition had an effect on cognitive performance. There was a significant differences between the positive and negative mood condition. Participants in the negative mood condition ($M = 12.40$, $SD = 5.61$) performed significantly better on the task than those in the positive mood condition ($M = 10.15$, $SD = 4.32$), $t(78) = 2.01, p = .024, d = 0.45$. This indicates a small effect of mood on cognitive performance."

