# Übung 6 {.unnumbered #sec-uebung-06}

```{r}
#| include: false
# Set working directory of R
knitr::opts_knit$set(root.dir = '../')
```

::: {.callout-note appearance="default" title="Lernziele dieser Übung"}
Nach der heutigen Übung können Sie:

- _R_ und _RStudio_ zur Analyse von Daten verwenden

- einfaktorielle Varianzanalysen ohne Messwiederholung in _R_ durchführen
    - Hypothesen zum Vergleich von mehr als zwei Stichprobenmittelwerten von unabhängigen Gruppen durchführen
    - Voraussetzungen überprüfen
    - Test berechnen 
    - Resultate interpretieren
    - Post-hoc Paarvergleiche und Kontrastanalysen berechnen

Diese Übung ist eine Weiterführung von [Übung 5](uebung-5.qmd). Absolvieren Sie zuerst Übung 5, bevor Sie hier weiterarbeiten. 

:::


:::{.callout-note appearance="default" title="Voraussetzungen"}

1. Packages {tidyverse}, {afex}, {emmeans}, {beeswarm}, {effectsize} sind installiert.

2. Projekt und Datensatz aus Übung 5 wurden heruntergeladen.

3. Übung 5 wurde gelöst.

:::

<br>

## Aufgabe 6.0: Projektumgebung erstellen 

_Falls obige Anforderungen noch nicht erfüllt:_ 

- Laden Sie den Projektordner herunter und __entzippen__ Sie den Ordner.^[Für das Entzippen mit _Windows_ machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie `Entpacken nach` und geben Sie den Ordner an, in dem Sie alle Ihre _RProject-Ordner_ speichern. Für das Entzippen mit _Mac_ speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre _RProject-Ordner_ speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden.] </aside>

- Installieren Sie die benötigten Packages (falls noch nicht geschehen) unter `Tools` > `Install Packages...` oder in der Konsole mit

   `install.packages("afex")`
   
   `install.packages("emmeans")`
   
   `install.packages("beeswarm")`
   
   `install.packages("effectsize")`
    
__a.__ Öffnen Sie das _RProjekt_ `anova`.
  
__b.__ Erstellen Sie ein _RNotebook_ namens `uebung-06` oder arbeiten Sie bei `uebung-05` weiter.

<br>

## Aufgabe 6.1: Einstieg

__a.__ Welche Vermutungen haben Sie bei Aufgabe __5.2.h__? Welche Mittelwerte unterscheiden sich Ihrer Einschätzung nach bedeutsam?

> z.B. Instrumental > Rock/Oper > Schlager

__b.__ Wie viele paarweise Mittelwertsvergleiche durch _t_-Tests sind im Musikexperiment grundsätzlich möglich?

> 3*2=6

> $\mu_1 = \mu_2$, $\mu_1 = \mu_3$, $\mu_1 = \mu_4$, $\mu_2 = \mu_3$, $\mu_2 = \mu_4$, $\mu_3 = \mu_4$

> Mit Kontrasten sind aber auch Kombinationen davon möglich.

__c.__ Worin besteht das Problem des multiplen Testens?

> Bei multiplen Mittelwertvergleichen kumuliert sich der $\alpha$-Fehler. Man spricht deshalb auch von einer Inflation des Fehlers 1. Art. Wenn die Nullhypothese gilt, wird jeder Test mit einer Wahrscheinlichkeit $\alpha$ signifikant, somit steigt mit jedem zusätzlichen Test die Wahrscheinlichkeit, dass der Test rein zufällig signifikant wird, weil $\alpha$ kumuliert wird. z.B. bei 6 Einzelvergleichen mit der gleichen Stichprobe, würde die Nullhypothese ohne Korrektur bereits bei 0.265 verworfen und nicht bei 0.05. 

> $s = 3$, $\alpha_r = 0.05$

> $\alpha_{fam} = 1 - (1 - \alpha_r)^6 = 1 - 0.95^6 = 1 - 0.735 = 0.265$


## Aufgabe 6.2: Post-hoc Vergleiche

<!-- hier ev. den Code bis und mit Anova drin lassen, damits schneller geht -->

__a.__ Anova-Modell berechnen

- Lesen Sie den Datensatz `anova_music.csv` ein und konvertieren Sie die Variable `id` und `condition` zu einem Faktor (siehe [Übung 5](uebung-05.qmd)). Schauen Sie sich den Datensatz kurz mit `glimpse()` an.

```{r, message=FALSE}
# tidyverse laden
library(tidyverse)

# Datensatz einlesen
d_music <- read.csv("data/anova_music.csv")

# Faktoren konvertieren
d_music <- d_music |>
  mutate(id = as.factor(id)) |>
  mutate(condition = as.factor(condition))

# Datensatz anschauen
glimpse(d_music)
```

- Berechnen Sie das Anova-Modell `m_anova1` (siehe [Übung 5](uebung-05.qmd)). 

```{r, message=FALSE}
# afex laden
library(afex)

# Einfaktorielle Anova 
m_anova1 <- aov_4(testscore ~ condition + (1 | id), 
                data = d_music) 

# Resultate ausgeben
summary(m_anova1) 
m_anova1$Anova
```


- Erstellen Sie mit der Funktion `emmeans()` aus dem Package {emmeans} ein Objekt, z.B. `m_anova1_results`. Darin werden die "Estimated Marginal Means" gespeichert. 

```{r}
#| eval: false

# Package emmeans laden
library(emmeans)

# Resultate (estimated marginal means) speichern
m_anova1_result <- emmeans(object = ____, specs = ~ ____) # object = anova modell, ~ uv
m_anova1_result
```

```{r, message=FALSE}
# Package emmeans laden
library(emmeans)

# Resultate (estimated marginal means) speichern
m_anova1_result <- emmeans(object = m_anova1, specs = ~ condition) # object = anova modell, ~ uv
m_anova1_result
```
> Hier können Mittelwerte abgelesen werden.

- Lassen Sie sich mit der Funktion `pairs(x = model, adjust = "none")` zuerst alle Paarvergleiche ausgeben, ohne dass eine Korrektur vorgenommen wird. Zu Übungszwecken können Sie die korrigierten Resultate mit den unkorrigierten vergleichen.  

```{r}
# Post-hoc ohne Adjustierung
pairs(x = m_anova1_result, adjust = "none") 
```
> Ohne Adjustierung sind alle ausser "oper-rock" signifikant unterschiedlich. So aber nicht zulässig (Multiples Testen). 


__b.__ Überprüfen Sie mit dem Tukey-Test alle Paarvergleiche gleichzeitig.

- Welche Voraussetzungen erfordert der Tukey-Test?

> Der Tukey-Test setzt voraus, dass für alle _J_ Bedingungen gleiche Stichprobengrössen vorliegen. Bei unbalancierten Stichproben wird der Tukey-Kramer-Test oder der Scheffé-Test verwendet. Nur die Tukey-Adjustierung ist eigentlich für einen vollständigen Paarvergleich aller Bedingungen wie hier geeignet. Die anderen Adjustierungsmethoden sollten vorzugsweise für ein Subset von Bedingungsvergleichen benutzt werden. Diese müssten dann zuerst als ein Set von Kontrasten definiert werden.

- Welchen Vorteil hat der Tukey-Test gegenüber der Bonferroni-Korrektur?

> Bei Gültigkeit der statistischen Voraussetzungen hat der Tukey-Test eine grössere Power als Tests auf der Basis der Bonferroni-Korrektur, wenn alle Mittelwerte miteinander verglichen werden (Maxwell & Delaney, 2004). 

- Welche Prüfgrösse gibt der Tukey-Test aus?

> t.ratio (add comment, formel siehe VL6)

- Führen Sie den Post-hoc-Vergleich für alle möglichen Mittelwertspaare mit `adjust = "tukey"` durch. Wie lautet Ihre Testentscheidung? 

```{r}
# Post-hoc mit dem Tukey-Test
pairs(x = m_anova1_result, adjust = "tukey") 
```

> Der Tukey-Test wird verwendet, wenn alle möglichen Mittelwertspaare verglichen werden sollen.

> Interpretation: Die paarweise Mittelwertsdifferenzen unterscheiden sich signifikant von 0, ausser die Differenz Rock - Oper.

> Im Vergleich zu den p-Werten ohne Korrektur: Die p-Werte sind ohne Korrektur kleiner, d.h. deuten eher darauf hin, dass die Nullhypothese abgelehnt wird, da unter der Nullhypothese kleine p-Werte (grosse t-Werte) unwahrscheinlich sind. 

```{r}
# Post-hoc ohne Korrektur
pairs(x = m_anova1_result, adjust = "none") 
```


__c.__ Als eine weitere Möglichkeit wollen Sie a-priori (also vorher) festgelegte Hypothesen prüfen. Dabei ist es wichtig, vorher festzulegen, welche Mittelwertsvergleiche untersucht werden sollen. 

Prüfen Sie mit der Bonferroni-Holm-Methode, welche Bedingungsmittelwerte sich signifikant unterscheiden. 

- Wie funktioniert die Bonferroni-Holm-Methode?

> Aufsteigende Sortierung der p-Werte (bzw. auch an t-Werte möglich).
> Jeder p-Wert wird dann mit spezifisch adjustiertem p-Wert verglichen (schrittweise).
> Dies wird solange fortgesetzt, bis der erste p-Wert nicht mehr signifikant ist. 
> Ab dann alle weiteren $H_0$ nicht mehr ablehnen.  

- Welchen Vorteil hat sie gegenüber der Bonferroni-Methode?

> Mehr Power, da schrittweises Testen. 

- Führen Sie den Post-hoc-Vergleich mit `adjust = "holm"` durch. Wie lautet Ihre Testentscheidung? Vergleichen Sie die $p$-Werte mit den unkorrigierten Werten.

```{r}
# Post-hoc-Vergleiche mit der Bonferroni-Holm-Methode
pairs(x = m_anova1_result, adjust = "holm")

```

> Die BHM passt das Signifikanzniveau schrittweise an. Daher kontrolliert die Methode den Fehler 1. Art (family-wise error rate), hat aber gleichzeitig mehr Power als die klassische Bonferroni-Methode.

> Hier wird der Vergleich mit dem kleinsten t-Wert zum Schluss auf dem 0.05-Alphaniveau getestet, die vorherigen Vergleiche werden auf einem korrigierten Alphaniveau getestet. Dies ist hier nicht wirklich ersichtlich, da der zweitletze Vergleich (oper- schlager) auf dem 0.025 Niveau getestet wird und daher auch signifikant wird. Man sieht jedoch, dass der zweitgrösste $p$-Wert mit $\cdot 2$ adjustiert wurde ($0.0005 \cdot 2 = 0.0011$). 


- Falls ein unbalanciertes Design vorliegt, kann die Bonferroni-Holm-Methode nicht verwendet werden. Überprüfen Sie die Paarvergleiche daher auch mit dem Scheffé-Test mit `adjust = "scheffe"`. Was fällt Ihnen auf? 

> Scheffé-Test bei unbalancierten Designs sinnvoll, da recht streng/konversativ, lehnt Nullhypothese nicht schnell ab

> Mit diesem Test wird der gesamte, mit allen möglichen Einzelvergleichen verbundene Hypothesenkomplex der Varianzanalyse auf dem festgelegten Niveau eines Fehlers 1. Art abgesichert.

```{r}
# Post-hoc-Vergleiche mit dem Scheffé-Test z.B. bei unbalancierten Daten
pairs(x = m_anova1_result, adjust = "scheffe")
```

> p-Werte sind höher, d.h. die Wahrscheinlichkeit, dass die Nullhypothese abgelehnt wird, ist kleiner. Der Scheffé-Test ist tendenziell eher konservativ (d. h. entscheidet zugunsten der H0).


> Weitere Varianten

```{r}
# Post-hoc-Vergleiche mit Adjustierung
pairs(x = m_anova1_result, adjust = "sidak")

# Post-hoc-Vergleiche mit Bonferroni
pairs(x = m_anova1_result, adjust = "bonferroni")
```



## Aufgabe 6.3: Kontrastanalysen

__a.__ Schauen Sie sich mit der Funktion `levels()` im Datensatz an in welcher Reihenfolge die Stufen des Faktors `condition` geordnet sind:

```{r}
levels(d_music$condition)
```


__b.__ Kontrastanalysen erfordern das Definieren von Kontrasten. Definieren Sie die Kontraste für folgende Hypothesen und benennen Sie den Kontrast. Wichtig: Ein Kontrast in dieser Aufgabe besteht aus 4 Werten. In der Summe ergeben die Werte eines Kontrastes 0. 

- "Die kognitive Leistung unter Opernmusik ist höher als in den drei anderen Bedingungen."

> Kontrast "oper - rest" : -1 3 -1 -1

- "Die kognitive Leistung unter Schlagermusik ist besser als unter Rockmusik."

> Kontrast "schlager - rock" : 0 0 -1 1

- "Die kognitive Leistung ist besser unter Rockmusik im Vergleich zu den drei anderen Musikarten."

> Kontrast "instrumental - rest" : -1 -1 3 -1


__c.__ Wir wollen nun die Hypothese überprüfen, dass die Konzentrationsleistung von Personen unter dem Einfluss klassischer Instrumentalmusik (Bedingung 1) __höher__ ist als unter dem Einfluss von Opernmusik (Bedingung 2), von Rockmusik (Bedingung 3) oder von Schlagermusik (Bedingung 4).

Überprüfen Sie mit Hilfe eines Kontrasts die Hypothese, dass die kognitive Leistung in der Instrumentalbedingung höher ist als der Durchschnitt der kognitiven Leistung in den drei anderen Musikbedingungen.  

```{r}
# Kontrastanalyse
## H: Instrumental unterscheidet sich von anderen Bedingungen
m_anova1_contrast1 <- list("instrumental - rest" = c(3, -1, -1, -1)) # Kontrast definieren
contrast(object = m_anova1_result, method = m_anova1_contrast1)
```

> Test auf Abweichung einer Bedingung vom Durchschnitt der anderen Bedingungen (=Helmert Kontrast)

> 3, -1, -1, -1 (oder mathematisch äquivalente Lösungen, aber sinnvoll ist, dass die interessierende Bedingung gemäss Hypothese positiven Wert hat, d.h. 3) 

> gerichtete Hypothese: der $p$-Wert muss dadurch halbiert werden (einseitig testen) --> $p < .001$ (macht hier keinen Unterschied zu ungerichtet, da hoch signifikant)

__b.__ Überprüfen Sie nun eine andere Hypothese, die besagt, dass sich moderne Pop- und Rocksongs (inkl. Schlager) von anderen Musikarten wie Instrumentalmusik und Oper in ihrem Effekt auf die kognitive Leistung unterscheiden (d.h. Instrumental & Oper versus Schlager & Rock). 

```{r}
# Kontrastanalyse
## H: Instrumental/Oper unterscheidet sich von Rock/Schlager
m_anova1_contrast2 <- list("instrumental/oper - rock/schlager" = c(1, -1, 1, -1)) # Kontrast definieren
contrast(object = m_anova1_result, method = m_anova1_contrast2)
```

__c.__ Was passiert, wenn man mehrere Kontraste berechnet? 

> Je mehr Kontraste überprüft werden, umso stärker steigt der $\alpha_{fam}$-Fehler für eine Familie von Kontrasten an. Es ist daher wichtig und sinnvoll, dass die Kontraste vorher definiert werden und ADD. 


## Zusatzaufgabe

:::{.callout-tip appearance="default" title="Zusatzaufgaben"}

__Zusatzaufgaben müssen nicht gelöst werden.__

:::

__a.__ Verfassen Sie für die Resultate der Aufgabe 6.2 in einen Text für einen wissenschaftlichen Artikel.

__b.__ Erstellen Sie eine Grafik des Datensatzes `d_music` der die durchschnittliche Leistung in allen vier Bedingungen miteinander vergleicht, mit `condition` und `testscore` auf den beiden Achsen. Hierfür eignet sich beispielsweise ein Boxplot oder einem Violinplot.








