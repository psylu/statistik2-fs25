[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Datenanalyse mit R",
    "section": "",
    "text": "Überblick\nDiese Website enthält ein Online-Skript begleitend zur Vorlesung Statistik 2 (FS 2025) des Bachelorstudiums Psychologie (VPF) an der Universität Luzern.\nInhalt:\nZu Beginn einige wichtige Informationen zum Arbeiten mit der Website:\nTextbausteine dieser Website\nUm das Arbeiten mit dem Skript zu erleichten, enthält dieses verschiedene Bausteine, die unterschiedliche Funktionen haben:\nText\nDies ist ein Text inkl. mathematischer Formulierungen: \\(\\alpha = 5\\).\nCode\nCode ist Text, welcher in R ausgeführt werden kann. Wenn ein #-Zeichen davor steht, ist der Text “auskommentiert”, das bedeutet, dass R ihn nicht liest/ausführt.\n# Dies ist ein Kommentar, also auskommentierter Text. Er wird nicht ausgeführt.\n# Unten eine Zeile Code (ausführbarer Text):\nalpha = 5\nInfo-Blöcke\nInfo-Blöcke beinhalten Informationen, Aufgaben oder Lösungen.\nWebR-Konsolen\nIn den WebR-Blöcken können Sie direkt in Ihrem Browser Code eingeben und ausführen. Sie können den Code aus diesen Blöcken in R ebenfalls ausführen.",
    "crumbs": [
      "Überblick"
    ]
  },
  {
    "objectID": "index.html#weiteres",
    "href": "index.html#weiteres",
    "title": "Datenanalyse mit R",
    "section": "Weiteres",
    "text": "Weiteres\nTasten werden wie folgt beschrieben: Drücken Sie Ctrl-CCtrl-C um ausgewählten Code zu kopieren und Ctrl-VCtrl-V um ihn wieder einzufügen.",
    "crumbs": [
      "Überblick"
    ]
  },
  {
    "objectID": "r/installation.html",
    "href": "r/installation.html",
    "title": "1  Installation",
    "section": "",
    "text": "1.1 Step-by-Step Installation für Windows",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "r/installation.html#sec-windows",
    "href": "r/installation.html#sec-windows",
    "title": "1  Installation",
    "section": "",
    "text": "1.1.1 Installation von R\nÖffnen Sie die Installations-Website. Wählen Sie Download R for Windows, um die neuste Version von R (4.4.2 Pile of Leaves) zu installieren.\n\n\n\n\n\n\nFigure 1.1: Startseite für die Installation von R und RStudio\n\n\n\nLaden Sie unter install R for the first time die Installationsdatei herunter.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Installation von R: Auswahl des Betriebssystems\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.3: Installation von R für Windows: Auswahl der R Version\n\n\n\n\n\n\nKlicken Sie auf Download R-4.4.2 for Windows.\n\n\n\n\n\n\nFigure 1.4: Installation von R für Windows: Downloadlink\n\n\n\nÖffnen Sie die Installationsdatei (oft im Ordner Downloads zu finden) und folgen Sie den Anweisungen. Falls untenstehend nicht anders erwähnt, behalten Sie die Standardeinstellungen bei.\n\nUnter_Select Setup Language_ wählen Sie am besten English als Sprache. Die englische Version macht es leichter im Internet Hilfe zu finden.\n\n\n\n\n\n\n\nFigure 1.5: Installation von R für Windows: Englisch\n\n\n\n\nAm besten speichern Sie R in einem Ordner auf dem Laufwerk C: ab. Hierfür benötigen Sie Admin-Rechte.\n\n\n\n\n\n\n\nFigure 1.6: Installation von R für Windows: Wählen des Speicherorts\n\n\n\nSobald das untenstehende Fenster erscheint, haben Sie R erfolgreich installiert.\n\n\n\n\n\n\nFigure 1.7: Installation von R für Windows: Erfolgreiche Installation\n\n\n\n\n\n1.1.2 Installation von RStudio\nWählen Sie Download RStudio Desktop for Windows, um die neuste Version von RStudio zu installieren.\n\n\n\n\n\n\nFigure 1.8: Startseite für die Installation von R und RStudio\n\n\n\nÖffnen Sie die Installationsdatei (oft im Ordner Downloads zu finden) und folgen Sie den Anweisungen. Falls untenstehend nicht anders erwähnt, behalten Sie die Standardeinstellungen bei.\nWenn Sie R und RStudio installiert haben, fahren Sie hier fort.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "r/installation.html#sec-macos",
    "href": "r/installation.html#sec-macos",
    "title": "1  Installation",
    "section": "1.2 Step-by-Step Installation für MacOS",
    "text": "1.2 Step-by-Step Installation für MacOS\n\n1.2.1 Installation von R\nÖffnen Sie die Installations-Website. Wählen Sie Download R for macOS, um die neuste Version von R (4.2.2 “Pile of Leaves”) zu installieren.\n\n\n\n\n\n\nFigure 1.9: Startseite für die Installation von R und RStudio\n\n\n\nLaden Sie die zu Ihrer Version von macOS passende Installationsdatei herunter. Beachten Sie, dass es zwei Versionen gibt. In der Regel gibt es eine Fehlermeldung, falls Sie einen Intel Prozessor (ältere Mac-Modelle, ca. vor 2021) haben und daher nicht die obere Version verwenden können.\n\n\n\n\n\n\nFigure 1.10: Installation von R für macOS: Downloadlink\n\n\n\nÖffnen Sie die Installationsdatei (oft im Ordner Downloads zu finden) und folgen Sie den Anweisungen. Falls die Auswahl erscheint, wählen Sie English als Sprache. Die englische Version macht es leichter im Internet Hilfe zu finden. Falls untenstehend nicht anders erwähnt, behalten Sie die Standardeinstellungen bei.\n\nSpeichern Sie R auf der Macintosh HD ab. In der Regel entspricht dies den Standardeinstellung und Sie müssen nichts anpassen. Sie benötigen hierfür Admin-Rechte.\n\n\n\n\n\n\n\nFigure 1.11: Installation von R für macOS: Startfenster\n\n\n\nSobald das untenstehende Fenster erscheint, haben Sie R erfolgreich installiert.\n\n\n\n\n\n\nFigure 1.12: Installation von R für macOS: Erfolgreiche Installation\n\n\n\n\n\n1.2.2 Installation von RStudio\nWählen Sie Download RStudio Desktop for MacOS, um die neuste Version von RStudio zu installieren.\n\n\n\n\n\n\nFigure 1.13: Startseite für die Installation von R und RStudio\n\n\n\nÖffnen Sie die Installationsdatei (oft im Ordner Downloads zu finden) und folgen Sie den Anweisungen. Falls untenstehend nicht anders erwähnt, behalten Sie die Standardeinstellungen bei.\nWenn Sie R und RStudio installiert haben, fahren Sie hier fort.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "r/installation.html#sec-setuprstudio",
    "href": "r/installation.html#sec-setuprstudio",
    "title": "1  Installation",
    "section": "1.3 Einrichten von RStudio",
    "text": "1.3 Einrichten von RStudio\nIn einem nächsten Schritt können wir RStudio konfigurieren, so dass wir gut damit arbeiten können.\n\n1.3.1 Verändern der Grundeinstellungen\nUnter Tools &gt; Global Options ... finden Sie viele Anpassungsmöglichkeiten für Ihre RStudio-Konfiguration.\nFolgende Anpassung empfehlen wir, weil dies hilft zukünftige Fehler zu vermeiden. Entfernen Sie die beiden Haken bei den eingefärbten Kästchen und wählen Sie die Option Never.\n\n\n\n\n\n\nFigure 1.14: Einrichten RStudio: Speicheroptionen\n\n\n\nWeiter können Sie hier beispielsweise unter Appereance die Farben und Schriftarten verändern.\n\n\n1.3.2 Informationen zu Ihrem Setup\nUm zu erfahren, wie Ihr installiertes Setup aussieht, können Sie folgende Befehle nutzen.\n\n# Informationen über das Betriebssystem\nSys.info()\n\n# Informationen über die R Version\nR.version\n\n# Informationen über die RStudio Version\nRStudio.Version()\n\nDiese Informationen sind unter Umständen sehr nützlich, wenn es ums Debugging/Beheben von Fehler geht.\n\n\n1.3.3 Speicherort der Packages\nFühren Sie folgenden Code in der Konsole aus, um zu erfahren in welchen Ordner RStudio Packages herunterlädt.\n\n.libPaths()",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "r/installation.html#faq-installation",
    "href": "r/installation.html#faq-installation",
    "title": "1  Installation",
    "section": "1.4 FAQ Installation",
    "text": "1.4 FAQ Installation\nHier werden häufige Fragen beantwortet.\nZurzeit noch keine Fragen und Antworten vorhanden.\n\n\n\n\n\n\nHilfreiche Informationen und Anleitungen zur Installation\n\n\n\n\nPsyTeachR Website: Ausführliche Installationsanweisungen inkl. Screenshots und Videoanweisung (in Englisch).",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "r/installation.html#footnotes",
    "href": "r/installation.html#footnotes",
    "title": "1  Installation",
    "section": "",
    "text": "Sie können R und RStudio selbstverständlich auch mit Linux installieren. Wir gehen in dieser Veranstaltung davon aus, dass Sie dies ohne zusätzliche Anleitung ausführen können. Für allfällige linuxspezifische Probleme können wir nur in begrenztem Rahmen Hilfe anbieten. Falls Sie die Expertise und Motivation haben eine Step-by-Step Anleitung für Linux zu schreiben, dürfen Sie sich gerne bei uns melden.↩︎",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html",
    "href": "r/rrstudio.html",
    "title": "2  Basics R und RStudio",
    "section": "",
    "text": "2.1 R, RStudio und WebR\nR ist eine leistungsstarke Programmiersprache und eine Open-Source-Softwareumgebung. Sie wird in der Forschung für die Datenverarbeitung, statistische Datenanalyse und Datenvisualisierung eingesetzt. R wird von Forschenden und Data Scientists weltweit verwendet, da eine breite Sammlung an Erweiterungen (Packages) zugänglich ist. Dadurch, dass diese Packages kontinuierlich weiterentwickelt und neue Packages erstellt werden, bietet R umfangreiche “state of the art” Funktionen. R kann für einfache Datenanalysen, wie auch für komplexe statistische Modelle und machine learning genutzt werden.\nRStudio ist eine integrierte Entwicklungsumgebung (IDE) für die Programmiersprache R, die den Umgang mit R vereinfacht und benutzerfreundlicher gestaltet. In RStudio kann Code geschrieben, ausgeführt und gespeichert werden. RStudio integriert Funktionen wie eine Konsole, ein Skriptfenster, eine Umgebung zur Verwaltung von Variablen und eine Historie der ausgeführten Befehle.\nWebR ermöglicht das Verwenden von R mit einem Browser, z.B. auf der Kurswebsite.\nArbeiten in R und RStudio eignet sich ideal für Datenverarbeitung, -analyse und -visualisierung aufgrund folgender Vorteile:",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html#r-rstudio-und-webr",
    "href": "r/rrstudio.html#r-rstudio-und-webr",
    "title": "2  Basics R und RStudio",
    "section": "",
    "text": "Genauere Informationen zu R in deutsch und englisch.\n\n\n\n\n\nleistungsstarke Funktionen wie {tidyverse} und {ggplot2} für das Einlesen, Bearbeiten, Zusammenfassen und Visualisieren von Datensätzen\nReproduzierbarkeit des Codes und wiederverwendbare sowie nachvollziehbare Analysen ermöglicht durch abspeicherbare und gut kommentierbare Skripte\nFlexibilität durch eine grosse Auswahl von R-Packages auf CRAN und die Möglichkeit, eigene Funktionen zu erstellen\nAktualität durch ständige Updates von R und R-Packages mit modernen Analysefunktionen\nZugänglichkeit: kostenlos und Open-Source\nSupport durch aktive Community mit schneller Hilfe",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html#programmierumgebung-rstudio",
    "href": "r/rrstudio.html#programmierumgebung-rstudio",
    "title": "2  Basics R und RStudio",
    "section": "2.2 Programmierumgebung RStudio",
    "text": "2.2 Programmierumgebung RStudio\nWenn Sie RStudio öffnen, sehen Sie die Standardansicht. Links finden Sie die Konsole. Sobald Sie ein Code-File öffnen, erscheint dieses links oben.\n\nSkript: In einem Skript können Sie Code schreiben und ausführen. Es können verschiedene Code-Files geöffnet werden, z.B. RSkript und RNotebooks. Wenn Sie einen Datensatz anschauen, erscheint dieser auch in diesem Quadrant.\nKonsole: Hier können Sie direkt Code eingeben und ausführen.\nUmgebung: Hier finden Sie gespeicherte Objekte (z.B. Variablen).\nArbeitsverzeichnis, Plots, Packages, Help, …: Hier finden Sie diverse hilfreiche Informationen wie z.B. die Ordnerstruktur mit der Sie aktuell arbeiten (working directory), die Anzeige von Plots, welche Packages installiert und geladen sind, Hilfe zu den einzelnen Funktionen, u.v.m.\n\n\n\nBitte verändern Sie zu Beginn diese Ansicht nicht, denn wir werden der Einfachheit halber jeweils auf Quadranten hinweisen (z.B. Sie finden etwas im “linken oberen Quadranten”). Wenn Sie die Fenster umstellen, wird diese Angabe nicht mehr zu Ihrer Konfiguration passen. Sobald Sie sich sicher fühlen, können Sie RStudio Ihre Bedürfnissen anpassen.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html#sec-rprojects",
    "href": "r/rrstudio.html#sec-rprojects",
    "title": "2  Basics R und RStudio",
    "section": "2.3 RProjekte",
    "text": "2.3 RProjekte\nIn RStudio gibt es die Möglichkeit mit RProjekten zu arbeiten. Dies gibt Ihnen die Möglichkeit Ihren Code in Projekte zu strukturieren. Ein Projekt ist eine Einheit, in der Sie Daten und Analysecode bündeln möchten.\n\nWir werden in den Übungen jeweils mit Projekten arbeiten.\n\nRProjekte haben zwei grosse Vorteile, die uns das Arbeiten in RStudio vereinfachen:\n1. RProjekte sammeln zusammengehörige Daten und Code in einem Ordner. So behalten Sie den Überblick, wo der Code für dieses Projekt zu finden ist. Sobald Sie an etwas Neuem arbeiten, erstellen Sie einfach ein neues Projekt.\n2. RProjekte ermöglichen ein stabiles working directory.\nDort wo das RProjekt abgelegt ist, beginnt R zu suchen, wenn Sie einen Pfad eingeben. Das hat zur Folge, dass innerhalb eines RProjekt-Ordners die Pfade immer gleich bleiben, auch wenn Sie den Ordner an einen anderen Ort oder sogar auch einen anderen Computer verschieben. Ausserdem sind die Pfade oft viel kürzer.\n\n# Einlesen Daten ausserhalb eines Projekts\nd_ohne_projekt &lt;- read.csv(\"C://User/nameName/Ordner/Unterordner/Unterunterordner/data/daten.csv\")\n\n# Einlesen Daten aus dem Ordner data innerhalb eines Projekts\nd_mit_projekt &lt;- read.csv(\"data/daten.csv\")\n\n\n\n\n\n\n\nProjekt-Ordner\n\n\n\n\n\nÜberlegen Sie zu Beginn gut, wo Sie Ihre Projekte abspeichern möchten.\nErstellen Sie dort einen RProjects-Ordner.\nSpeichern Sie alle RProjekte immer in diesem Ordner ab. So behalten Sie den Überblick.\n\n\n\n\n2.3.1 RProjekt erstellen\nUnter File &gt; New Project kann ein neues RProjekt erstellt werden.\n Es empfiehlt sich bei RProjekten eine Einstellungsänderung (Tools&gt; Project Options...) vorzunehmen, so dass die aktuell gespeicherten Variablen bei jedem Schliessen vom Projekt gelöscht werden. Dies verhindert, dass der aktuelle Code nur aufgrund früherer Speicherung läuft oder das falsche Variablen verwendet werden.\n\n\n\nEinstellungen anpassen für RProject\n\n\n\n\n\n\n\n\nHands-on: Erstellen eines RProjekts\n\n\n\nErstellen Sie ein neues RProjekt auf Ihrem Computer mit folgenden Schritten:\n\nÖffnen Sie RStudio.\nErstellen Sie ein neues RProjekt.\n\nKlicken Sie dafür auf File &gt; New Project &gt; New Directory &gt; New Project\nBenennen Sie das Project introduction_to_r und speichern Sie es an einem sinnvollen Ort auf Ihrem Computer.\nKlicken Sie auf Create Project.\n\nPassen Sie die Einstellungen unter Tools &gt; Project Options an.\nSchauen Sie sich im rechten unteren Quadranten unter Files das aktuelle working directory an. Was passiert, wenn Sie nun auf Ihrem Computer im Ordnern des RProjekts einen neuen Ordner namens data erstellen?\nWo im Fenster von RStudio finden Sie die Information, ob Sie gerade in einem Projekt arbeiten (und in welchem) oder nicht?\n\n\n\n\n\n\n\n\n\nTipp: Namensgebung für Files und Variablen\n\n\n\nWenn Sie Filenamen auswählen, achten Sie darauf dass diese machine-readable sind:\n\nkeine Lücken (verwenden Sie stattdessen den camelCase, den snake_case oder -)\nkeine ä, ö, ü oder andere Sonderzeichen verwenden",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html#code-schreiben-ausführen-und-speichern",
    "href": "r/rrstudio.html#code-schreiben-ausführen-und-speichern",
    "title": "2  Basics R und RStudio",
    "section": "2.4 Code schreiben, ausführen und speichern",
    "text": "2.4 Code schreiben, ausführen und speichern\nIn RStudio können Sie Code auf verschiedene Arten schreiben, ausführen und speichern.\n1. Code in der Konsole\nDies ist die einfachste Art Code zu schreiben und auszuführen. Sie können die Konsole (linker unterer Quadrant) direkt nutzen. Schreiben Sie in die Konsole Code und drücken Sie EnterEnter, um diesen auszuführen. Code in der Konsole kann nicht gespeichert werden, er geht z.B. beim Schliessen von RStudio verloren. Deshalb eignet sich die Konsole vor allem für schnelles und einmaliges Schreiben von Code. Beispiele dafür sind das Herunterladen von Packages, Ausprobieren von Code und kurzen Berechnungen, welche nicht gespeichert werden müssen.\n2. Code in RSkripts\nWenn ein RProjekt ein Ordner wäre, wären RSkripts die Blätter. Ein neues RSkript kann unter File &gt; New File &gt; R Script erstellt werden. RSkripts sind simpel: Alles was geschrieben wird, kann als Code ausgeführt werden. Mit einer Ausnahmen: Wenn ein # am Anfang der Zeile steht, gilt die Zeile als auskommentiert und wird nicht ausgeführt.\n\n# Das hier ist auskommentierter Text. Er kann nicht als Code ausgeführt werden.\n1+1 # vor dem Hash steht Code, Text hinter dem Hash wird nicht ausgeführt.\n\nUm den Code auszuführen, gibt es zwei Möglichkeiten:\n\nCode anwählen und CtrlCtrl + EnterEnter eingeben\nCode anwählen und oben das Symbol Run drücken\n\n3. Code in RNotebooks:\nEin RNotebooks, RMarkdown- oder Quarto-Files ist praktisch, wenn man Text und Code kombinieren möchte, aber man Text ohne das Auskommentieren (mit dem #) schreiben möchte. Dies ist beispielsweise der Fall, wenn man Details zu einer Analyse zu den Berechnungen hinzu schreiben möchte. Ein RNotebook kann zudem “gerendert” werden, dass heisst, es kann damit ein .html- oder ein .pdf-File erstellt werden. Das ist besonders praktisch, wenn man seine Analyse mit jemanden teilen möchte, der/die kein R benutzt (z.B. bei einer Publikation kann so der Code mit dem Artikel eingereicht werden).\nIn einem RNotebook ist Text grundsätzlich normaler Text. Nur Text in einem Code-Feld (Chunk) wird als Code erkannt. Um den Code auszuführen, gibt es drei Möglichkeiten:\n\nCode anwählen und CtrlCtrl + EnterEnter eingeben\noben rechts beim Codechunk Run drücken\noben rechts beim RNotebook Run drücken",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html#rnotebooks",
    "href": "r/rrstudio.html#rnotebooks",
    "title": "2  Basics R und RStudio",
    "section": "2.5 RNotebooks",
    "text": "2.5 RNotebooks\n\n2.5.1 Erstellen eines neuen RNotebooks\nUnter File &gt; New File &gt; R Notebook kann ein neues RNotebook erstellt werden.\n\n\n\n\n2.5.2 Header\nDer Header beschreibt den Teil zwischen den --- ganz oben im RNotebook. Dort kann der Titel des RNotebooks geändert werden. Zudem wird dort definiert, zu was das RNotebook gerendert wird (z.B. PDF, html, etc.)\n\n\n2.5.3 Codechunks\nCode wird in den Code-Chunks eingegeben und ausgeführt. Ein neuer Code-Chunk wird eingefügt mit der Tastenkombination CtrlCtrl + AltAlt +II / OptionOption +CommandCommand + II oder unter Code &gt; Insert Chunk.1\nUm den Code auszuführen, gibt es drei Möglichkeiten:\n\nCode anwählen und CtrlCtrl + EnterEnter eingeben\noben rechts beim Codechunk Run drücken\noben rechts beim RNotebook Run drücken\n\nCode kann auch auskommentiert werden mit #\n\n\n2.5.4 Textfeld\nAlles was nicht im Header oder in einem Codechunk steht, wird als Text erkannt und nicht als Code ausgeführt. Text kann in R Markdown Files nicht nur geschrieben, sondern auch relativ simpel formatiert werden mit Kapiteln, fett/kursiv Schrift, etc. strukturiert werden.\n\nCheatsheet für RMarkdown zum herunterladen\n\nWeiter können Links, Bilder, Dataoutputs, etc. eingefügt werden. Dies macht dieses Format sehr praktisch für das Erstellen von reproduzierbaren Datenanalysen-Reports.\n\nFür Interessierte: diese ganze Website ist mit Quarto-Files erstellt, die nach demselben Prinzip wie RNotebooks funktionieren. Quarto-Files können ebenfalls in RStudio erstellt und bearbeitet werden.\n\n\n\n\n\n\n\nErstellen eines RNotebooks\n\n\n\nErstellen Sie ein neues RNotebook mit folgenden Schritten:\n\nÖffnen Sie Ihr RProjekt in RStudio (falls nicht noch offen).\nErstellen Sie ein neues RNotebook.\n\nKlicken Sie dafür auf File &gt; New File &gt; R Notebook.\nBenennen Sie das RNotebook intro_datawrangling und speichern Sie es im RProjekt-Ordner ab.\n\nPassen Sie den Titel an.\nSchreiben Sie Text in das Textfeld.\nSchreiben Sie eine Zeile Code in den Code-Chunk.\nDrücken Sie Knit, um das Dokument zu rendern.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html#übersicht-dateiformate",
    "href": "r/rrstudio.html#übersicht-dateiformate",
    "title": "2  Basics R und RStudio",
    "section": "2.6 Übersicht Dateiformate",
    "text": "2.6 Übersicht Dateiformate\nIn einem RProjekt-Ordner finden sich nach der Arbeit damit viele Dateien. Die wichtigsten sind:\n\nRProjects: .Rproj\nRSkripts: .R\nRNotebooks: .Rmd\ngerenderte RNotebooks: .html, .pdf, etc.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/rrstudio.html#footnotes",
    "href": "r/rrstudio.html#footnotes",
    "title": "2  Basics R und RStudio",
    "section": "",
    "text": "Der Code-Chunk kann auch selber erstellt werden, indem die Backticks etc. eingegeben werden, aber das ist eher aufwändig.↩︎",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics R und RStudio</span>"
    ]
  },
  {
    "objectID": "r/programmieren.html",
    "href": "r/programmieren.html",
    "title": "3  Basics Programmieren",
    "section": "",
    "text": "3.1 Weshalb Programmieren als Psycholog:in?\nWir lernen in diesem Kurs das Programmieren nicht im luftleeren Raum, sondern anhand von Aufgaben und Problemen, die sich uns als Psycholog:innen stellen.\nDie Psychologie ist eine empirische Wissenschaft. Das bedeutet, die Erkenntnisse der Wissenschaftlichen Psychologie werden zu einem grossen Teil durch das Erheben und Auswerten von Daten gewonnen. Hierfür brauchen wir nicht nur Wissen darüber, wie Daten systematisch erhoben werden können, sondern auch darüber, wie diese Daten verarbeitet, zusammengefasst, interpretiert und kommuniziert werden können.\nDie Methodenausbildung befähigt dazu\nDeshalb starten wir zu Beginn mit möglichst wenig trockenem Wissen, sondern erarbeiten uns das Programmierwissen nach und nach anhand von Beispielen aus der psychologischen Praxis. Sie müssen, um mit Daten zu sprechen, keine Programmiersprache perfekt beherrschen, sondern nur genügend gut, um die Informationen zu erhalten, die Sie interessieren.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basics Programmieren</span>"
    ]
  },
  {
    "objectID": "r/programmieren.html#weshalb-programmieren-als-psychologin",
    "href": "r/programmieren.html#weshalb-programmieren-als-psychologin",
    "title": "3  Basics Programmieren",
    "section": "",
    "text": "“Psychologie erforscht das menschliche Erleben und Verhalten – sie untersucht, beschreibt und erklärt psychische Phänomene wie Gefühle, Entscheidungen, Gedanken, Motivationen oder Erinnerungen.”1\n\n\n\nWenn wir Daten verstehen wollen, müssen wir mit ihnen sprechen. Und eine Sprache, die uns dies ermöglicht, ist R.\n\n\n\ndie Qualität von Studien und einzelnen Aussagen kritisch zu hinterfragen und einzuordnen.\nzu beurteilen, ob erhobene Daten, das statistische Verfahren und die wissenschaftliche Aussage zueinander passen.\nDaten selbstständig zu erheben und zu analysieren, um wissenschaftliche Aussagen machen zu können zu den interessierenden Fragen in allen Feldern der Psychologie.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basics Programmieren</span>"
    ]
  },
  {
    "objectID": "r/programmieren.html#wichtige-aspekte-von-programmiersprachen",
    "href": "r/programmieren.html#wichtige-aspekte-von-programmiersprachen",
    "title": "3  Basics Programmieren",
    "section": "3.2 Wichtige Aspekte von Programmiersprachen",
    "text": "3.2 Wichtige Aspekte von Programmiersprachen\nR ist eine Programmiersprache, wie beispielsweise auch Python, C, Java, MATLAB, etc. Wie gesprochene Sprachen (z.B. Englisch und Deutsch) haben Programmiersprachen andere Wörter aber ähnliche Strukturen. (Wenn Sie R lernen, wird es Ihnen also auch einfacher fallen andere Programmiersprachen zu erlernen.) Zudem erlernt man durch das Programmieren, grössere Arbeitsschritte in kleinere aufzuteilen, sich gezielt im Internet Hilfe zu suchen, Lösungen zu überprüfen und logisch vorzugehen.\n\nGrundsätzlich besteht Code aus Text welcher ausgeführt wird.\nAnders als bei gesprochenen Sprachen ist beim Programmieren fehlerfreier Text sehr wichtig. Wenn ein Funktionsname falsch geschrieben oder ein falsches Zeichen verwendet wird, kann der Code nicht ausgeführt werden oder falsche Ergebnisse produzieren. Ein häufiger Fehler ist auch, dass eine Klammer geöffnet ( aber nicht wieder geschlossen ) wird. Im Gegensatz zu anderen Programmiersprachen sind in R Einrückungen oder Leerzeichen irrelevant und werden nicht beachtet.\nProgrammiersprachen enthalten verschiedene Bausteine wie Funktionen, Argumente, Abläufe (z.B. loops/Schleifen), Bedingungen (conditional statements), Objekte (variables), etc., die in einer bestimmten Form/Reihenfolge aufgeschrieben werden. Sobald das Grundprinzip dieser Bausteine verinnerlicht wurde, wird die Anwendung von Programmiersprachen sehr viel einfacher. Dieses Wissen kann auch auf andere Programmiersprachen übertragen werden.\nIndem man sich an gewisse Konventionen bei der Speicherung von Code und Variablen hält, bleibt ein Skript übersichtlich und der Code ist leichter lesbar. In diesem Kurs verwenden wir R mit R-Projects und Notebooks, so dass die Datei-Struktur immer ähnlich aufgebaut ist. Zudem benennen wir Variablen nach bestimmten Regeln, um den Überblick zu behalten.\nZuletzt ist es wichtig zu wissen, was zu tun ist, wenn der Code nicht läuft. Debugging bedeutet, dass man sich auf die Fehlersuche macht, weshalb z.B. ein Code nicht ausgeführt werden kann. Niemand schreibt fehlerfreien Code, oft entsteht Code durch trial and error. Fehlermeldungen sind also kein Grund zur Sorge, sondern ein wichtiger Bestandteil der Arbeit mit R und geben Hinweise, wo und wie man den Code anpassen muss.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basics Programmieren</span>"
    ]
  },
  {
    "objectID": "r/programmieren.html#bausteine-von-programmiersprachen",
    "href": "r/programmieren.html#bausteine-von-programmiersprachen",
    "title": "3  Basics Programmieren",
    "section": "3.3 Bausteine von Programmiersprachen",
    "text": "3.3 Bausteine von Programmiersprachen\nIn diesem Unterkapitel werden die wichtigsten Bausteine von Programmiersprachen zusammengefasst. Es ist daher ok, wenn Sie zu Beginn nicht alles verstehen oder anwenden können. Sie können dieses Kapitel nutzen, um nachzuschlagen wie etwas funktioniert, sobald wir darauf stossen.\nGrundsätzlich gilt:\n\n«To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call.» J. M. Chambers2\n\nEs gibt also wichtige Grundbausteine, Objekte und Funktionsaurufe, die etwas mit diesen Objekten tun.\n\nObjekte können erstellt und benannt, sowie bearbeitet werden. Beispiele dafür sind eine Variable, ein Datensatz.3\nAufrufen von Funktionen lassen etwas passieren. Beispiele dafür ist das Verwenden von mathematischen Operatoren (sqrt() berechnet die Wurzel einer Zahl) oder das Aufrufen der Funktion lm(), die ein lineares Modell berechnet.\n\nIn den folgenden Unterkapiteln wird auf folgende wichtige Bausteine in R eingegangen:\n\nPackages\nVariablen\nDatensätze\nMathematische Operatoren\nLogische Operatoren\n\n\n3.3.1 Packages\nPackages sind Sammlungen von Funktionen, die für das Programmieren genutzt werden können. Packages können mit der Funktion install.packages() installiert und mit der Funktion library() geladen werden.\nEin Beispiel für ein Package ist das {tidyverse}. Es enthält eine Sammlung von verschiedenen, für Data Science sehr geeigneten Funktionen, welche viele Schritte der Datenverarbeitung ermöglichen und vereinfachen.\n\nMehr Informationen zum tidyversefinden Sie hier.\n\nDas tidyverse kann direkt in R heruntergeladen werden:\n\n# Download und installieren des Packages (nur einmal in der Konsole ausführen)\ninstall.packages(\"tidyverse\")\n\nEin Package muss nur einmal heruntergeladen und installiert werden, danach ist es lokal auf dem Computer gespeichert. Aber: Jedes Mal wenn RStudio geöffnet wird, müssen Packages wieder neu geladen werden.\n\n# Package laden (bei jedem Öffnen von R zu Beginn des Skripts ausführen)\nlibrary(\"tidyverse\") \n\n\nSobald ein Package installiert ist, können die Funktionen auch verwendet werden ohne, dass das ganze Package mit library() geladen wird, indem die Funktion mit dem Package-Namen zusammen aufgerufen wird: packagename::packagefunction(). Dies macht Sinn, wenn verschiedene Packages dieselben Namen für verschiedene Funktionen nutzen und es so zu Konflikten kommt oder wenn nur eine Funktion aus einem Package verwendet werden soll und alle anderen sowieso nicht gebraucht werden.\n\n# Aufrufen Funktion aus Package ohne Laden\ntidyverse::tibble()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Mathematische Operatoren\nR kann als einfacher Rechner verwendet werden, wenn man die Konsole oder die Rechnung in einem Skript / RNotebook ausführt.\n\n1+1-4*2/15\n\n[1] 1.466667\n\n\nNach Ausführen des Codes wird unter der Konsole das Resultat - der Output - angezeigt. Die Zahl in Klammern, also [1] beschreibt die Zeilennummer. Dahinter wird der Output des ausgeführten Codes angezeigt.\n\n Konsole Tipp Lösung\n\n\nDer Code in der WebR-Konsole kann gelöscht und durch anderen Code ersetzt werden. Es können auch andere Operatoren (z.B. -, / oder *) oder Funktionen (wie sqrt()) genutzt werden.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nDrücken Sie Run Code.\n\n\n\n1+1-4*2/15\n\n[1] 1.466667\n\n\n\n\n\n\nDie WebR Konsole ergibt dieselben Outputs wie in RStudio, so kann auf der Website direkt Code geschrieben und ausgeführt werden, der auch in RStudio kopiert werden kann. Sobald ein grüner Pfeil und Run Code erscheint, ist WebR geladen und bereit. Mit Run Code kann der Code in der Konsole ausgeführt werden.\n\nIn dieser Tabelle finden Sie die wichtigsten mathematischen Operatoren. Am linken Rand wird die Zeilennummer des Codes angegeben analog zu einem RSkript oder RNotebook. Diese Zahl kann nicht geändert werden. Sie dient bei langem Code dazu sich zu orientieren oder den Fehler zu finden, wenn einer auftritt.\n\nMathematische Operatoren in R\n\n\n\n\n\n\n\n\nOperation\nOperator in Text\nOperator in R\nBeispielscode\n\n\n\n\nAddition\n+\n+\n3+2\n\n\nSubtraktion\n-\n-\n\n\n\nMultiplikation\n*\n*\n\n\n\nDivision\n/\n/\n\n\n\nPotenz\n^\n^\n3^2\n\n\nWurzel\n\\[\\sqrt{9}\\]\nsqrt()\nsqrt(9)\n\n\nExponentialfunktion\n\\[e^2\\]\nexp()\nexp(3)\n\n\nLogarithmus\n\\[log_{e}, log_{10}, log_{10}10\\]\nlog(), log10()\nlog(10), log10(10)\n\n\nTrigonometrische Funktionen\n\\[cos, sin, tan\\]\ncos(), sin(), tan()\ncos(2), sin(2), tan(2)\n\n\n\n\n\n Konsole Tipp Lösung\n\n\nGeben Sie in die Konsole folgende mathematische Operationen ein:\n\n\\(1+1+1\\)\n\\(5*5\\)\n\\(3*(4+3)\\)\n\\(1000/10^2\\)\n\\(\\sqrt{144}\\)\n\\(\\sin60\\)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSchauen Sie in der untenstehenden Tabelle Mathematische Operatoren in R nach.\n\n\n\n\n[1] 3\n\n\n[1] 25\n\n\n[1] 21\n\n\n[1] 10\n\n\n[1] 12\n\n\n[1] -0.3048106\n\n\n\n\n\n\n\n\n\n\n\n3.3.3 Variablen in R\nObjekte können in R erstellt werden indem einer der beiden Zuweisungsoperatoren = oder &lt;- genutzt wird. In diesem Kurs arbeiten wir vor allem mit &lt;-.4 In den meisten Fällen ergibt = jedoch dasselbe Ergebnis.\nVor dem Zuweisungsoperator steht der Variablenname. Nach dem Zuweisungsoperator steht der Variablenwert bzw. die -werte.\n\nEinfache Variablen: Vektoren\nDie simpelsten Objekte in R sind Vektoren. Man kann sich dies vorstellen wie einen Wert (z.B. eine Zelle) oder eine Reihe von Werten (z.B. eine Spalte) einer Exceltabelle. Ein Vektor kann keinen, einen oder mehrere Werte enthalten. Matrizen können mehrere Vektoren desselben Datentyps kombinieren (z.B. mehrere Spalten in einer Exceltabelle). Datensätze (data.frame oder tibble) können Variablen unterschiedlicher Typen kombinieren. Es können also Buchstaben und Zahlen gemischt werden.\nEine neue Variable kann mit einem Zuweisungsoperator erstellt werden.\nHier ein paar Beispiele:\n\na &lt;- 5 # Variable namens a mit dem Wert 5\nb = 5 # Variable namens b mit dem Wert 5\nc &lt;- 6.45 # Variable namens c mit dem Wert 6.45\nd &lt;- 5*3 # Variable namens d mit dem Wert ?\n\nFür das Erstellen der Variable muss der Code nicht nur geschrieben, sondern auch ausgeführt werden. Durch das Ausführen wird dem Objektnamen a den Wert 5 zugewiesen. Variablen können abgerufen werden, indem ihr Name eingegeben und ausgeführt wird:\n\na\n\n[1] 5\n\n\nDiese Variable bleibt gespeichert/abrufbar, bis das Environment wieder gelöscht wird. Sie kann auch überschrieben werden.\n\na &lt;- 10\na\n\n[1] 10\n\n\n\n Konsole Tipp Lösung\n\n\n\nErstellen Sie die obigen Variablen a,b, c und d.\nRufen Sie die Variablen auf: Was haben Sie für Werte?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSetzen Sie vor dem Pfeil den Variablennamen ein.\nSetzen Sie nach dem Pfeil den Variablenwert ein.\nDrücken Sie Run Code.\n\n\n\na &lt;- 5\nb &lt;- 5\nc &lt;- 6.45\nd &lt;- 5*3\n\n\n\n\nWird eine Variable aufgerufen, die nicht existiert, wird die Fehlermeldung Error: object 'x' not found ausgegeben. Das bedeutet, dass die Variable x nicht auffindbar ist und daher nicht angezeigt werden kann.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nVariablen können auch mehrere Werte enthalten. Einen Weg mehrere Werte in einer Variable zu speichern ist die Funktion c() zu nutzen.5 Die Variable y &lt;- c(23, 45, 34) enthält die Werte 23, 45 und 34. Nicht numerische Werte, z.B. Wörter, werden jeweils in \"Anführungszeichen\" gesetzt: z &lt;- c(\"ja\", \"nein\", \"vielleicht\").\n\nFaktoren können mit der Funktion as.factor() erstellt werden. Wenn z.B. ja, nein und vielleicht als Faktoren gespeichert werden sollen lautet der Code z &lt;- as.factor(c(\"ja\", \"nein\", \"vielleicht\")).\n\n\n Konsole Tipp Lösung\n\n\nErstellen Sie eine Variable mit mehreren numerischen Werten und eine Variable mit mehreren Wörtern als Werte.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nFügen Sie in die Klammer mehrere Werte ein. Numerische Werte/Zahlen können einfach eingegeben werden. Kategorische Werte/Wörter hingegen müssen in Anführungszeichen (\" \") gesetzt werden.\nDrücken Sie Run Code.\n\n\n\nnumbers &lt;- c(23, 45, 34)\nwords &lt;- c(\"ja\", \"nein\", \"vielleicht\")\n\n\n\n\nVariablen können unterschiedliche Datentypen enthalten, z.B. Zahlen oder Wörter. Der Variablentyp (oder die Variablenklasse) entspricht dem zugewiesenen Wert bzw. den zugewiesenen Werten. Mit der Funktion class() kann erfragt werden, welchen Variablentyp eine Variable hat. In die Klammer wird der Variablennamen, also bspw. y eingesetzt.\n\n Konsole Tipp Lösung\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nDefinieren Sie eine Variable y.\nFügen Sie in die Klammer nach class den Variablennamen ein.\nSie können y &lt;- ... der nächsten Aufgabe kopieren und hier einsetzen, um sich den Variablentyp ausgeben zu lassen.\n\n\n\ny &lt;- c(23, 45, 34)\nclass(y)\n\n[1] \"numeric\"\n\n\n\n\n\n\n\n\n\n\n\n Quiz: Variablentyp\n\n\n\n\nWelcher Variablentyp hat die Variable y?\na.\ny &lt;- c(23, 34, 634, 234, 12, 34)\ncharacternumericfactorleer\nb.\ny &lt;- c(\"hallo\", \"a\", \"nein\")\ncharacternumericfactorleer\nc.\ny &lt;- 0\ncharacternumericfactorleer\nd.\ny &lt;- NULL\ncharacternumericfactorleer\ne.\ny &lt;- as.factor(c(\"blue\", \"red\", \"yellow\"))\ncharacternumericfactorleer\n\n\n\n\n\n\n3.3.4 Datensätze\nObjekte können nicht nur einen Vektor enthalten wie oben, sondern können auch ganze Datensätze sein. Also mehrere aneinandergereihte Vektoren (wie eine Exceltabelle). Datensätze können unterschiedliche Variablentypen enthalten.\n\n Konsole Tipp Lösung\n\n\nErstellen Sie einen Datensatz mit 3 Variablen:\n\nName: sub, Werte: sub-01, sub-02, sub-03, sub-04\nAlter: age, Werte: 43, 54, 33, 29\nKorrekte Antworten: accuracy, Werte: 89, 77, 95, 98\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nFügen Sie bei allen ___ die fehlenden Werte ein und drücken Sie Run Code.\n\n\n\nd &lt;- tibble(sub = c(\"sub-01\", \"sub-02\", \"sub-03\", \"sub-04\"),\n            age = c(43, 54, 33, 29),\n            accuracy = c(89, 77, 95, 98)\n            )\n\n\n\n\nZusammenfassend können Variablen keinen, mehrere oder einen Wert haben. Sie können unterschiedliche oder identische Datentypen beinhalten.\n\n\n\n\n\n\n\n3.3.5 Funktionen und Argumente\nFunktionen sind Befehle, die etwas ausführen. Um dies zu tun, wird der Funktionsname und in den Klammern die Argumente angegeben. Bei jeder Funktion ist definiert, ob und wenn ja welche Argumente eingegeben werden müssen. Hierbei gibt es Argumente die unbedingt benötigt werden, und solche, die weggelassen werden können, dann werden die Standardeinstellungen genommen.\nBeispiele für Funktionen\nDie Funktion mean()berechnet den arithmetischen Mittelwert. In der Dokumentation (also z.B. durch eingeben von ?mean() wird angegeben, dass mean() mindestens ein Argument benötigt, nämlich ein Objekt mit Zahlen darin: mean(x, ...). Um mehrere Zahlen als Objekt zu speichern, wird die column-Funktion c() verwendet.\n\nmean(c(105, 88, 115, 102, 104, 96, 85, 112, 98))\n\n[1] 100.5556\n\n\nOder wir können mit der Funktion c() einen numerischen Vektor erstellen, und dann diesen Vektor als Argument verwenden:\n\n# mean with a numeric vector\niq &lt;- c(105, 88, 115, 102, 104, 96, 85, 112, 98)\nmean(iq)\n\n[1] 100.5556\n\n\n\n Konsole Tipp Lösung\n\n\nBerechnen Sie den arithmetischen Mittelwert von\n346, 56, 23, 85, 234, 8, 4, 812, 34\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nErstellen Sie zuerst mit c() einen numerischen Vektor.\nRufen Sie dann die Funktion mean() mit diesem Vektor als Argument auf.\n\n\n\nnum_var &lt;- c(346, 56, 23, 85, 234, 8, 4, 812, 34)\nmean(num_var)\n\n[1] 178\n\n\n\n\n\nWichtige Funktionen für statistische Berechnungen:\n\nmean(): berechnet den Mittelwert\nmedian(): berechnet den Median\nsd(): berechnet die Standardabweichung6\nvar(): berechnet die Varianz7\nsum(): berechnet die Summe\nmin(): extrahiert den kleinsten Wert\nmax(): extrahiert den grössten Wert\nscale(): z-transformiert die Daten\n\n\n\n\n\n\n\n Quiz: Funktionen nutzen\n\n\n\n\nDieser Code erstellt einen Variable mit 100 fiktiven IQ-Messungen.\n\ndata_iq &lt;- rnorm(100, mean = 100, sd = 15) # diese Zeile generiert 100 Messungen\n\nVerwenden Sie die Konsole, um die Variable data_iq zu erstellen mit dem obigen Code. Danach können Sie die Funktionen von oben nutzen um das Quiz zu beantworten.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\na. Was ist der Mittelwert der Daten?\nca. 50ca. 100ca. 1000\nb. Was ist der Median der Daten?\nca. 10ca. 50ca. 100\nc. Was ist die Standardabweichung der Daten?\nca. 15ca. 50ca. 100\nd. Was ist die der maximale Wert? (keine Quiz-Antwort möglich da Werte unterschiedlich)\ne. Was ist der minimale Wert? (keine Quiz-Antwort möglich da Werte unterschiedlich)\n\n\n\nAlles hinter dem # wird nicht ausgeführt, es dient als Kommentar. So kann beschrieben werden, was eine Zeile Code genau macht, ohne dass diese mit dem Code interferiert.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basics Programmieren</span>"
    ]
  },
  {
    "objectID": "r/programmieren.html#data-wrangling",
    "href": "r/programmieren.html#data-wrangling",
    "title": "3  Basics Programmieren",
    "section": "3.4 Data wrangling",
    "text": "3.4 Data wrangling\nDatensätze können in R einfach dargestellt und zusammengefasst werden.\nMit der Funktion glimpse() kann der Datensatz angeschaut werden\n\n Konsole Tipp Lösung\n\n\nSchauen Sie sich den oben erstellten Datensatz an.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nFalls d nicht angezeigt werden kann, erscheint die Fehlermeldung Error: object 'd' not found. Scrollen Sie nach oben und erstellen Sie den Datensatz dunter 3. Objekte in R.\nDrücken Sie Run Code.\n\n\n\nglimpse(d)\n\nRows: 4\nColumns: 3\n$ sub      &lt;chr&gt; \"sub-01\", \"sub-02\", \"sub-03\", \"sub-04\"\n$ age      &lt;dbl&gt; 43, 54, 33, 29\n$ accuracy &lt;dbl&gt; 89, 77, 95, 98\n\n\n\n\n\nZum Üben gibt es in R Datensätze, die immer verfügbar sind, z.B. cars. In diesem Datensatz von 1920 werden verschiedene Autos und ihre Eigenschaften beschrieben.\nMit summary() kann der Datensatz zusammengefasst werden, es werden automatisch die minimalen und maximalen Werte, Mittelwerte, etc. ausgegeben.\n\n Konsole Tipp Lösung\n\n\nSchauen Sie sich die Zusammenfassung von cars an:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nVerwenden Sie die Funktion summary().\nDrücken Sie Run Code.\n\n\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\n\n\n\nMit dem Operator $ kann eine einzelne Variable aus dem Datensatz ausgewählt werden.\n\n Konsole Tipp Lösung\n\n\nSchauen Sie sich die einzelnen Variablen von cars an.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nWählen Sie aus den oben angezeigten Variablen eine aus und setzen Sie sie nach dem $ ein.\nBeispiel: speed oder dist.\nDrücken Sie Run Code.\n\n\n\ncars$speed\n\n [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15\n[26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 24 25\n\n\noder\n\ncars$dist\n\n [1]   2  10   4  22  16  10  18  26  34  17  28  14  20  24  28  26  34  34  46\n[20]  26  36  60  80  20  26  54  32  40  32  40  50  42  56  76  84  36  46  68\n[39]  32  48  52  56  64  66  54  70  92  93 120  85",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basics Programmieren</span>"
    ]
  },
  {
    "objectID": "r/programmieren.html#datenvisualisieren",
    "href": "r/programmieren.html#datenvisualisieren",
    "title": "3  Basics Programmieren",
    "section": "3.5 Datenvisualisieren",
    "text": "3.5 Datenvisualisieren\nUm Grafiken zu erstellen gibt es in R einfache Befehle, wie\n\nplot()\nhist()\nboxplot()\n\n\nKomplexere und grafisch ansprechendere Plots können mit dem Package {ggplot2} erstellt werden. Cheatsheet für Interessierte\n\nIn die Grafikfunktionen können teilweise ganze Datensätze als Argument eingegeben werden. Meistens brauchen die Funktionen aber die genauen Variablen, die geplottet werden sollen als Argumente. Die einzelnen Variablen können mit dem $ spezifiziert werden (z.B. cars$speed).\n\n3.5.1 Scatterplot\nDie Funktion plot() macht einen Scatterplot, zeichnet also immer die ersten beiden Werte zweier Variablen als Punkt. Dann die zweiten zwei Werte, usw.\n\n Konsole Tipp Lösung\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSetzen Sie den Namen des Datensatzes (z.B.cars) ein.\nDrücken Sie Run Code.\n\n\n\nplot(cars)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.2 Histogramme\nDie Funktion hist() erstellt ein Histogramm. Dafür wird nur eine Variable benötigt. Es wird die Häufigkeit eines Werts in dieser Variable abgetragen.\n\n Konsole Tipp Lösung\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSetzen Sie den Namen des Datensatzes (z.B.cars) ein. Setzen Sie hinter dem $ einen Variablennamen ein.\nDrücken Sie Run Code.\n\n\n\nhist(cars$speed)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.3 Boxplots\nDie Funktion boxplot() erstellt ein Boxplot, mit Median und der 1. und 3. Quartile. Dafür wird nur eine Variable benötigt. Es kann aber auch ein Datensatz mit mehreren Variablen eingegeben werden. Dann werden mehrere Boxen geplottet.\n\n Konsole Tipp Lösung\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSetzen Sie den Namen des Datensatzes (z.B.cars) ein. Setzen Sie hinter dem $ einen Variablennamen ein um nur eine Variable zu plotten.\nDrücken Sie Run Code.\n\n\n\nboxplot(cars)",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basics Programmieren</span>"
    ]
  },
  {
    "objectID": "r/programmieren.html#footnotes",
    "href": "r/programmieren.html#footnotes",
    "title": "3  Basics Programmieren",
    "section": "",
    "text": "https://www.unilu.ch/studium/studienangebot/bachelor/vpf/psychologie/↩︎\nChambers, J.M.(2014): Object-Oriented Programming, Functional Programming and R. In: Statistical Science. Band 29, Nr. 2, S. 167–180, https://arxiv.org/abs/1409.3531↩︎\nAuch Funktionen sind Objekte. Das kann anfangs irritierend wirken, ist aber eigentlich recht logisch. Als Analogie: Auch wenn ein Rechner (Funktion) ein Objekt ist, kann damit gerechnet werden (Funktionsaufruf).↩︎\nDer Zuweisungsoperator &lt;- zeigt klarer als das = auf, dass ein Wert zugewiesen wird und ist daher intuitiver.↩︎\nc() ist wie die Plastikumhüllung für sechs Tetrapack Milch. Sie fasst einfach mehrere Werte zusammen und zeigt R, dass diese in eine Variable gehören. So können sechs Werte mit einem “Henkel” (Variablennamen) herumgetragen werden. ↩︎\nHier wird die geschätzte Standardabweichung berechnet mit \\(n-1\\)↩︎\nHier wird die geschätzte Varianz berechnet mit \\(n-1\\)↩︎",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basics Programmieren</span>"
    ]
  },
  {
    "objectID": "r/help.html",
    "href": "r/help.html",
    "title": "4  Help center",
    "section": "",
    "text": "4.1 Hilfe in R",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Help center</span>"
    ]
  },
  {
    "objectID": "r/help.html#hilfe-in-r",
    "href": "r/help.html#hilfe-in-r",
    "title": "4  Help center",
    "section": "",
    "text": "4.1.1 ?\nUm zu erfahren, was genau eine Funktion macht und welche Argumente sie benötigt, kann die leere Funktion mit einem Fragezeichen aufgerufen werden: ?cor(). Dies funktioniert nur, wenn das Package in dem sich die Funktion befindet geladen ist!\n\nWird zum Beispiel ?glimpse() eingegeben bevor das {tidyverse} geladen ist, gibt R eine Fehlermeldung aus.\n\n\n Konsole Tipp Lösung\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nWählen Sie eine Funktion aus und setzen Sie vorher ein ? ein.\nDrücken Sie Run Code.\n\n\n\n?cor()\n\nstarting httpd help server ... done\n\n\n\n\n\n\n\n4.1.2 HelpFenster in RStudio\nIm rechten unteren Quadranten finden Sie einen Reiter namens Help. Dort können Sie Namen von Packages oder Funktionen eingeben um zur Dokumentation zu gelangen.\n\n\n4.1.3 Autocomplete mit TabTab\nMit der Taste TabTab können Sie schauen, welche Vorschläge R Ihnen macht. So sehen Sie z.B. welche Argumente eine Funktion benötigt.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Help center</span>"
    ]
  },
  {
    "objectID": "r/help.html#bücher-und-tutorials",
    "href": "r/help.html#bücher-und-tutorials",
    "title": "4  Help center",
    "section": "4.2 Bücher und Tutorials",
    "text": "4.2 Bücher und Tutorials\nSehr geeignete Bücher und Websites sind im Folgenden aufgelistet. Der Vorteil dieser Quellen im Vergleich zu Suchmaschinen oder LLMs ist, dass die Informationen verifiziert sind.\n\nR for Data Science von Hadley Wickham\nData Skills for Reproducible Research\nIntroduction to R",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Help center</span>"
    ]
  },
  {
    "objectID": "r/help.html#suchmaschinen",
    "href": "r/help.html#suchmaschinen",
    "title": "4  Help center",
    "section": "4.3 Suchmaschinen",
    "text": "4.3 Suchmaschinen\nUm weiterzukommen ist es oft hilfreich Suchmaschinen zu nutzen (Fehlermeldung in Suchmaschine kopieren). Oft hatten andere vorher schon dasselbe Problem.\nSuchmaschinen eignen sich oft für das Beheben von Problemen in dem man z.B.\n\ndie Fehlermeldung kopiert und in einer Suchmaschine eingibt.\ndas Stichwort R und das Ziel (z.B. Zusammenfügen mehrerer Variablen zu einem Datensatz) eingibt (meistens erzielt man bessere Resultate, wenn man das Ziel in Englisch formuliert).\nForen für Programmierprobleme sind beispielsweise StackOverflow oder das Posit-Forum.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Help center</span>"
    ]
  },
  {
    "objectID": "r/help.html#llms",
    "href": "r/help.html#llms",
    "title": "4  Help center",
    "section": "4.4 LLMs",
    "text": "4.4 LLMs\nAuch ChatGPT zu fragen kann hilfreich sein (z.B. “Was bedeutet dieser Code? cor(x,y)”). Natürlich kann die Antwort von ChatGPT immer falsch sein und muss getestet und kritisch überprüft werden1.\nLLMs eignen sich oft zu Beginn nicht schlecht, da sie für “einfache” und “häufige” Probleme besser performen, als für Spezialfälle. Hierbei gilt es einige Punkte zu beachten:\n\nLLMs geben Code aus. Aber auch wenn dieser problemlos ausgeführt werden kann, muss trotzdem genau überprüft werden, ob der Code das richtige tut. Dieses Überprüfen kann unter Umständen genau so lange dauern, wie das Lesen und Verstehen der Dokumentation.\nDas Überprüfen von Code erfordert gewisse Grundkenntnisse. Das direkte Verwenden von Code ohne kompetente Prüfung ist in der Forschung unethisch!\nEs dürfen keine sensiblen Daten eingegeben werden.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Help center</span>"
    ]
  },
  {
    "objectID": "r/help.html#faq",
    "href": "r/help.html#faq",
    "title": "4  Help center",
    "section": "4.5 FAQ",
    "text": "4.5 FAQ\nHier finden Sie FAQs und Antworten dieses Kurses.",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Help center</span>"
    ]
  },
  {
    "objectID": "r/help.html#footnotes",
    "href": "r/help.html#footnotes",
    "title": "4  Help center",
    "section": "",
    "text": "↩︎",
    "crumbs": [
      "R und RStudio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Help center</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/workflow.html",
    "href": "datenverarbeitung/workflow.html",
    "title": "5  Workflow",
    "section": "",
    "text": "5.1 Datensatz-Formate\nDatensätze können im Long-Format und im Wide-Format formattiert sein.",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/workflow.html#datensatz-formate",
    "href": "datenverarbeitung/workflow.html#datensatz-formate",
    "title": "5  Workflow",
    "section": "",
    "text": "5.1.1 Long-Format\n\nJede Variable (jede gemessene Eigenschaft) entspricht einer Spalte (column)\nJede Messung entspricht einer Zeile (row)\n\nWird eine Variable innerhalb einer Person mehrmals gemessen (z.B. error), dann hat jede Messung eine neue Zeile und die anderen Variablenwerte werden wiederholt (z.B. id). Dieses Format eignet sich sehr gut für die Datenvisualisierung und für die Datenanalyse in R.\n\n\n5.1.2 Wide-Format\n\nJede Einheit hat eine Zeile (row)\nJede Messung entspricht einer Spalte (column)\n\nDieses Format eignet sich, um fehlende Werte schnell zu entdecken und um Daten einzugeben.\n\n\n\nLong und Wide Format",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/workflow.html#footnotes",
    "href": "datenverarbeitung/workflow.html#footnotes",
    "title": "5  Workflow",
    "section": "",
    "text": "Wickham, H., Çetinkaya-Rundel, M., Grolemund, G. (2025). R for Data Science (2e). https://r4ds.hadley.nz↩︎",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/readandwrite.html",
    "href": "datenverarbeitung/readandwrite.html",
    "title": "6  Datensätze einlesen und schreiben",
    "section": "",
    "text": "6.1 Einlesen mit dem GUI\nIm rechten oberen Quadranten unter dem Reiter Environment findet sich die Fläche Import Datset. Hier muss ausgewählt werden, welches Dateiformat der Datensatz hat. Danach können weitere Einstellungen vorgenommen werden, wie z.B. - soll die oberste Zeile als Variablennamen erkannt werden? - welche Trennzeichen (separators oder delimiters) sollen verwendet werden (z.B. ,) etc.\nDieses Vorgehen hat drei Vorteile:",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Datensätze einlesen und schreiben</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/readandwrite.html#einlesen-mit-dem-gui",
    "href": "datenverarbeitung/readandwrite.html#einlesen-mit-dem-gui",
    "title": "6  Datensätze einlesen und schreiben",
    "section": "",
    "text": "Die Funktion zum Einlesen muss nicht bekannt sein, RStudio übernimmt das.\nEine Direktansicht zeigt, wie der Datensatz mit den vorgenommenen Einstellungen aussehen würde.\nRStudio gibt zum Schluss automatisch Code aus, welcher verwendet wurde. Dieser kann für zukünftiges Einlesen dieses Datensatzes verwendet werden.",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Datensätze einlesen und schreiben</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/readandwrite.html#einlesen-mit-code",
    "href": "datenverarbeitung/readandwrite.html#einlesen-mit-code",
    "title": "6  Datensätze einlesen und schreiben",
    "section": "6.2 Einlesen mit Code",
    "text": "6.2 Einlesen mit Code\nDas Einlesen eines Datensatzes mit Code eignet sich vor allem für das Automatisieren des Vorgangs. Mit Code muss nicht jedesmal im GUI angeklickt werden wie der Datensatz eingelesen werden soll, sondern wird automatisch immer gleich und mit wenig Aufwand geladen.\n\n6.2.1 Einlesen eines .csv-Files\n\n# Einlesen eines .csv-Files\ndata_csv &lt;- read.csv(\"data/nameoftheCSVfile.csv\")\n\nWeitere Einstellungen:\n\nheader = FALSE: die oberste Zeile wird nicht als Variablennamen eingelesen (Standardeinstellung header = TRUE)\nsep = \";\": ein Semikolon wird als Zellentrennungszeichen angenommen (Standardeinstellung sep = \",\")\n\n\n\n6.2.2 Einlesen eines .xlsx-Files\n\n# Einlesen eines .xlsx-Files\nlibrary(readxl)\ndata_xlsx &lt;- read_xlsx(\"data/nameoftheEXCELfile.xlsx\")\n\nWeitere Einstellungen:\n\ncol_names = FALSE: die oberste Zeile wird nicht als Variablennamen eingelesen (Standardeinstellung col_names = TRUE)\n\n\n\n6.2.3 Funktionen zum Einlesen von Datensätzen\n\nEinlesen von Datensätzen\n\n\n\n\n\n\n\n\n\nDateiformat\nImport Dataset (GUI)\nCode (Funktion)\nCode (Argumente)\nCode-Beispiel\n\n\n\n\n.csv\nFrom text\nread.csv()\nfile, (header), (sep), …\nread.csv(file = \"data/datafile.csv\")\n\n\n.xlsx\nFrom Excel\nreadxl::read_xlsx()\npath, (sheet), (col_names), …\nreadxl::read_xlsx(path = \"data/datafile.xlsx\")\n\n\n.sav\nFrom SPSS\nhaven::read_sav()\nfile, …\nhaven::read_sav(file = \"data/datafile.sav\")\n\n\n.txt\nFrom text\nread.delim()\nfile, (delim), (col_names)\nread.delim(file = \"data/datafile.txt\")\n\n\n.sas7bdat\nFrom SAS\n…\n\n\n\n\n.dta\nFrom Stata\n…\n\n\n\n\n\n\n\n\n\n\n\nEinlesen eines Datensatzes\n\n\n\n\nÖffnen Sie Ihr RProjekt introduction_to_r auf Ihrem Computer und öffnen Sie Ihr RNotebook intro_datawangling. Falls Sie kein RProjekt und RNotebook mit diesem Namen haben, folgen Sie den Anweisungen im Kapitel: Basics R und RStudio.\nLaden Sie den Datensatz herunter und speichern Sie ihn im data-Ordner Ihres RProjekts.\n\nreadingskills.csv 1\n\nLesen Sie den Datensatz ein über Import Dataset oder mit read.csv().\nChecken Sie, ob das Einlesen einwandfrei geklappt hat, indem Sie den Datensatz unter Environment anwählen oder mit dem untenstehenden Code:\n\n\nlibrary(tidyverse)\nglimpse(___)",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Datensätze einlesen und schreiben</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/readandwrite.html#datensätze-speichern-write.csv",
    "href": "datenverarbeitung/readandwrite.html#datensätze-speichern-write.csv",
    "title": "6  Datensätze einlesen und schreiben",
    "section": "6.3 Datensätze speichern: write.csv()",
    "text": "6.3 Datensätze speichern: write.csv()\nMit der Funktion write.csv() kann eine neue Datei geschrieben werden. Hierzu braucht die Funktion den Datensatz sowie den Namen und Pfad der neuen Datei. Das Argument row.names = FALSE verhindert, dass eine Spalte Zeilennummern eingefügt wird.\n\nwrite.csv(d, file = \"data/neuerdatensatz.csv\", row.names = FALSE)",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Datensätze einlesen und schreiben</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/readandwrite.html#footnotes",
    "href": "datenverarbeitung/readandwrite.html#footnotes",
    "title": "6  Datensätze einlesen und schreiben",
    "section": "",
    "text": "Der Datensatz ist Teil des Packages {betareg}. Quelle: Smithson M, Verkuilen J (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.↩︎",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Datensätze einlesen und schreiben</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html",
    "href": "datenverarbeitung/transform.html",
    "title": "7  Datensätze bearbeiten",
    "section": "",
    "text": "7.0.1 Laden der notwendigen Packages und Daten\nZu Beginn muss das {tidyverse} geladen und der Beispielsdatensatz eingelesen werden.\nlibrary(tidyverse)\nd &lt;- read.csv(\"data/readingskills.csv\")",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#datensatz-kennenlernen-und-anschauen",
    "href": "datenverarbeitung/transform.html#datensatz-kennenlernen-und-anschauen",
    "title": "7  Datensätze bearbeiten",
    "section": "7.1 Datensatz kennenlernen und anschauen",
    "text": "7.1 Datensatz kennenlernen und anschauen\nBei der Arbeit mit einem neuen Datensatz ist es wichtig, sich zu Beginn mit den enthaltenen Daten bekannzumachen. Hierzu können folgende Fragen gestellt werden:\n\nWelche Variablen sind enthalten?\nWelche Informationen enthalten diese?\nWelches Format haben sie? (Skalenniveau, Variablentyp)\nWas sind die maximal / minimal möglichen Werte?\nWie sind nicht vorhandene Werte codiert?\nIst der Datensatz im Long-Format oder im Wide-Format oder gemischt aufgebaut?\n\nIm Idealfall besteht ein Data Dictionary, welches diese Informationen kurz und knapp zusammenfasst.\n\n\n\n\n\n\nDatensatz readingskills.csv\n\n\n\nIn diesem Kapitel wird der Beispielsdatensatz readingskills.csv verwendet.\nDer Datensatz stammt aus dem Package {betareg}.\nEr enthält Daten von 44 Kindern im Alter zwischen acht und zwölf Jahren über die Lesegenauigkeit, IQ-Wert aus einem nonverbalen Intelligenztest, und ob sie Dyslexie haben oder nicht.1\n\nData-Dictionary des readingskills-Datensatzes\n\n\n\n\n\n\n\n\n\n\n\nvariable\nlabel\ntype\nvalues\nsource\ntransformations\nmissings\n\n\n\n\nparticipant identification\nid\ncharacter, factor\n\"sub-01\" to \"sub-44\"\nraw\nanonymized variable “participant”\nNA\n\n\ndyslexia diagnosis\ndyslexia\ncharacter, factor\n\"no\", \"yes\"\nraw\n\nNA\n\n\nz-score in nonverbal IQ-test\niq_zscore\nnumeric\napprx. -2 to 2\nraw\nz-transformed\nNA\n\n\nreading performance\naccuracy\nnumeric\n0 to 1\nraw\ntransformed from points to proportion\nNA\n\n\n\nDer Datensatz wurde für dieses Kapitel noch mit einer zusätzlichen Variable und zwei zusätzlichen Versuchspersonen ergänzt. Finden Sie diese?\n\n\nUm den Datensatz zu erkunden, gibt es viele verschiedene Wege.\n\n7.1.1 Datensatz erkunden im GUI\nDer Datensatz kann angeschaut werden, in dem im Environment-Fenster darauf geklickt wird:\n\nBei Klick auf das blaue Dreieck, erscheint eine Liste mit den Variablen.\nBei Doppelklick auf den Datensatz, wird eine Tabelle geöffnet.\n\nPraktisch ist hier, dass die Variablen in der Tabelle ein Format haben, dass man sich von anderen Tabellenverarbeitungsprogrammen, wie z.B. Excel, gewöhnt ist. Variablen können so auch mit wenig Aufwand der Grösse nach geordnet werden.\n\n\n7.1.2 Datensatz erkunden durch Aufrufen des Datensatznamens\nDer Datensatz kann durch Aufrufen des Datensatznames in die Konsole ausgeben werden:\n\nd\n\n       id dyslexia iq_zscore accuracy name\n1  sub-01       no     0.827  0.88386   ZU\n2  sub-02       no     0.590  0.76524   SD\n3  sub-03       no     0.471  0.91508   VE\n4  sub-04       no     1.144  0.98376   WE\n5  sub-05       no    -0.676  0.88386   WD\n6  sub-06       no    -0.795  0.70905   TE\n7  sub-07       no    -0.281  0.77148   GW\n8  sub-08       no    -0.914  1.00000   QS\n9  sub-09       no    -0.043  1.00000   XC\n10 sub-10       no     0.907  1.00000   WS\n11 sub-11       no     0.511  1.00000   DD\n12 sub-12       no     1.223  1.00000   HR\n13 sub-13       no     0.590  1.00000   VE\n14 sub-14       no     1.856  1.00000   AM\n15 sub-15       no    -0.399  1.00000   AH\n16 sub-16       no     0.590  1.00000   ER\n17 sub-17       no    -0.043  0.70281   ZW\n18 sub-18       no     1.738  1.00000   BE\n19 sub-19       no     0.471  0.66535   WE\n20 sub-20       no     1.619  1.00000   EH\n21 sub-21       no     1.144  0.95878   IA\n22 sub-22       no    -0.201  1.00000   AD\n23 sub-23       no    -0.281  0.73402   PW\n24 sub-24       no     0.590  0.64662   AO\n25 sub-25       no     1.777  1.00000   EP\n26 sub-26      yes    -0.083  0.57794   DE\n27 sub-27      yes    -0.162  0.64038   AS\n28 sub-28      yes    -0.795  0.45932   LA\n29 sub-29      yes    -0.281  0.65286   RG\n30 sub-30      yes    -0.874  0.60916   AL\n31 sub-31      yes     0.313  0.60916   IF\n32 sub-32      yes     0.709  0.54048   PF\n33 sub-33      yes     1.223  0.57170   BN\n34 sub-34      yes    -1.230  0.70281   NO\n35 sub-35      yes    -0.162  0.56546   IS\n36 sub-36      yes    -0.993  0.53424   IV\n37 sub-37      yes    -1.191  0.57794   ML\n38 sub-38      yes    -1.745  0.69032   OW\n39 sub-39      yes    -1.745  0.54673   MF\n40 sub-40      yes    -0.439  0.68408   LK\n41 sub-41      yes    -1.666  0.59043   MW\n42 sub-42      yes    -1.507  0.62165   ME\n43 sub-43      yes    -0.518  0.67159   QE\n44 sub-44      yes    -1.270  0.66535   DF\n45 sub-98      yes        NA  3.00000   PE\n46   &lt;NA&gt;       no     0.300  0.70000   KW\n47 sub-99       no     0.400 99.00000   TS\n\n\n\n\n7.1.3 Datensatz erkunden mit Funktionen\nNützliche Funktionen zum Erkunden eines Datensatzes sind zudem glimpse()\n\nglimpse(d)\n\nRows: 47\nColumns: 5\n$ id        &lt;chr&gt; \"sub-01\", \"sub-02\", \"sub-03\", \"sub-04\", \"sub-05\", \"sub-06\", …\n$ dyslexia  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ iq_zscore &lt;dbl&gt; 0.827, 0.590, 0.471, 1.144, -0.676, -0.795, -0.281, -0.914, …\n$ accuracy  &lt;dbl&gt; 0.88386, 0.76524, 0.91508, 0.98376, 0.88386, 0.70905, 0.7714…\n$ name      &lt;chr&gt; \"ZU\", \"SD\", \"VE\", \"WE\", \"WD\", \"TE\", \"GW\", \"QS\", \"XC\", \"WS\", …\n\n\nund head().\n\nhead(d)\n\n      id dyslexia iq_zscore accuracy name\n1 sub-01       no     0.827  0.88386   ZU\n2 sub-02       no     0.590  0.76524   SD\n3 sub-03       no     0.471  0.91508   VE\n4 sub-04       no     1.144  0.98376   WE\n5 sub-05       no    -0.676  0.88386   WD\n6 sub-06       no    -0.795  0.70905   TE\n\n\n\n\n7.1.4 Datensatz erkunden durch Zusammenfassen\nMit der Funktion summary()kann eine kurze Übersicht über den Datensatz erstellt werden:\n\nsummary(d)\n\n      id              dyslexia           iq_zscore          accuracy      \n Length:47          Length:47          Min.   :-1.7450   Min.   : 0.4593  \n Class :character   Class :character   1st Qu.:-0.7652   1st Qu.: 0.6310  \n Mode  :character   Mode  :character   Median :-0.0630   Median : 0.7090  \n                                       Mean   : 0.0152   Mean   : 2.9113  \n                                       3rd Qu.: 0.5900   3rd Qu.: 1.0000  \n                                       Max.   : 1.8560   Max.   :99.0000  \n                                       NA's   :1                          \n     name          \n Length:47         \n Class :character  \n Mode  :character",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#einzelne-variablen-ausgeben",
    "href": "datenverarbeitung/transform.html#einzelne-variablen-ausgeben",
    "title": "7  Datensätze bearbeiten",
    "section": "7.2 Einzelne Variablen ausgeben",
    "text": "7.2 Einzelne Variablen ausgeben\nEinzelne Variablen können angeschaut werden, indem das $ Zeichen verwendet wird:\n\nd$id\n\n [1] \"sub-01\" \"sub-02\" \"sub-03\" \"sub-04\" \"sub-05\" \"sub-06\" \"sub-07\" \"sub-08\"\n [9] \"sub-09\" \"sub-10\" \"sub-11\" \"sub-12\" \"sub-13\" \"sub-14\" \"sub-15\" \"sub-16\"\n[17] \"sub-17\" \"sub-18\" \"sub-19\" \"sub-20\" \"sub-21\" \"sub-22\" \"sub-23\" \"sub-24\"\n[25] \"sub-25\" \"sub-26\" \"sub-27\" \"sub-28\" \"sub-29\" \"sub-30\" \"sub-31\" \"sub-32\"\n[33] \"sub-33\" \"sub-34\" \"sub-35\" \"sub-36\" \"sub-37\" \"sub-38\" \"sub-39\" \"sub-40\"\n[41] \"sub-41\" \"sub-42\" \"sub-43\" \"sub-44\" \"sub-98\" NA       \"sub-99\"",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#verwenden-der-pipe-oder",
    "href": "datenverarbeitung/transform.html#verwenden-der-pipe-oder",
    "title": "7  Datensätze bearbeiten",
    "section": "7.3 Verwenden der Pipe: |> oder %>%",
    "text": "7.3 Verwenden der Pipe: |&gt; oder %&gt;%\nIn R kann die Pipe verwendet werden, um mehrere Datenverarbeitungsschritte aneinander zu hängen. Damit spart man sich aufwändige Zwischenschritte und vermeidet das Erstellen von immer neuen Datensätzen. Statt zwei einzelne Datenverarbeitungsschritte zu machen wie oben, können mehrere Schritte (hier Daten einlesen und anzeigen) zusammengefasst werden, in dem nach Zeilenende eine Pipe eingefügt wird:\n\nWann Pipes ungeeignet sind wird hier beschrieben.\n\n\nd &lt;- read.csv(\"data/readingskills.csv\") |&gt;\n    glimpse()\n\nDie Base R Pipe |&gt; und die magritter Pipe %&gt;%_ unterscheiden sich nur in Details. Für dieses Kapitel spielt es keine Rolle, welche Pipe verwendet wird.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nAchtung: Wenn zu Beginn ein &lt;- oder = verwendet wird, wird alles was nach der Pipe kommt den Datensatz verändern. Wird z.B. der Code …\n\nd &lt;- read.csv(\"data/readingskills.csv\") |&gt;\n    head()\n\n…eingegeben, besteht der Datensatz d dann nur noch aus 6 Zeilen, weil head() nur die obersten 6 Zeilen anzeigt.\nWird die Pipe ohne &lt;- oder = verwendet, bleibt der Datensatz unverändert:\n\nd |&gt;\n    head()",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#datensatz-bearbeiten-oder-neuer-datensatz-erstellen",
    "href": "datenverarbeitung/transform.html#datensatz-bearbeiten-oder-neuer-datensatz-erstellen",
    "title": "7  Datensätze bearbeiten",
    "section": "7.4 Datensatz bearbeiten oder neuer Datensatz erstellen",
    "text": "7.4 Datensatz bearbeiten oder neuer Datensatz erstellen\nDer Datensatz kann, z.B. für das Visualisieren oder für die Analyse, verändert werden. Hierbei kann entweder der bestehende Datensatz, also d, überschrieben werden, oder es kann eine neuer Datensatz erstellt werden.\n\nWird der eingelesene Datensatz angepasst, wird keine Veränderung an der Datensatz-Datei (z.B. readingskills.csv) vorgenommen. Um diese zu verändern, muss eine neue Datei geschrieben werden, z.B. mit write.csv().).",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#variablen-auswählen-select",
    "href": "datenverarbeitung/transform.html#variablen-auswählen-select",
    "title": "7  Datensätze bearbeiten",
    "section": "7.5 Variablen auswählen: select()",
    "text": "7.5 Variablen auswählen: select()\nEin komplexer Datensatz mit sehr vielen Variablen wird oft für die Analyse aus Gründen der Einfachheit oder Anonymisierung reduziert. Das bedeutet, dass man die nötigen Variablen auswählt, und nur mit diesem reduzierten Datensatz weiterarbeitet. Hierzu eignet sich die Funktion select() sehr gut: Mit select(.data, variablenname, ...) können die zu behaltenden Variablen ausgewählt werden. Wird ein ! vor einen Variablennamen gesetzt, wird die Variable nicht behalten, sondern alle anderen Variablen bleiben im Datensatz.\nMit select() können Variablen innerhalb des Datensatzes sortiert und umbenannt werden, damit der Datensatz so strukturiert ist, dass er sich für die Analyse/Visualisierung eignet.\nBeispiele:\n\n# Variablen id und accuracy behalten ohne Pipe\nd_simpler &lt;- select(d, id, accuracy)\n\n# Variablen id und accuracy behalten mit Pipe\nd_simpler &lt;- d |&gt; select(id, accuracy)\n\n# Variablen id und accuracy mit umgekehrter Reihenfolge behalten mit Pipe\nd_simpler &lt;- d |&gt; select(accuracy, id)\n\n# alle Variablen ausser id behalten\nd_simpler &lt;- d |&gt; select(!id)\n\n# Variablennamen verändern\nd_simpler &lt;- d |&gt; select(iq_value = iq_zscore)\n\nSollen mehrere Variablen am Stück ausgewählt werden, kann die erste Variable in der Reihe (z.B. word) und die letzte in der Reihe (z.B. congruent) als word:congruent eingeben, dann werden auch alle dazwischen liegenden Variablen ausgewählt.\n\nd_simpler &lt;- d |&gt; select(id:accuracy)\n\n\n\n\n\n\n\nHands-on: Variablen auswählen\n\n\n\nVariablen, die nicht verwendet werden aber persönliche Informationen enthalten, können zur Anonymisierung entfernt werden. Welche Variable wurde zum Originaldatensatz hinzugefügt und könnte (wenn sie nicht erfunden wäre) persönliche Informationen der Kinder enthalten, die für die weiteren Analysen nicht nötig sind?\nÜberschreiben Sie den Datensatz d mit einer anonymisierten Version.\nUntenstehend finden Sie ein Beispiel, wie der Datensatz danach aussehen könnte.\n\n\n\n\n\n\n\n\nLösung: Variablen auswählen\n\n\n\n\n\nDie Variable name enthält persönliche Angaben, die irrelevant für die Datenanalyse/-visualisierung sind.\n\nd &lt;- d |&gt;\n  select(id, \n         dyslexia, \n         iq_zscore, \n         accuracy)\nglimpse(d)\n\nRows: 47\nColumns: 4\n$ id        &lt;chr&gt; \"sub-01\", \"sub-02\", \"sub-03\", \"sub-04\", \"sub-05\", \"sub-06\", …\n$ dyslexia  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ iq_zscore &lt;dbl&gt; 0.827, 0.590, 0.471, 1.144, -0.676, -0.795, -0.281, -0.914, …\n$ accuracy  &lt;dbl&gt; 0.88386, 0.76524, 0.91508, 0.98376, 0.88386, 0.70905, 0.7714…",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#messungen-auswählen-filter",
    "href": "datenverarbeitung/transform.html#messungen-auswählen-filter",
    "title": "7  Datensätze bearbeiten",
    "section": "7.6 Messungen auswählen: filter()",
    "text": "7.6 Messungen auswählen: filter()\nMit der Funktion filter() können bestimmte Beobachtungen oder Untergruppen ausgewählt werden. Hierfür muss in der Funktion filter(.data, filter, ...) der Datensatz, die betreffende Variable, sowie eine Bedingung eingegeben werden. Es wird die ganze Zeile im Datensatz behalten in der die Variable der angegebenen Bedingung entspricht.\nBeispiele:\n\n# nur Messungen (Zeilen) der Person sub-01 werden behalten\nd_filtered &lt;- filter(d, id == \"sub-01\")\n\n# dasselbe mit der Pipe\nd_filtered &lt;- d |&gt; filter(id == \"sub-01\")\n\n# nur Messungen (Zeilen) mit accuracy über 0.5 werden behalten\nd_filtered &lt;- d |&gt; filter(accuracy &gt; 0.5)\n\n# nur Messungen (Zeilen) der Kinder mit Dyslexie werden behalten\nd_filtered &lt;- d |&gt; filter(dyslexia == \"yes\")\n\n# nur Messungen (Zeilen) der Kinder die nicht Dyslexie: ja haben werden behalten\nd_filtered &lt;- d |&gt; filter(dyslexia != \"yes\")\n\n# nur Messungen (Zeilen) mit accuracy zwischen 0.5 und 0.8 werden behalten\nd_filtered &lt;- d |&gt; filter(accuracy &gt; 0.5 & accuracy &lt; 0.8)\n\n# nur Messungen (Zeilen) mit iq_zscore grösser oder gleich gross wie 1 behalten\nd_filtered &lt;- d |&gt; filter(iq_zscore &gt;= 1)\n\nEs kann auch mehrere Male hintereinander die filter()-Funktion aufgerufen werden:\n\n# mehrere Filter verwenden\nd_filtered &lt;- d |&gt; \n    filter(id != \"NA\") |&gt;\n    filter(iq_zscore &lt;= 1)\n\n\n\n\n\n\n\nHands-on: Daten filtern\n\n\n\nDrei Messungen (Zeilen) sind ungültig. Schauen Sie zuerst den Datensatz an, um zu erkennen, welche es sind.\nÜberschreiben Sie den Datensatz d und behalten Sie nur die gültigen Messungen (44 Messungen).\n\n\n\n\n\n\n\n\nLösung: Daten filtern\n\n\n\n\n\n\nd &lt;- d|&gt;\n  filter(id != \"NA\") |&gt;\n  filter(iq_zscore != \"NA\") |&gt;\n  filter(accuracy &lt;= 1)",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#neue-variablen-generieren-und-verändern-mutate-und-case_when",
    "href": "datenverarbeitung/transform.html#neue-variablen-generieren-und-verändern-mutate-und-case_when",
    "title": "7  Datensätze bearbeiten",
    "section": "7.7 Neue Variablen generieren und verändern: mutate() und case_when()",
    "text": "7.7 Neue Variablen generieren und verändern: mutate() und case_when()\nMit der mutate(.data, …) Funktion können im Datensatz neue Variablen generiert oder bestehende Varaiablen verändert werden.\nBeispiel:\n\n# Neue Variablen erstellen\nd_new &lt;- d |&gt;\n    mutate(num_variable = 1.434,\n           chr_variable = \"1.434\",\n           sum_of_variable = accuracy + 1,\n           copy_variable = accuracy)\n\n# Bestehende Variablen verändern\nd_new &lt;- d_new |&gt;\n    mutate(accuracy = accuracy * 100) # z.B. um Accuracy zu Percent correct zu transformieren\n\nMit case_when() kann eine neue Variable erstellt werden in Abhängigkeit von Werten anderer Variablen. Damit kann z.B. eine Variable passed erstellt werden, für alle Werte die genügend guten Leseresultate entsprechen.\nBeispiel:\n\nd_condvariable &lt;- d |&gt;\n    mutate(grade = case_when(accuracy &gt; 0.7 ~ \"passed\",\n                             accuracy &lt;= 0.7 ~ \"failed\",\n                             .default = NA))\n\nEs können immer auch vorher definierte Variablen eingesetzt werden in die Funktionen, solange die Variable den richtigen Variablentyp hat:\n\nCUTOFF = 0.7\n\nd_condvariable &lt;- d |&gt;\n    mutate(grade = case_when(accuracy &gt; CUTOFF ~ \"passed\",\n                             accuracy &lt;= CUTOFF ~ \"failed\",\n                             .default = NA))\n\n\n\n\n\n\n\nHands-on: Variablen generieren und verändern\n\n\n\n\nErstellen Sie im Datensatz d_grades eine neue Variable mit dem Namen researcher, den Ihren Namen enthält.\nErstellen Sie zudem eine Variable grade, mit pass für accuracy-Werten über 0.9 und mit fail für accuracy-Werten unter 0.9.\nSchauen Sie den Datensatz an: Wie viele Kinder hätten bestanden bei diesem Cut-off?\n\n\n\n\n\n\n\n\n\nLösung: Variablen generieren und verändern\n\n\n\n\n\n\nCUTOFF = 0.9\n\nd_grades &lt;- d |&gt;\n  mutate(\n    researcher = \"Vorname Nachname\",\n    grade = case_when(accuracy &gt; CUTOFF ~ \"pass\",\n                      accuracy &lt;= CUTOFF ~ \"fail\",\n                      .default = NA)\n  )\n\nd_grades$grade\n\n [1] \"fail\" \"fail\" \"pass\" \"pass\" \"fail\" \"fail\" \"fail\" \"pass\" \"pass\" \"pass\"\n[11] \"pass\" \"pass\" \"pass\" \"pass\" \"pass\" \"pass\" \"fail\" \"pass\" \"fail\" \"pass\"\n[21] \"pass\" \"pass\" \"fail\" \"fail\" \"pass\" \"fail\" \"fail\" \"fail\" \"fail\" \"fail\"\n[31] \"fail\" \"fail\" \"fail\" \"fail\" \"fail\" \"fail\" \"fail\" \"fail\" \"fail\" \"fail\"\n[41] \"fail\" \"fail\" \"fail\" \"fail\"",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#variablentyp-verändern-as.factor-as.numeric",
    "href": "datenverarbeitung/transform.html#variablentyp-verändern-as.factor-as.numeric",
    "title": "7  Datensätze bearbeiten",
    "section": "7.8 Variablentyp verändern: as.factor(), as.numeric(), …",
    "text": "7.8 Variablentyp verändern: as.factor(), as.numeric(), …\nVariablen können verschiedene Tyoen haben, sie können z.B. kategoriale (factor, character) oder numerische (integer, numeric, double) Informationen enthalten. Beim Einlesen “rät” R, welche Klasse eine Variable hat. Teilweise ist es praktisch dies zu ändern für die weitere Analyse.\nWenn wir eine Variable zu einem Faktor machen möchten, verwenden wir as.factor(). Dies macht z.B. Sinn, wenn die Versuchspersonennummer als Zahl eingelesen wurde. Um von einem Faktor zu einer numerischen Variable zu kommen, verwenden wir as.numeric().\n\n# Die Variable \"id\" zu einem Faktor machen\nd &lt;- d |&gt; \n    mutate(id = as.factor(id))\n\n\n\n\n\n\n\nHands-on: Variablentyp verändern\n\n\n\nSchauen Sie sich den Datensatz mit glimpse() an. Welche Variablentypen enthält Ihr Datensatz und was bedeuten Sie?\nVerändern Sie alle character-Variablen (chr) zu factor-Variablen.\nWieviele Levels haben die Variablen nun?\n\n\n\n\n\n\n\n\nLösung: Variablentyp verändern\n\n\n\n\n\n\nd &lt;- d |&gt; \n  mutate(id = as.factor(id),\n         dyslexia = as.factor(dyslexia))",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#daten-gruppieren-und-zusammenfassen-group_by-und-summarise",
    "href": "datenverarbeitung/transform.html#daten-gruppieren-und-zusammenfassen-group_by-und-summarise",
    "title": "7  Datensätze bearbeiten",
    "section": "7.9 Daten gruppieren und zusammenfassen: group_by() und summarise()",
    "text": "7.9 Daten gruppieren und zusammenfassen: group_by() und summarise()\nMit diesen beiden Funktionen könne Datensätze effizient gruppiert und zusammengefasst werden.\n\n# Nach Diagnose gruppieren und Accuracy zusammenfassen\nd |&gt; group_by(dyslexia) |&gt;\n    summarise(mean_acc = mean(accuracy),\n              sd_acc = sd(accuracy))\n\n# A tibble: 2 × 3\n  dyslexia mean_acc sd_acc\n  &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 no          0.905 0.129 \n2 yes         0.606 0.0637\n\n\n\n\n\n\n\n\nHands-on: Datensätze gruppieren und zusammenfassen\n\n\n\nErstellen Sie einen neuen Datensatz d_summary wie folgt:\n\nGruppieren Sie den Datensatz für Dyslexia (ja / nein)\nFassen Sie für diese Gruppen die durchschnittliche Accuracy und der durchschnittliche IQ-Wert zusammen sowie die Standardabweichungen zusammen.\n\nUnterscheiden sich die Accuracy und IQ-Werte zwischen den Gruppen?\n\n\n\n\n\n\n\n\nLösung: Datensätze gruppieren und zusammenfassen\n\n\n\n\n\n\nd_summary &lt;- d |&gt; \n  group_by(dyslexia) |&gt;\n  summarise(mean_acc = mean(accuracy),\n          sd_acc = sd(accuracy),\n          mean_iq = mean(iq_zscore),\n          sd_iq = sd(iq_zscore))\nd_summary\n\n# A tibble: 2 × 5\n  dyslexia mean_acc sd_acc mean_iq sd_iq\n  &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 no          0.905 0.129    0.497 0.819\n2 yes         0.606 0.0637  -0.653 0.838",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#datensatzformate-transformieren-pivot_wider-und-pivot_longer",
    "href": "datenverarbeitung/transform.html#datensatzformate-transformieren-pivot_wider-und-pivot_longer",
    "title": "7  Datensätze bearbeiten",
    "section": "7.10 Datensatzformate transformieren: pivot_wider() und pivot_longer()",
    "text": "7.10 Datensatzformate transformieren: pivot_wider() und pivot_longer()\n\n7.10.1 Wide zu Long transformieren\nEin Datensatz im Wide-Format kann mit pivot_longer() zu einem Datensatz im Long-Format verändert werden.\n\n# Wide Datensatz erstellen\nd_wide &lt;- tibble(\n  id = c(\"sub-01\", \"sub-02\"),\n  conditionA = c(1.85, 2.13),\n  conditionB = c(2.65, 2.11),\n  conditionC = c(1.64, 1.78)\n)\n\n# Zu Long transformieren\nd_long &lt;- d_wide |&gt;\n  pivot_longer(conditionA:conditionC, # Variablen zum zusammenfassen\n               names_to = \"condition\", # Neuer Variablenname Kategorien\n               names_prefix = \"condition\", # Entfernen aus Bezeichnung (optional)\n               values_to = \"error\") # Neuer Variablenname Werte\nd_long\n\n# A tibble: 6 × 3\n  id     condition error\n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;\n1 sub-01 A          1.85\n2 sub-01 B          2.65\n3 sub-01 C          1.64\n4 sub-02 A          2.13\n5 sub-02 B          2.11\n6 sub-02 C          1.78\n\n\n\n\n7.10.2 Long zu Wide transformieren\nEin Datensatz im Long-Format kann mit pivot_wider() zu einem Datensatz im Wide-Format verändert werden.\n\n# Wide Datensatz erstellen\nd_long &lt;- tibble(\n  id = c(\"sub-01\", \"sub-01\", \"sub-01\", \"sub-02\", \"sub-02\", \"sub-02\"),\n  condition = c(\"A\", \"B\", \"C\", \"A\", \"B\", \"C\"),\n  error = c(1.85, 2.65, 1.64, 2.13, 2.11, 1.78)\n)\n\n# Zu Wide transformieren\nd_wide &lt;- d_long |&gt;\n  pivot_wider(id_cols = id, # ID Variable\n              names_from = condition, # Variable mit Kategorien\n              names_prefix = \"condition\", # Namenszusatz (optional)\n              values_from = error # Variable mit Werten\n              )\nd_wide\n\n# A tibble: 2 × 4\n  id     conditionA conditionB conditionC\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 sub-01       1.85       2.65       1.64\n2 sub-02       2.13       2.11       1.78\n\n\n\n\n\nTransformation von Wide zu Long und von Long zu Wide mit der pivot-Funktion",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#datensätze-speichern-write.csv",
    "href": "datenverarbeitung/transform.html#datensätze-speichern-write.csv",
    "title": "7  Datensätze bearbeiten",
    "section": "7.11 Datensätze speichern: write.csv()",
    "text": "7.11 Datensätze speichern: write.csv()\n\n\n\n\n\n\nHands-on: Neuer Datensatz abspeichern\n\n\n\nSpeichern Sie den bearbeiteten Datensatz als Datei ab\n\nwrite.csv(d, \"data/readingskills_clean.csv\", row.names = FALSE)",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenverarbeitung/transform.html#footnotes",
    "href": "datenverarbeitung/transform.html#footnotes",
    "title": "7  Datensätze bearbeiten",
    "section": "",
    "text": "Smithson M, Verkuilen J (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.↩︎",
    "crumbs": [
      "Datenverarbeitung",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Datensätze bearbeiten</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html",
    "href": "datenanalyse/descriptive.html",
    "title": "8  Deskriptive Statistik",
    "section": "",
    "text": "8.0.1 Laden der notwendigen Packages und Daten\nZu Beginn muss das {tidyverse} geladen und der Beispielsdatensatz eingelesen werden. Die beiden Variablen id und dyslexia werden zu Faktoren transformiert.\nlibrary(tidyverse)\nd &lt;- read.csv(\"data/readingskills_clean.csv\") |&gt;\n  mutate(id = as.factor(id),\n         dyslexia = as.factor(dyslexia))\nglimpse(d)\n\nRows: 44\nColumns: 4\n$ id        &lt;fct&gt; sub-01, sub-02, sub-03, sub-04, sub-05, sub-06, sub-07, sub-…\n$ dyslexia  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ iq_zscore &lt;dbl&gt; 0.827, 0.590, 0.471, 1.144, -0.676, -0.795, -0.281, -0.914, …\n$ accuracy  &lt;dbl&gt; 0.88386, 0.76524, 0.91508, 0.98376, 0.88386, 0.70905, 0.7714…",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html#minimale-und-maximale-werte-min-und-max",
    "href": "datenanalyse/descriptive.html#minimale-und-maximale-werte-min-und-max",
    "title": "8  Deskriptive Statistik",
    "section": "8.1 Minimale und maximale Werte: min() und max()",
    "text": "8.1 Minimale und maximale Werte: min() und max()\nFür einzelne Variablen kann der minimale Wert und der maximale Wert ausgegeben werden:\n\nmin(d$accuracy)\n\n[1] 0.45932\n\nmax(d$accuracy)\n\n[1] 1\n\n\n\n\n\n\n\n\nHands-on: Minimale und maximale Werte\n\n\n\nWas passiert, wenn\n\nmin(d)\n\neingegeben wird? Was bedeutet die Fehlermeldung?",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html#lagemasse-mittelwert-und-median",
    "href": "datenanalyse/descriptive.html#lagemasse-mittelwert-und-median",
    "title": "8  Deskriptive Statistik",
    "section": "8.2 Lagemasse: Mittelwert und Median",
    "text": "8.2 Lagemasse: Mittelwert und Median\nFür einzelne Variablen kann der Mittelwert mit mean() und der Median mit median() ausgegeben werden.\n\nmean(d$accuracy)\n\n[1] 0.7757161\n\nmedian(d$accuracy)\n\n[1] 0.70593",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html#streumasse-standardabweichung-und-varianz",
    "href": "datenanalyse/descriptive.html#streumasse-standardabweichung-und-varianz",
    "title": "8  Deskriptive Statistik",
    "section": "8.3 Streumasse: Standardabweichung und Varianz",
    "text": "8.3 Streumasse: Standardabweichung und Varianz\nDie Standardabweichung kann mit sd() ausgegeben werden.\n\nsd(d$accuracy)\n\n[1] 0.1826967\n\n\nDie Varianz kann mit var() ausgegeben werden.\n\nvar(d$accuracy)\n\n[1] 0.03337808",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html#zusammenfassen-mit-summary",
    "href": "datenanalyse/descriptive.html#zusammenfassen-mit-summary",
    "title": "8  Deskriptive Statistik",
    "section": "8.4 Zusammenfassen mit summary()",
    "text": "8.4 Zusammenfassen mit summary()\nMit der Funktion summary() werden alle Variablen im Datensatz zusammengefasst.\n\nsummary(d)\n\n       id     dyslexia   iq_zscore             accuracy     \n sub-01 : 1   no :25   Min.   :-1.7450000   Min.   :0.4593  \n sub-02 : 1   yes:19   1st Qu.:-0.7950000   1st Qu.:0.6185  \n sub-03 : 1            Median :-0.1225000   Median :0.7059  \n sub-04 : 1            Mean   :-0.0000227   Mean   :0.7757  \n sub-05 : 1            3rd Qu.: 0.6197500   3rd Qu.:1.0000  \n sub-06 : 1            Max.   : 1.8560000   Max.   :1.0000  \n (Other):38                                                 \n\n\nUm die Werte als Variable zu erhalten, kann mit summary() ein Objekt erstellt und aufgerufen werden:\n\nd_summary &lt;- summary(d)\n\n\n\n\n\n\n\nHands-on: Summary\n\n\n\nWieso werden nicht für alle Variablen dieselben Informationen ausgegeben?\nFür welche Variablen gibt summary() folgende Informationen heraus:\n\nminimaler und maximaler Wert\nMittelwert und Median\nAnzahl der vorhandenen Messungen pro Faktorstufe",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html#zusammenfassen-mit-describe",
    "href": "datenanalyse/descriptive.html#zusammenfassen-mit-describe",
    "title": "8  Deskriptive Statistik",
    "section": "8.5 Zusammenfassen mit describe()",
    "text": "8.5 Zusammenfassen mit describe()\nIm Package {Hmisc} ist die Funktion describe() enthalten, mit der deskriptive Angaben über den Datensatz herausgegeben werden.\n\nFalls {Hmisc} noch nicht installiert ist können Sie dies mit install.packages(\"Hmisc\") in der Konsole (nicht im Skript!) tun.\n\n\nHmisc::describe(d)\n\nd \n\n 4  Variables      44  Observations\n--------------------------------------------------------------------------------\nid \n       n  missing distinct \n      44        0       44 \n\nlowest : sub-01 sub-02 sub-03 sub-04 sub-05, highest: sub-40 sub-41 sub-42 sub-43 sub-44\n--------------------------------------------------------------------------------\ndyslexia \n       n  missing distinct \n      44        0        2 \n                      \nValue         no   yes\nFrequency     25    19\nProportion 0.568 0.432\n--------------------------------------------------------------------------------\niq_zscore \n         n    missing   distinct       Info       Mean    pMedian        Gmd \n        44          0         32      0.999 -2.273e-05    -0.0035      1.159 \n       .05        .10        .25        .50        .75        .90        .95 \n   -1.6421    -1.2580    -0.7950    -0.1225     0.6198     1.2230     1.7202 \n\nlowest : -1.745 -1.666 -1.507 -1.27  -1.23 , highest: 1.223  1.619  1.738  1.777  1.856 \n--------------------------------------------------------------------------------\naccuracy \n       n  missing distinct     Info     Mean  pMedian      Gmd      .05 \n      44        0       27    0.974   0.7757   0.7858   0.2064   0.5414 \n     .10      .25      .50      .75      .90      .95 \n  0.5673   0.6185   0.7059   1.0000   1.0000   1.0000 \n\nlowest : 0.45932 0.53424 0.54048 0.54673 0.56546\nhighest: 0.88386 0.91508 0.95878 0.98376 1      \n--------------------------------------------------------------------------------\n\n\n\n{Hmisc} wird hier nicht geladen, sondern vor die Funktion gesetzt, da dieses Package Funktionsnamen verwendet, die auch in {tidyverse} vorkommen.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html#zusammenhangsmasse-kovariation-und-korrelation",
    "href": "datenanalyse/descriptive.html#zusammenhangsmasse-kovariation-und-korrelation",
    "title": "8  Deskriptive Statistik",
    "section": "8.6 Zusammenhangsmasse: Kovariation und Korrelation",
    "text": "8.6 Zusammenhangsmasse: Kovariation und Korrelation\nDie Kovarianz zweier Variablen kann mit cov() berechnet werden.\n\ncov(d$accuracy, d$iq_zscore)\n\n[1] 0.1038148\n\n\nDie Korrelation zweier Variablen kann mit cor() berechnet werden.\n\ncor(d$accuracy, d$iq_zscore)\n\n[1] 0.5681996",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/descriptive.html#footnotes",
    "href": "datenanalyse/descriptive.html#footnotes",
    "title": "8  Deskriptive Statistik",
    "section": "",
    "text": "Smithson M, Verkuilen J (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(7), 54–71.↩︎",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_unabhaengig.html",
    "href": "datenanalyse/ttest_unabhaengig.html",
    "title": "9  t-Test für unabhängige Stichproben",
    "section": "",
    "text": "9.1 Anwendungsbereich\nMit t-Tests für unabhängige Stichproben wird untersucht, wie sich zwei voneinander unabhängige Gruppen in einem intervallskalierten Mass unterscheiden, wenn die Populationsvarianz unbekannt ist.\nTypische Fragestellungen:\nBeispiele:",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>*t*-Test für unabhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_unabhaengig.html#anwendungsbereich",
    "href": "datenanalyse/ttest_unabhaengig.html#anwendungsbereich",
    "title": "9  t-Test für unabhängige Stichproben",
    "section": "",
    "text": "Wie unterscheiden sich Personen mit der Diagnose von Personen ohne Diagnose X in der Fähigkeit Y?\nWie unterscheiden sich Personen mit einer hohen Ausprägung eines Persönlichkeitsmerkmals von Personen mit einer tiefen Ausprägung in Fähigkeit Y?\nWie unterscheiden sich ältere Personen von jüngeren Personen in der Einschätzung von Y (z.B. Lebenszufriedenheit)?\nWie unterscheiden sich Personen, die ein Treatment erhalten haben, von Personen, welche dieses Treatment nicht erhalten haben (Kontrollgruppe) in der Symptomausprägung Y?\n\n\n\nMartin & Kerns (2011)\n\nFragestellung: Welchen Einfluss hat eine positive Stimmung auf die kognitive Leistung gemessen im Stroop Task oder im Running Span Task?\nTypische Aussage: The results revealed that the positive mood group performed significantly worse on the running span task, \\(t(174) = 2.14, p &lt; .05\\), but there were no differences between the groups on the Stroop task, \\(t(173) = 0.54, p = .590\\).",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>*t*-Test für unabhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_unabhaengig.html#voraussetzungen",
    "href": "datenanalyse/ttest_unabhaengig.html#voraussetzungen",
    "title": "9  t-Test für unabhängige Stichproben",
    "section": "9.2 Voraussetzungen",
    "text": "9.2 Voraussetzungen\n\nVoraussetzungen t-Test für unabhängige Stichproben, Überprüfung und mögliche Alternativen bei Verletzung der Annahmen\n\n\nVoraussetzung\nBeschreibung\nVorgehen bei Verletzung\n\n\n\n\nAbhängige Variable\nEine abhängige Variable mit metrischem Skalenniveau. Die AV muss in den beiden Teilpopulationen stetig und normalverteilt sein (bei genügend grosser Stichprobe ist der t-Test robust).\nTransformieren der Variable oder Verwenden von non-parametrischen Verfahren: Falls die AV ordinalskaliert ist, kann ein non-parametrisches (verteilungsfreies) Verfahren gewählt werden; z.B. Vergleich von zwei unabhängigen Stichproben mit dem Wilcoxon-Vorzeichen-Rangtest bzw. U-Test von Mann-Whitney.\n\n\nUnabhängige Variable\nEine unabhängige Variable mit zwei Stufen (dichotome Gruppenvariable).\nVerwenden eines anderen statistischen Verfahrens (z.B. Regression) oder Dichotomisierung der UV mittels Mediansplit (z.B. Alter von Zahl zu “jung” und “alt”).\n\n\nUnabhängigkeit der Messwerte\nDie Messwerte innerhalb der beiden Stichproben sind voneinander unabhängig. Es handelt sich um einfache, innerhalb der Stichprobe voneinander unabhängigen, Zufallsstichproben.\n\n\n\nUnabhängigkeit der Gruppen/Stichproben\nDie Messwerte zwischen den beiden Stichproben sind voneinander unabhängig (unabhängige Gruppen). Eine Verletzung der Unabhängigkeitsannahme liegt vor, wenn die Annahme, dass die Messwerte zwischen den beiden Stichproben unabhängig nicht zutrifft, d.h. die Messwerte in natürlichen Paaren (z.B. Geschwister, Messwiederholung) vorliegen.\nFür die Abhängigkeit der Gruppen kann kontrolliert werden, indem z.B. ein t-Test für abhängige Stichproben verwendet wird (siehe Kapitel: t-Test für abhängige Stichproben)\n\n\nVarianzhomogenität / Homoskedastizität\nDie Varianzen innerhalb der beiden Teilpopulationen sind homogen (Homoskedastizität). Vor allem wenn die Stichproben unterschiedlich gross sind, bietet sich eine empirische Überprüfung der Varianzhomogenitätsannahme an.\nÜberprüfung der Varianzhomogenitätsannahme:  Der Vergleich von zwei Stichprobenvarianzen mittels F-Test oder Levene-Test (robuste Variante zum F-Test).  Bei Verletzung der Varianzhomogenitätsannahme (Heteroskedastizität), kann als Alternative der Welch-Test verwendet werden, welcher nicht die gepoolten Innerhalb-Varianzen, sondern die beiden unterschiedlichen Stichprobenvarianzen \\(\\hat \\sigma^2_1\\) und \\(\\hat \\sigma^2_2\\) verwendet.\n\n\n\n\n\nAuf alternative statistische Verfahren bei Verletzung der Annahmen (z.B. Transformationen oder non-parametrische Verfahren) wird in diesem Semester nicht eingegangen.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>*t*-Test für unabhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_unabhaengig.html#grundkonzepte-und-vorgehen",
    "href": "datenanalyse/ttest_unabhaengig.html#grundkonzepte-und-vorgehen",
    "title": "9  t-Test für unabhängige Stichproben",
    "section": "9.3 Grundkonzepte und Vorgehen",
    "text": "9.3 Grundkonzepte und Vorgehen\n\n\n\nAllgemeiner Workflow der Datenanalyse\n\n\n\n9.3.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\nUngerichtete Hypothesen:\n\\(H_0\\): Die Populationsmittelwerte der Gruppe 1 und 2 unterscheiden sich nicht (d.h. haben eine Differenz gleich 0) \\(\\mu_1 = \\mu_2\\)\n\\(H_1\\): Die Populationsmittelwerte der Gruppe 1 und 2 unterscheiden sich (d.h. haben eine Differenz ungleich 0) \\(\\mu_1 \\neq \\mu_2\\)\nGerichtete Hypothesen:\nDie Hypothesen können auch gerichtet formuliert werden (die Populationsmittelwerte sind grösser/kleiner in einer Gruppe):\n\\(H_0\\): Der Mittelwert der Gruppe 1 ist kleiner oder gleich gross wie der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 \\leq \\mu_2\\)\n\\(H_1\\): Der Mittelwert der Gruppe 1 ist grösser als der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 &gt; \\mu_2\\).\noder\n\\(H_0\\): Der Mittelwert der Gruppe 1 ist grösser oder gleich gross wie der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 \\geq \\mu_2\\)\n\\(H_1\\): Der Mittelwert der Gruppe 1 ist kleiner als der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 &lt; \\mu_2\\).\nSignifikanzniveau:\nWird ein Signifikanzniveau von \\(\\alpha = 0.05\\) festgelegt, bedeutet dies, dass bei der Verwerfung der Nullhypothese eine 5% Wahrscheinlichkeit besteht, dass eigentlich kein Unterschied besteht und irrtümlicherweise einer angenommen wurde.\n\n\nA-priori Poweranalyse durchführen\nVor der Datenerhebung soll eine a-priori Poweranalyse durchgeführt werden. Einerseits kann damit ermittelt werden, wie viel Power (Teststärke) der Test hat, um einen Effekt von vordefinierter Grösse (z.B. einen grossen Effekt von \\(d=0.8\\)) zu entdecken. Andererseits kann berechnet werden, wie gross die Stichprobe sein sollte, um einen Effekt bestimmter Grösse und eine festgelegte Teststärke zu erreichen.\n\nEin Wert über \\(0.8\\) gilt gemäss den Konventionen für \\(\\delta\\) -Masse nach Cohen (1988) für den Zweistichprobentest als grosser Effekt.1\n\n\n\n\n9.3.2 Vorverarbeitung\n\nDaten einlesen, vorverarbeiten und visualisieren\nZuerst müssen die Daten eingelesen und bereinigt werden. Daten können diagnostisch visualisiert werden, um z.B. fehlende Werte zu entdecken oder Verteilungen der Daten visuell beurteilen und Extremwerte zu identifizieren.\nFür den t-Test für unabhängige Stichproben werden die Daten hier in einem long-Format benötigt.\n\nEs ist auch möglich Daten im Wide-Format zu verwenden, da sich das Long-Format aber für die Deskriptivstatistik und Visualisierung besser eignen, wird in diesem Kapitel durchgehend mit einem Long-Format gearbeitet.\n\n\n\nVoraussetzungen überprüfen\n\nVarianzhomogenität\n\nDer t-Test für unabhängige Stichproben setzt Varianzhomogenität voraus. Dies kann mit dem Levene-Test (in R mit der Funktion leveneTest()) überprüft werden.\nDer Levene-Test geht von der Nullhypothese aus, dass sich die beiden Varianzen nicht unterscheiden. Ein nicht signifikantes Ergebnis bedeutet daher, dass sich die Varianzen nicht unterscheiden und somit Varianzhomogenität (sogenannte Homoskedastizität) besteht. Wenn der Test signifikant ist, wird Varianzheterogenität angenommen. Konventionell wird hierfür ein \\(\\alpha = 0.05\\) angenommen.\n\nTeilweise wird ein konservativerer Cut-off von \\(\\alpha = 0.1\\) verwendet.\n\nFalls die Varianzen heterogen (unterschiedlich) sind , müssen die Freiheitsgrade des t-Wertes entsprechend angepasst werden. In diesem Fall kann ein Welch-Test (Welch’s t-Test) verwendet werden, der zur Berechnung der Teststatistik die beiden unterschiedlichen Populationsvarianzen anstatt die gepoolte Innerhalbvarianz nimmt. Dazu wird in R die Funktion t.test()mit der Option var.equal = FALSE genutzt.\n\n\n\n9.3.3 Analyse\n\nDeskriptivstatistik und Visualisierung\nBei Gruppenunterschieden wird für jede Gruppe ein Lagemass (z.B. Mittelwert oder Median) sowie ein Streumass (z.B. Standardabweichung, Standardfehler, Konfidenzintervall) berechnet. Das Lagemass stellt die durchschnittliche Merkmalsausprägung in den beiden Gruppen dar. Das Streumass zeigt den Streubereich der Daten auf.\n\nGenauere Informationen zu Lage- und Streumassen sind im Kapitel: Deskriptive Statistik zu finden.\n\nZur Visualisierung von Gruppenunterschieden eignen sich Lagemasse mit Fehlerbalken. Boxplots eignen sich beispielsweise gut, um Grösse des Gruppenunterschiedes (Effekts) und die Kohärenz der Datenpunkte (Ähnlichkeit der Werte innerhalb einer Bedingung/Gruppe) zu beurteilen.\nDurch die Visualisierung der Rohwerte, kann die Verteilung der Messungen gut eingeschätzt werden und Extremwerte werden deutlich sichtbar. Bei zu vielen Datenpunkten führt das Visualisieren der Rohwerte zu unübersichtlichen Grafiken.\n\n\nTeststatistik berechnen\nUm zu überprüfen, ob die beiden Mittelwerte signifikant unterschiedlich sind, muss die Teststatistik berechnet werden. Die Verteilung der Teststatistik folgt bei homogenen Varianzen einer sogenannten t-Verteilung (auch Student’s t-Verteilung genannt2), die durch die Anzahl Freiheitsgrade (df) definiert ist.\nUm die empirische Prüfgrösse zu berechen, wird die Mittelwertsdifferenz durch den Standardfehler der Mittelwertsdifferenz geteilt:\n\\(t_{\\overline{x}_1-\\overline{x}_2}=\\frac{\\overline{x}_1-\\overline{x}_2}{\\hat\\sigma_{\\overline{x}_1-\\overline{x}_2}}\\)\nDer Standardfehler der Mittelwertsdifferenz wird wie folgt geschätzt:\n\\(\\hat \\sigma_{\\overline{x}_1-\\overline{x}_2}=\\sqrt {\\frac {\\hat\\sigma_{inn}^2}{n_1}+ \\frac{\\hat\\sigma_{inn}^2}{n_2}}\\)\nDie dafür nötige gepoolte (gemeinsame) Innerhalbvarianz kann folgendermassen berechnet werden:\n\\(\\hat\\sigma_{inn}^2=\\frac{\\hat\\sigma^2_1 \\cdot (n_1-1) +\\hat\\sigma^2_2 \\cdot (n_2-1) }{n_1+n_2-2}\\)\nDie Freiheitsgrad lassen sich für einen unabhängigen t-Test berechnen:\n\\(df=n_1+n_2-2\\)\nNun muss die berechnete empirische Prüfgrösse t auf Signifikanz überprüft werden. Dazu wird der Wert mit dem kritischen Wert der durch die Freiheitsgrade bestimmten t-Verteilung verglichen. Der kritische Wert kann in dieser Tabelle abgelesen werden.\n\nDie \\(H_0\\) wird beibehalten, wenn die empirische Prüfgrösse t kleiner als der kritische Wert ist. Die Gruppen unterscheiden sich nicht signifikant bzw. es konnte kein Einfluss der Gruppenvariablen auf die AV gefunden werden.\nDie \\(H_0\\) wird abgelehnt, wenn die empirische Prüfgrösse t grösser als der kritische Wert ist. Die Gruppen unterscheiden sich signifikant bzw. es konnte ein Einfluss der Gruppenvariablen auf die AV gefunden werden.\n\n\nBei gerichteten Hypothesen müssen die Aussagen entsprechend angepasst werden.\n\n\n\nEffektstärke bestimmen\nDie Effektgrösse beim t-Test für unabhängige Stichproben sagt etwas darüber aus, wie gross der Unterschied zwischen den beiden Populationsmittelwerten ist.\nDie standardisierte Effektgrösse kann folgendermassen berechnet werden:\n\\(d=\\frac{\\overline{x}_1-\\overline{x}_2}{\\hat\\sigma_{inn}}\\)\nDie Effektgrösse \\(d\\) kann auch direkt über den t-Wert bestimmt werden:\n\\(d=t \\cdot \\sqrt {\\frac{n_1 + n_2}{n_1 \\cdot n_2}}\\)\nDie Konventionen nach Cohen (1988) lauten hier:\n\\(|d|=\\approx 0.2\\): kleiner Effekt\n\\(|d|=\\approx 0.5\\): mittelgrosser Effekt\n\\(|d|=\\approx 0.8\\): grosser Effekt\n\n\n\n9.3.4 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nJe grösser der empirische t-Wert ist, desto stärker spricht dies gegen die Nullhypothese.\nMeistens werden in psychologischen Publikationen die Stichprobenmittelwerte und ihre geschätzten Populationsstandardabweichungen (Stichprobenstandardabweichungen) sowie die t-Statistik, ihre Freiheitsgrade und der p-Wert (also der Wahrscheinlichkeit dieses oder eines noch extremeren t-Wertes unter Annahme der Nullhypothese) berichtet.\nFalls der exakte p-Wert sehr klein ist, beispielsweise \\(p=0.00000012\\) bzw. kleiner als \\(0.001\\), wird dies folgendermassen notiert: \\(p &lt; .001\\).3\n\nPersonen mit dem Treatment X unterscheiden sich signifikant in ihrer kognitiven Leistung von Personen ohne Treatment X, t(40)=-2.63, p &lt; .001, d = 0.34.\n\n\nPersonen mit der Diagnose X unterscheiden sich nicht in ihrer Schmerzempfindlichkeit von Personen ohne Diagnose X, t(40)=-0.13,) p = .641).",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>*t*-Test für unabhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_unabhaengig.html#anwendungsbeispiel-in-r",
    "href": "datenanalyse/ttest_unabhaengig.html#anwendungsbeispiel-in-r",
    "title": "9  t-Test für unabhängige Stichproben",
    "section": "9.4 Anwendungsbeispiel in R",
    "text": "9.4 Anwendungsbeispiel in R\n\n\n\n\n\n\nBeispiel: Stimmungsexperiment\n\n\n\nIn einem Experiment4 wurden Versuchspersonen entweder in positive Stimmung (Gruppe 1) oder in negative Stimmung (Gruppe 2) versetzt und mussten danach Rechenaufgaben lösen. Gemessen wurde, wie viele Rechenaufgaben die Versuchspersonen im Anschluss korrekt lösen konnten.\n\nDie unabhängige Variable war die Stimmungsinduktion mit 2 Stufen (dichotom): positiv und negativ.\nDie abhängige Variable war die Anzahl korrekt gelöster Rechenaufgaben (metrisch). Es handelt es sich hierbei um einen Indikator für die stetige Variable kognitive Leistungsfähigkeit.\n\n\n\n\n9.4.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\n\\(H_0\\): Die Stimmung hat keinen Einfluss auf die Leistung: \\(\\mu_1=\\mu_2\\)\n\\(H_1\\): Die Stimmung hat einen Einfluss auf die Leistung: \\(\\mu_1 \\neq\\mu_2\\)\nDas Alphaniveau wird auf \\(5 \\%\\) festgelegt. Da es sich um eine ungerichtete Hypothese handelt, wird zweiseitig getestet.\n\n\nA-priori Poweranalyse durchführen\n\nn1: Anzahl Messwerte Stichprobe 1\nn2: Anzahl Messwerte Stichprobe 2\nd: Effektgrösse\nsig.level: \\(\\alpha\\) (Fehler 1. Art)\nalternative: \\(H_1\\) gerichtet (greateroder less) oder ungerichtet (two-sided)\n\n\n# Package laden\nlibrary(pwr)\n\n# A-priori Poweranalyse \n# Power berechnen\npwr.t2n.test(n1 = 40, n2 = 40, d = 0.8,\n             sig.level = 0.05,\n             alternative = \"two.sided\")\n\n\n     t test power calculation \n\n             n1 = 40\n             n2 = 40\n              d = 0.8\n      sig.level = 0.05\n          power = 0.9421818\n    alternative = two.sided\n\n# Stichprobengrösse berechnen\npwr.t.test(d = 0.8, power = 0.8, sig.level = 0.05, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 25.52458\n              d = 0.8\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\nVor dem ersten Verwenden muss das Package {pwr} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"pwr\").\n\nEine Teststärke (Power) von 0.94 bedeutet, dass die Wahrscheinlichkeit 94 % beträgt, einen tatsächlich vorhandenen Effekt mit einer Effektstärke von \\(d = 0.8\\) zu entdecken.\nUm mit einer Teststärke von 80% einen grossen Effekt von \\(d=0.8\\) zu finden, wird eine Stichprobe von mindestens \\(n=26\\) pro Gruppe benötigt.\n\n\n\n9.4.2 Vorverarbeitung\n\nDaten einlesen und vorverarbeiten\n\n\n\n\n\n\nHands-on: Beispieldatensatz Stimmungsexperiment\n\n\n\n\n\nDaten herunterladen und einlesen\nHier kann der Projektordner mit den Daten heruntergeladen werden. Vor dem ersten Verwenden muss der Ordner entzippt werden, dann kann das RProject namens ttests.Rproj geöffnet werden. Der Ordner enthält\n\nRProject namens ttest.Rproj\nDatensatz mood.csv in data-Ordner\nRNotebook namens independent_ttest.Rmd\n(die weiteren Dateien werden für den t-Test für abhängige Stichproben und die Übung 4 verwendet.)\n\n\n# Package laden\nlibrary(tidyverse)\n\n# Daten laden und anschauen\nd_mood &lt;- read.csv(\"data/mood.csv\") |&gt;\n    glimpse() \n\nRows: 40\nColumns: 2\n$ mood_neg &lt;int&gt; 10, 15, 12, 11, 11, 9, 15, 16, 21, 18, 17, 15, 21, 19, 15, 11…\n$ mood_pos &lt;int&gt; 5, 6, 9, 9, 8, 7, 15, 6, 20, 9, 10, 7, 12, 14, 15, 16, 11, 6,…\n\n\nDatensatz transformieren\nFür den t-Test werden die Daten in einem long Format benötigt. Daher müssen die Daten vom bisherigen wide Format in ein long Format umstrukturiert werden und eine Variable id ergänzt werden.\n\n# Datenformat von wide zu long transformieren\nd_mood_long &lt;- d_mood  |&gt;\n  pivot_longer(cols = c(mood_neg, mood_pos),\n               names_to = \"condition\",\n               values_to = \"performance\") |&gt;\n  mutate(id = row_number()) |&gt;\n  select(id, condition, performance)\n\n# id (Subjekt-ID) und condition (Gruppenvariable) als Faktor definieren\nd_mood_long &lt;- d_mood_long |&gt; \n  mutate(id = as.factor(id)) |&gt; \n  mutate(condition = as.factor(condition))\nprint(d_mood_long)\n\n# A tibble: 80 × 3\n   id    condition performance\n   &lt;fct&gt; &lt;fct&gt;           &lt;int&gt;\n 1 1     mood_neg           10\n 2 2     mood_pos            5\n 3 3     mood_neg           15\n 4 4     mood_pos            6\n 5 5     mood_neg           12\n 6 6     mood_pos            9\n 7 7     mood_neg           11\n 8 8     mood_pos            9\n 9 9     mood_neg           11\n10 10    mood_pos            8\n# ℹ 70 more rows\n\n\n\n\n\n\n\nVoraussetzungen überprüfen\nDer t-Test setzt voraus, dass das Merkmal \\(X\\) in der Population stetig und normalverteilt ist und die beiden Populationsvarianzen gleich (homogen) sind.\n\nDie Voraussetzung der Normalverteilung wird in diesem Semester nicht überprüft.\n\nDie Varianzhomogenität (Homoskedastizität) kann mit dem Levene-Test leveneTest(y ~ x, data = data) überprüft werden. Es wird ein konventionelles Signifikanzniveau von \\(\\alpha = 0.05\\) angenommen. Ein Levene-Test mit \\(p &lt; 0.05\\) bedeutet, dass der Varianzunterschied signifikant ist. Die Nullhypothese, dass die beiden Varianzen auf Populationsebene identisch sind, muss in diesem Fall verworfen werden.\n\nIn dieser Veranstaltung verwenden wir \\(\\alpha = 0.05\\). Teilweise wird ein konservativerer Cut-off von \\(\\alpha = 0.1\\) verwendet. Das würde im aktuellen Beispiel dazu führen, dass die Varianzen nicht als homogen angenommen werden. Im unten dargestellten Plot kann gut erkannt werden, dass die Streuung ähnlich, aber nicht exakt gleich ist.\n\n\n# Levene-Test mit dem package {car}\ncar::leveneTest(performance ~ condition, # av ~ uv\n                data = d_mood_long) # Datensatz\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)  \ngroup  1  3.3508 0.07099 .\n      78                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer Test ist hier nicht signifikant (\\(p = .071\\)), daher wird davon ausgegangen, dass die Varianzen in beiden Gruppen homogen sind. Somit kann ein Student’s t-Test verwendet werden.\n\n\n\n9.4.3 Analyse\n\nDeskriptivstatistik und Visualisierungn\nFür die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden.\n\n# Nach condition gruppieren und performance zusammenfassen\nd_summary &lt;- d_mood_long |&gt;\n  group_by(condition) |&gt; # Gruppieren\n  summarise(mean_performance = mean(performance), # Mittelwert\n            sd_performance = sd(performance)) # Standardabweichung\nd_summary\n\n# A tibble: 2 × 3\n  condition mean_performance sd_performance\n  &lt;fct&gt;                &lt;dbl&gt;          &lt;dbl&gt;\n1 mood_neg              12.4           5.61\n2 mood_pos              10.2           4.32\n\n\nMit einem Boxplot kann die Verteilung der Werte noch genauer angeschaut und die beiden Gruppen visuell miteinander verglichen werden.\n\n# Boxplot\np_boxplot &lt;- d_mood_long |&gt; \n  ggplot(aes(x = condition, y = performance)) +\n  geom_jitter(aes(colour = condition), alpha = 0.3, width = 0.1) + # Datenpunkte\n  geom_boxplot(alpha = 0, width = 0.2, color = \"black\") + # Boxplot\n  scale_colour_manual(values = c(\"mood_neg\" = \"red4\", # Farben\n                               \"mood_pos\" = \"blue4\")) +\n  labs(title = \"Effect of Mood on Performance\", # Beschriftungen\n      subtitle = \"Independent t-Test\",\n       x = \"Mood Condition\",\n       y = \"Performance Score\") +\n  theme_minimal(base_size = 12) + # Theme\n  theme(legend.position = \"none\") \n\np_boxplot # Plot anzeigen\n\n\n\n\n\n\n\n\n\n\nTeststatistik berechnen\na. Berechnung Teststatistik von Hand\nIm Folgenden wird ein t-Test für unabhängige Stichproben unter der Annahme von homogenen Varianzen “von Hand” berechnet.\n\nn1 &lt;- 40 # Stichprobengrösse: negative Stimmung\nn2 &lt;- 40 # Stichprobengrösse: positive Stimmung\nx1 &lt;- 12.40 # Mittelwert: negative Stimmung\nsd1 &lt;- 5.61 # Standardabweichung: negative Stimmung\nx2 &lt;- 10.15 # Mittelwert: positive Stimmung\nsd2 &lt;- 4.32 # Standardabweichung: positive Stimmung\n\n# Berechnung der empirischen Prüfgrösse\nvar_inn &lt;- (sd1^2*(n1 - 1) + sd2^2*(n2 - 1))/((n1 - 1) + (n2 - 1))\nsd_meandiff &lt;- sqrt(var_inn/n1 + var_inn/n2)\n(x1 - x2)/sd_meandiff # empirischer t-Wert\n\n[1] 2.00976\n\n# Ausgabe der kritischen Werte\nqt(0.025, 78) # kritischer t-Wert unterhalb\n\n[1] -1.990847\n\nqt(0.975, 78) # kritischer t-Wert oberhalb\n\n[1] 1.990847\n\n\nNach dieser Berechnung liegt der empirische t-Wert bei \\(2.01\\) leicht über dem kritischen Wert von \\(1.99\\). Die Mittelwerte unterscheiden sich daher signifikant auf dem \\(5 \\%\\)-Niveau.\nb. Berechnung Teststatistik in R mit der Funktion t.test\nViel einfacher kann den t-Test für unabhängige Stichproben mit t.test(formula = y ~ x, alternative, var.equal, data) berechnet werden.\n\ny: Abhängige Variable (metrisch)\nx: Unabhängige Variable (Bedingung oder Gruppenvariable)\nalternative: festlegen, ob die \\(H_1\\) gerichtet (greateroder less) oder ungerichtet (two-sided) ist\nvar.equal: festlegen, ob die Annahme homogener Varianzen zutrifft (TRUE) oder nicht (FALSE)\n\n\n# t-Test für unabhängige Stichproben durchführen\nt.test(formula = performance ~ condition, # av ~ uv\n       alternative = \"two.sided\",\n       var.equal = TRUE,\n       data = d_mood_long)\n\n\n    Two Sample t-test\n\ndata:  performance by condition\nt = 2.008, df = 78, p-value = 0.04811\nalternative hypothesis: true difference in means between group mood_neg and group mood_pos is not equal to 0\n95 percent confidence interval:\n 0.01920551 4.48079449\nsample estimates:\nmean in group mood_neg mean in group mood_pos \n                 12.40                  10.15 \n\n\nDie Mittelwerte der beiden Gruppen unterscheiden sich signifikant auf dem \\(5 \\%\\)-Niveau. Die Nullhypothese, wonach sich die beiden Mittelwerte nicht unterscheiden kann verworfen werden. Die Stimmung beeinflusst somit die kognitive Leistung.\n\n\nEffektstärke bestimmen\nBerechnung der Effektgrösse (Cohen’s d)\nNun kann noch die Effektgrösse mit cohen.d(formula = y ~ x, data) aus dem Package {effsize} berechnet werden.\n\n# Effektgrösse berechnen\neffsize::cohen.d(formula = performance ~ condition, # av ~ uv\n                 data = d_mood_long) # Datensatz\n\n\nCohen's d\n\nd estimate: 0.4489995 (small)\n95 percent confidence interval:\n       lower        upper \n-0.001741657  0.899740658 \n\n\nDie Effektgrösse liegt bei \\(d=0.45\\). Es handelt sich nach der Taxonomie von Cohen (1988) um einen kleinen Effekt.\n\n\n\n9.4.4 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nDas Ergebnis ist auf dem \\(5 \\%\\)-Niveau signifikant und die Nullhypothese kann somit verworfen werden: Die Stimmung beeinflusst die kognitive Leistungsfähigkeit. Es handelt sich nach der Taxonomie von Cohen (1988) um einen kleinen Effekt (\\(d=0.45\\)).\n\n“We examined whether the mood condition had an effect on cognitive performance. There was a significant difference between the positive and negative mood condition, t(78) = 2.01, p = .048, d = 0.45). Participants in the negative mood condition (M = 12.40, SD = 5.61) performed significantly better on the task than those in the positive mood condition (M = 10.15, SD = 4.32). This indicates a small effect of mood on cognitive performance according to Cohen’s convention (1988).”",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>*t*-Test für unabhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_unabhaengig.html#footnotes",
    "href": "datenanalyse/ttest_unabhaengig.html#footnotes",
    "title": "9  t-Test für unabhängige Stichproben",
    "section": "",
    "text": "Eid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 338↩︎\nhttps://www.scientificamerican.com/article/how-the-guinness-brewery-invented-the-most-important-statistical-method-in/↩︎\nhttps://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf↩︎\nEid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 366↩︎",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>*t*-Test für unabhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_abhaengig.html",
    "href": "datenanalyse/ttest_abhaengig.html",
    "title": "10  t-Test für abhängige Stichproben",
    "section": "",
    "text": "10.1 Anwendungsbereich\nMit t-Tests für abhängige Stichproben wird untersucht, wie sich zwei verbundene Gruppen in einem intervallskalierten Mass unterscheiden.\nAbhängige/verbundene Stichproben bedeutet hierbei, dass die Daten einer Person zu zwei Messzeitpunkten (in zwei Bedingungen) erhoben werden. Verbunden kann ebenfalls bedeuten, dass die Daten zweier Personen erhoben werden, die nicht unabhängig voneinander sind (z.B. Paare, Geschwister, Kontrollpersonen etc.).\nAbhängigkeit/Verbundenheit kann entstehen durch:\nTypische Fragestellungen:",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>*t*-Test für abhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_abhaengig.html#anwendungsbereich",
    "href": "datenanalyse/ttest_abhaengig.html#anwendungsbereich",
    "title": "10  t-Test für abhängige Stichproben",
    "section": "",
    "text": "Messwiederholung\nNatürliche Paare\nParallelisierung der Stichproben\n\n\n\nWie unterscheidet sich Symptomausprägung Y einer Person vor und nach einem Treatment X?\nWie unterscheidet sich Partner:in A von Partner:in B in der Fähigkeit Y?\nWie unterscheidet sich das Verhalten einer Person in Situation A von dem in Situation B?",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>*t*-Test für abhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_abhaengig.html#voraussetzungen",
    "href": "datenanalyse/ttest_abhaengig.html#voraussetzungen",
    "title": "10  t-Test für abhängige Stichproben",
    "section": "10.2 Voraussetzungen",
    "text": "10.2 Voraussetzungen\n\nVoraussetzungen t-Test für abhängige Stichproben, Überprüfung und mögliche Alternativen bei Verletzung der Annahmen\n\n\nVoraussetzung\nBeschreibung\nVorgehen bei Verletzung\n\n\n\n\nAbhängige Variable\nEine abhängige Variable mit metrischem Skalenniveau. Die Differenzvariable (gemessener Unterschied zwischen jedem Paar) muss in der Population normalverteilt sein (bei genügend grosser Stichprobe ist der t-Test robust).\nTransformieren der Variable oder Verwenden von non-parametrischen Verfahren: Der Wilcoxon-Vorzeichen-Rangtest kann verwendet werden, wenn der Mittelwert nicht zur Bestimmung der zentralen Tendenz verwendet werden kann. Man greift auf dieses Verfahren u.a. auch dann zurück, wenn die Stichprobe zu klein ist, um von der Robustheit des t-Tests ausgehen zu können.\n\n\nUnabhängige Variable\nEine unabhängige Variable mit zwei Stufen (dichotome Gruppenvariable).\nVerwenden eines anderen statistischen Verfahrens (z.B. Regression)\n\n\nUnabhängigkeit der Messwerte\nDie Messwerte innerhalb der beiden Stichproben sind voneinander unabhängig. Es handelt sich um einfache, innerhalb der Stichprobe voneinander unabhängigen, Zufallsstichproben.\n\n\n\nAbhängigkeit der Gruppen/Stichproben\nDie Messwerte zwischen den beiden Stichproben sind verbunden (abhängige Gruppen).\nBei unabhängigen Gruppen kann ein t-Test für unabhängige Stichproben verwendet werden (siehe Kapitel: t-Test für unabhängige Stichproben)\n\n\n\n\n\nAuf alternative statistische Verfahren bei Verletzung der Annahmen (z.B. Transformationen oder non-parametrische Verfahren) wird in diesem Semester nicht eingegangen.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>*t*-Test für abhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_abhaengig.html#grundkonzepte-und-vorgehen",
    "href": "datenanalyse/ttest_abhaengig.html#grundkonzepte-und-vorgehen",
    "title": "10  t-Test für abhängige Stichproben",
    "section": "10.3 Grundkonzepte und Vorgehen",
    "text": "10.3 Grundkonzepte und Vorgehen\n\n\n\nAllgemeiner Workflow der Datenanalyse\n\n\n\n10.3.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\nUngerichtete Hypothesen:\n\\(H_0\\): Die Populationsmittelwerte unterscheiden sich nicht (d.h. haben eine Differenz gleich 0) \\(\\mu_1 = \\mu_2\\) oder \\(\\mu_D = 0\\)\n\\(H_1\\): Die Populationsmittelwerte unterscheiden sich (d.h. haben eine Differenz ungleich 0) \\(\\mu_1 \\neq \\mu_2\\) oder \\(\\mu_D \\neq 0\\)\nGerichtete Hypothesen:\nHypothesen können auch gerichtet formuliert werden (die Populationsmittelwerte sind grösser/kleiner in einer Gruppe):\n\\(H_0\\): Der Mittelwert der Gruppe 1 ist kleiner oder gleich gross wie der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 \\leq \\mu_2\\)\n\\(H_1\\): Der Mittelwert der Gruppe 1 ist grösser als der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 &gt; \\mu_2\\).\noder\n\\(H_0\\): Der Mittelwert der Gruppe 1 ist grösser oder gleich gross wie der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 \\geq \\mu_2\\)\n\\(H_1\\): Der Mittelwert der Gruppe 1 ist kleiner als der Mittelwert der Gruppe 2 \\(\\quad \\mu_1 &lt; \\mu_2\\).\nSignifikanzniveau:\nWird ein Signifikanzniveau von \\(\\alpha = 0.05\\) festgelegt, bedeutet dies, dass bei der Verwerfung der Nullhypothese eine 5% Wahrscheinlichkeit besteht, dass eigentlich kein Unterschied besteht und irrtümlicherweise einer angenommen wurde.\n\n\nA-priori Poweranalyse durchführen\nVor der Datenerhebung soll eine a-priori Poweranalyse durchgeführt werden. Einerseits kann damit ermittelt werden, wie viel Power (Teststärke) der Test hat, um einen Effekt von vordefinierter Grösse (z.B. einen grossen Effekt von \\(d=0.6\\)) zu entdecken. Andererseits kann berechnet werden, wie gross die Stichprobe sein sollte, um einen Effekt bestimmter Grösse und eine festgelegte Teststärke zu erreichen.\n\nEin Wert über \\(0.57\\) gilt gemäss den Konventionen für \\(\\delta\\) -Masse nach Cohen (1988) als grosser Effekt.1\n\n\n\n\n10.3.2 Vorverarbeitung\n\nDaten einlesen, vorverarbeiten und visualisieren\nZuerst müssen die Daten eingelesen und bereinigt werden. Daten können diagnostisch visualisiert werden, um z.B. fehlende Werte zu entdecken oder Verteilungen der Daten visuell beurteilen und Extremwerte zu identifizieren.\nFür den t-Test für abhängige Stichproben werden die Daten hier in einem wide-Format benötigt. Für die Visualisierung wird eine Datensatz im long-Format benötigt.\n\n\nVoraussetzungen überprüfen\n\nNormalverteilung der Differenzen\n\nOb die Differenzen der Messwerte approximativ normalverteilt sind, kann z.B. visuell mit einem Plot oder dem Shapiro-Wilk-Test überprüft werden.\n\n\n\n10.3.3 Analyse\n\nDeskriptivstatistik und Visualisierung\nBei Gruppenunterschieden wird für jede Gruppe ein Lagemass (z.B. Mittelwert oder Median) sowie ein Streumass (z.B. Standardabweichung, Standardfehler, Konfidenzintervall) berechnet. Das Lagemass stellt die durchschnittliche Merkmalsausprägung in den beiden Gruppen dar. Das Streumass zeigt den Streubereich der Daten auf.\n\nGenauere Informationen zu Lage- und Streumassen sind im Kapitel: Deskriptive Statistik zu finden.\n\nZur Visualisierung von Gruppenunterschieden eignen sich Lagemasse mit Fehlerbalken. Boxplots eignen sich beispielsweise gut, um Grösse des Gruppenunterschiedes (Effekts) und die Kohärenz der Datenpunkte (Ähnlichkeit der Werte innerhalb einer Bedingung/Gruppe) zu beurteilen.\nDurch die Visualisierung der Rohwerte, kann die Verteilung der Messungen gut eingeschätzt werden und Extremwerte werden deutlich sichtbar. Bei zu vielen Datenpunkten führt das Visualisieren der Rohwerte zu unübersichtlichen Grafiken.\n\n\nTeststatistik berechnen\nUm zu überprüfen, ob die beiden Mittelwerte signifikant unterschiedlich sind, muss die Teststatistik berechnet werden. Die Verteilung der Teststatistik folgt einer sogenannten t-Verteilung, die durch die Anzahl Freiheitsgrade (df) definiert ist.\nDer t-Test für abhängige Stichproben wird über die Differenz der Messwertpaare (intraindividuelle Differenzwerte) ermittelt.\nDazu werden zuerst die Differenzen aller Mittelwertspaare gebildet: \\(d_m=x_{m_1}-x_{m_2}\\)\nDaraus wird der Mittelwert und die Standardabweichung der Differenz berechnet, wobei \\(n\\) der Anzahl der Messwertpaare entspricht:\n\nMittelwert: \\(\\overline{x}_D=\\frac{\\sum^n_{m=1} d_m}{n}\\)\nStandardabweichung: \\(\\hat{\\sigma}_D=\\sqrt{\\frac{\\sum^n_{m=1} (d_m-\\overline{x}_D)^2}{n-1}}\\)\n\nDie empirische Prüfgrösse wird mit Hilfe des geschätzten Standardfehlers berechnet:\n\nGeschätzter Standardfehler: \\(\\hat{\\sigma}_{x_D}=\\frac{\\hat{\\sigma}_D}{\\sqrt n}\\)\nEmpirische Prüfgrösse: \\(t_{x_D}=\\frac{\\overline{x}_D}{\\hat{\\sigma}_{x_D}}\\)\nDie Freiheitsgrad lassen sich für einen abhängigen t-Test berechnen durch: \\(df=n-1\\)\n\nNun muss die berechnete empirische Prüfgrösse t auf Signifikanz überprüft werden. Dazu wird der Wert mit dem kritischen Wert der durch die Freiheitsgrade bestimmten t-Verteilung verglichen. Der kritische Wert kann in einer Tabelle abgelesen werden.\n\nDie \\(H_0\\) wird beibehalten, wenn die empirische Prüfgrösse kleiner als der kritische Wert ist. Die Gruppen unterscheiden sich nicht signifikant bzw. die Gruppenvariable hat keinen Einfluss auf die AV.\nDie \\(H_0\\) wird abgelehnt, wenn die empirische Prüfgrösse grösser als der kritische Wert ist. Die Gruppen unterscheiden sich signifikant bzw. die Gruppenvariable hat einen Einfluss auf die AV.\n\n\nBei gerichteten Hypothesen müssen die Aussagen entsprechend angepasst werden.\n\n\n\nEffektstärke\nDie Effektgrösse beim t-Test für abhängige Stichproben sagt etwas darüber aus, wie gross der Unterschied zwischen den beiden Populationsmittelwerten ist.\nDie standardisierte Effektgrösse kann folgendermassen berechnet werden:\n\\(d=\\frac{\\overline{x}_D}{\\hat\\sigma_{D}}\\)\nDie Konventionen nach Cohen (1988) lauten hier:\n\\(|d|=\\approx 0.14\\): kleiner Effekt\n\\(|d|=\\approx 0.35\\): mittelgrosser Effekt\n\\(|d|=\\approx 0.57\\): grosser Effekt\n\n\n\n10.3.4 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nJe grösser der empirische t-Wert ist, desto stärker spricht dies gegen die Nullhypothese.\nMeistens werden in psychologischen Publikationen die Stichprobenmittelwerte und ihre geschätzten Populationsstandardabweichungen (Stichprobenstandardabweichungen) sowie die t-Statistik, ihre Freiheitsgrade und der p-Wert (also der Wahrscheinlichkeit dieses oder eines noch extremeren t-Wertes unter Annahme der Nullhypothese) berichtet.\nFalls der exakte p-Wert sehr klein ist, beispielsweise \\(p=0.00000012\\) bzw. kleiner als \\(0.001\\), wird dies folgendermassen notiert: \\(p &lt; .001\\).2\n\nDie kognitive Leistung von Personen vor und nach dem Treatment X unterscheidet sich nicht signifikant, t(15) = 0.75, p = .470.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>*t*-Test für abhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_abhaengig.html#anwendungsbeispiel-in-r",
    "href": "datenanalyse/ttest_abhaengig.html#anwendungsbeispiel-in-r",
    "title": "10  t-Test für abhängige Stichproben",
    "section": "10.4 Anwendungsbeispiel in R",
    "text": "10.4 Anwendungsbeispiel in R\n\n\n\n\n\n\nBeispiel: Social Media Experiment\n\n\n\nIn einem Experiment wurden 50 Versuchspersonen vor und nach dem Scrollen und Lesen von Nachrichten auf einer Social Media Plattform befragt, wie stark sie Zukunftsängste empfinden. Die Zukunftsangst wurde zu Messzeitpunkt 1 (kurz vor dem Lesen/Scrollen) und zu Messzeitpunkt 2 (kurz nach dem Lesen/Scrollen) gemessen. Hierfür gaben die Versuchspersonen mit einem digitalen Schieber auf einer durchgehenden Skala von 0 bis 10 an, wie stark ihnen die Zukunft Angst macht.\n\nDie unabhängige Variable war der Messzeitpunkt (dichotom): vorher (pre) und nachher (post).\nDie abhängige Variable war das Rating der Zukunftsangst.\n\n\n\n\n10.4.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\n\\(H_0\\): Das Lesen/Scrollen auf Social Media hat keinen Einfluss auf die Zukunftsangst: \\(\\mu_1=\\mu_2\\)\n\\(H_1\\): Die Lesen/Scrollen auf Social Media hat einen Einfluss auf die Zukunftsangst: \\(\\mu_1 \\neq\\mu_2\\)\nDas Alphaniveau wird auf \\(5 \\%\\) festgelegt. Da es sich um eine ungerichtete Hypothese handelt, wird zweiseitig getestet.\n\n\nA-priori Poweranalyse durchführen\n\nn: Anzahl Paare\nd: Effektgrösse\nsig.level: \\(\\alpha\\) (Fehler 1. Art)\nalternative: \\(H_1\\) gerichtet (greateroder less) oder ungerichtet (two-sided)\n\n\n# Package laden\nlibrary(pwr)\n\n# A-priori Poweranalyse\n# Power berechnen\npower.t.test(n = 50, # Anzahl Versuchspersonen/Paare\n             delta = 0.57, # Mittelwertsunterschied\n             sd = 1, # Standardabweichung\n             sig.level = 0.05, # Signifikanzlevel\n             type = \"paired\", # abhängig: \"paired\"\n             strict = TRUE,\n             alternative = \"two.sided\")\n\n\n     Paired t test power calculation \n\n              n = 50\n          delta = 0.57\n             sd = 1\n      sig.level = 0.05\n          power = 0.9767248\n    alternative = two.sided\n\nNOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs\n\n# Stichprobengrösse berechnen\npwr.t.test(d = 0.35, \n           power = 0.8, \n           sig.level = 0.05, \n           type = \"paired\",\n           alternative = \"two.sided\")\n\n\n     Paired t test power calculation \n\n              n = 66.01882\n              d = 0.35\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\n\nBeim ersten Verwenden muss das Package {pwr} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"pwr\").\n\nEine Teststärke (Power) von 0.98 bedeutet, dass die Wahrscheinlichkeit 98% beträgt, einen tatsächlich vorhandenen Effekt mit einer Effektstärke von 0.57 zu finden.\nUm mit einer Teststärke von 80% einen mittelgrossen Effekt von \\(d=0.35\\) zu finden, wird eine Stichprobe von mindestens \\(n=67\\) Personen benötigt.\n\n\n\n10.4.2 Vorverarbeitung\n\nDaten einlesen und vorverarbeiten\n\n\n\n\n\n\nHands-on: Beispieldatensatz Social-Media-Experiment vorverarbeiten\n\n\n\n\n\nDaten herunterladen und einlesen\nHier kann der Projektordner mit den Daten heruntergeladen werden. Vor dem ersten Verwenden muss der Ordner entzippt werden, dann kann das RProject namens ttests.Rproj geöffnet werden. Der Ordner enthält\n\nRProject namens ttest.Rproj\nDatensatz fear.csv in data-Ordner\nRNotebook namens dependent_ttest.Rmd\n(die weiteren Dateien werden für den t-Test für unabhängige Stichproben und die Übung 4 verwendet.)\n\n\n# Package laden\nlibrary(tidyverse)\n\n# Daten laden und anschauen\nd_fear &lt;- read.csv(\"data/fear.csv\") |&gt;\n    glimpse() \n\nRows: 50\nColumns: 3\n$ id        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ fear_pre  &lt;dbl&gt; 5.1, 6.3, 2.3, 3.3, 8.3, 3.6, 5.0, 0.8, 2.5, 3.4, 9.9, 7.2, …\n$ fear_post &lt;dbl&gt; 10.0, 7.1, 9.3, 8.9, 7.0, 9.1, 9.2, 8.7, 4.1, 4.5, 9.2, 9.8,…\n\n\nDatensatz transformieren\nFür den t-Test für abhängige Stichproben werden die Daten in einem wide Format benötigt. Die Variable id wird mit as.factor() in einen Faktor konvertiert.\nFür das Visualisieren jedoch werden Daten im long-Format verwendet. Dafür müssen die Daten vom bisherigen wide Format in ein long Format umstrukturiert werden. Die Variable id wird mit as.factor() in einen Faktor konvertiert.\n\n# id (Subjekt-ID) als Faktor definieren\nd_fear &lt;- d_fear |&gt;\n  mutate(id = as.factor(id))\n\n# Datenformat für Deskriptivstatistik und Visualisierung\n# von wide zu long transformieren\nd_fear_long &lt;- d_fear |&gt;\n  pivot_longer(cols = c(fear_pre, fear_post),\n               names_to = \"timepoint\",\n               names_prefix = \"fear_\", \n               values_to = \"fear\") |&gt;\n   select(id, timepoint, fear)\n\n# id (Subjekt-ID) und t (Gruppenvariable) als Faktor definieren\nd_fear_long &lt;- d_fear_long |&gt; \n  mutate(id = as.factor(id)) |&gt; \n  mutate(timepoint = factor(timepoint, levels = c(\"pre\", \"post\")))\n\n# Datensatz anzeigen\nd_fear_long\n\n# A tibble: 100 × 3\n   id    timepoint  fear\n   &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt;\n 1 1     pre         5.1\n 2 1     post       10  \n 3 2     pre         6.3\n 4 2     post        7.1\n 5 3     pre         2.3\n 6 3     post        9.3\n 7 4     pre         3.3\n 8 4     post        8.9\n 9 5     pre         8.3\n10 5     post        7  \n# ℹ 90 more rows\n\n\n\n\n\n\nHier konvertieren wir die Variable timepoint zu einem Faktor mit der Funktion factor(), so können wir im Argument levels = ... eingeben, dass die Stufe pre vor der Stufe post kommen soll (entgegen der automatisch alphabetischen Reihenfolge). Dies macht den Plot logischer, da dann pre links und post rechts dargestellt wird.\n\n\n\nVoraussetzungen überprüfen\nDer t-Test setzt voraus, dass die Differenzen der Messungen in beiden Gruppen normalverteilt sind.\n\nDie Voraussetzung der Normalverteilung wird in diesem Semester nicht überprüft. Zur Überprüfung der Normalverteilung können Plots dienen oder der Shapiro-Wilk-Test (shapiro.test(data$variable).\n\n\n\n\n10.4.3 Analyse\n\nDeskriptivstatisik und Visualisierung\nFür die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden.\nDas kann mit dem Wide Datensatz gemacht werden:\n\n# Nach condition gruppieren und performance zusammenfassen\nd_summary &lt;- d_fear |&gt;\n  summarise(mean_fear_pre = mean(fear_pre),\n            sd_fear_pre = sd(fear_pre),\n            mean_fear_post = mean(fear_post),\n            sd_fear_post = sd(fear_post))\nd_summary\n\n  mean_fear_pre sd_fear_pre mean_fear_post sd_fear_post\n1         4.318     2.62155          6.376     2.722886\n\n\nOder mit dem Long Datensatz:\n\n# Nach condition gruppieren und performance zusammenfassen\nd_summary &lt;- d_fear_long |&gt;\n  group_by(timepoint) |&gt;\n  summarise(mean_fear = mean(fear),\n            sd_fear = sd(fear))\nd_summary\n\n# A tibble: 2 × 3\n  timepoint mean_fear sd_fear\n  &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n1 pre            4.32    2.62\n2 post           6.38    2.72\n\n\nMit einem Boxplot kann die Verteilung der Werte angeschaut und die beiden Gruppen visuell miteinander verglichen werden.\n\n# Boxplot\np_boxplot &lt;- d_fear_long |&gt; \n  ggplot(aes(x = timepoint, y = fear)) +\n  geom_jitter(aes(colour = timepoint), alpha = 0.3, height = 0, width = 0.01) +\n  geom_line(aes(x = timepoint, y = fear, group = id), alpha = 0.15) +\n  geom_boxplot(alpha = 0, width = 0.2, color = \"black\") +\n  scale_colour_manual(values = c(\"pre\" = \"red4\",\n                               \"post\" = \"blue4\")) +\n  labs(title = \"Effect of Social Media on Fear \",\n       subtitle = \"Paired t-Test\",\n       x = \"Timepoint\",\n       y = \"Fear\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\")\n\np_boxplot\n\n\n\n\n\n\n\n\n\n\nTeststatistik berechnen\nBerechnung Teststatistik in R mit der Funktion t.test\nDer t-Test für abhängige Stichproben kann mit der Funktion t.test() durchgeführt werden. Hierbei wird ein Datensatz im wide-Format benötigt.\n\ny: Abhängige Variable Gruppe A\nx: Abhängige Variable Gruppe B\nalternative: festlegen, ob die \\(H_1\\) gerichtet (greateroder less) oder ungerichtet (two-sided) ist\nvar.equal: festlegen, ob die Annahme homogener Varianzen zutrifft (TRUE) oder nicht (FALSE)\n\n\n# t-Test für abhängige Stichproben durchführen\nt.test(x = d_fear$fear_post, # av t2\n       y = d_fear$fear_pre, # av t1\n       alternative = \"two.sided\",\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  d_fear$fear_post and d_fear$fear_pre\nt = 3.9751, df = 49, p-value = 0.000231\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.017604 3.098396\nsample estimates:\nmean difference \n          2.058 \n\n\nDie Mittelwerte zwischen den beiden Messzeitpunkten unterscheiden sich signifikant auf dem \\(5 \\%\\)-Niveau. Die Nullhypothese, wonach sich die beiden Mittelwerte nicht unterscheiden kann verworfen werden. Das Lesen/Scrollen durch Social Media Posts beeinflusst somit die empfundene Zukunftsangst.\n\n\nEffektstärke bestimmen\nBerechnung der Effektgrösse (Cohen’s d)\nNun kann noch die Effektgrösse mit cohen.d(x, y, paired = TRUE) aus dem Package {effsize} berechnet werden.\n\n# Effektgrösse berechnen\neffsize::cohen.d(d_fear$fear_post, # av t2\n                 d_fear$fear_pre, # av t1\n                 paired = TRUE)\n\n\nCohen's d\n\nd estimate: 0.7699901 (medium)\n95 percent confidence interval:\n   lower    upper \n0.332312 1.207668 \n\n\nDie Effektgrösse liegt bei \\(d = 0.77\\). Es handelt sich nach der Taxonomie von Cohen (1988) um einen grossen Effekt.\n\n\n\n\n\n\n\n\n10.4.4 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nDas Ergebnis ist auf dem \\(5 \\%\\)-Niveau signifikant und die Nullhypothese kann somit verworfen werden: Die Stimmung beeinflusst die kognitive Leistungsfähigkeit. Es handelt sich nach der Taxonomie von Cohen (1988) um einen grossen Effekt (\\(d = 0.77\\)).\n\n“We examined whether doom-scrolling on social media has an effect on the immediate experience of fear of the future. There was a significant difference between pre and post measurement, t(49) = 3.98, p &lt; .001, d = 0.77). Participants reported significantly higher fear of the future after reading/scrolling through social media posts (M = 6.38, SD = 2.72) compared to before (M = 4.32, SD = 2.62). This indicates a large effect of social media on experiences of fear of the future according to Cohen’s convention (1988).”",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>*t*-Test für abhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/ttest_abhaengig.html#footnotes",
    "href": "datenanalyse/ttest_abhaengig.html#footnotes",
    "title": "10  t-Test für abhängige Stichproben",
    "section": "",
    "text": "Eid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 374↩︎\nhttps://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf↩︎",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>*t*-Test für abhängige Stichproben</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova1.html",
    "href": "datenanalyse/anova1.html",
    "title": "11  Einfaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "",
    "text": "11.1 Anwendungsbereich\nMit der einfaktoriellen Varianzanalyse (ohne Messwiederholung) wird untersucht, ob sich die Mittelwerte mehrerer unabhängiger Gruppen unterscheiden bzw. ob die Gruppenvariable (UV) einen “Einfluss” oder “Effekt” auf die abhängige metrische Variable (AV) hat. Dabei ist wichtig, dass mit “Effekt” nicht zwingend ein kausaler Zusammenhang gemeint ist. Eine Varianzanalyse, die den Einfluss einer unabhängigen Variable (ein Faktor) untersucht, wird als einfaktorielle Varianzanalyse bezeichnet.\nDies bedeutet, dass die abhängige Variable (AV) als Merkmal mit der Varianzanalyse untersucht wird. Die unabhängige Variable (UV) ist die erklärende Variable - auch Faktor genannt. Ein Faktor kann zwei oder mehr Stufen haben. Die abhängige Variable muss metrisch und der Faktor kategorial sein. Die einfaktorielle Varianzanalyse ohne Messwiederholung stellt eine Erweiterung des t-Tests für unabhängige Stichproben bei mehr als zwei Stichproben dar.\nSind in jeder Gruppe gleich viele Personen bzw. Datenpunkte, spricht man von einem balancierten Design. Bei ungleichgrossen Gruppen handelt es sich um ein unbalanciertes Design.\nDie Varianzanalyse wird häufig auch ANOVA genannt (engl. ANalysis Of VAriance, kurz ANOVA).\nDie einfaktorielle Varianzanalyse überprüft somit die Auswirkung einer gestuften, unabhängigen Variable (= Faktor) auf eine abhängige Variable.\nTypische Fragestellungen:\nBeispiel einer mehrfaktorielle ANOVA:",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova1.html#anwendungsbereich",
    "href": "datenanalyse/anova1.html#anwendungsbereich",
    "title": "11  Einfaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "",
    "text": "Eine einfaktorielle Varianzanalyse kann mit einem Faktor von zwei Stufen berechnet werden. In diesem Fall entspricht der quadrierte t-Wert dem F-Wert (\\(t^2 = F\\)).\n\n\n\n\n\n\nUnterscheiden sich die Symptome auf einer Angstskala von Patient:innen in verschiedenen Therapierichtung (Kognitive Verhaltenstherapie, Psychoanalyse, Systemische Therapie?\nUnterscheiden sich Studierende in ihrer Konzentrationsfähigkeit Y, wenn sie 4, 6, 8 oder 10 Stunden geschlafen haben?\nHat die verwendete Lerntechnik (keine Technik, Wiederholen, Mnemotechnik) einen Einfluss auf die Anzahl richtig gelöster Prüfungsaufgaben?\n\n\n\nGonsalvez, C. J., Riebel, T., Nolan, L. J., Pohlman, S., & Bartik, W. (2023). Supervisor versus self-assessment of trainee competence: Differences across developmental stages and competency domains. Journal of Clinical Psychology, 79, 2959–2973. https://doi.org/10.1002/jclp.23590",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova1.html#voraussetzungen",
    "href": "datenanalyse/anova1.html#voraussetzungen",
    "title": "11  Einfaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "11.2 Voraussetzungen",
    "text": "11.2 Voraussetzungen\n\nVoraussetzungen einfaktorielle Varianzanalyse ohne Messwiederholung, Überprüfung und mögliche Alternativen bei Verletzung der Annahmen\n\n\n\n\n\n\n\nVoraussetzung\nBeschreibung\nVorgehen bei Verletzung\n\n\n\n\nAbhängige Variable\nEine abhängige Variable mit metrischem Skalenniveau. Die AV muss in den den Teilpopulationen stetig und normalverteilt sein (bei genügend grosser Stichprobe ist der F-Test robust).\nTransformieren der Variable oder Verwenden von non-parametrischen Verfahren: Falls die AV ordinalskaliert ist, kann ein non-parametrisches (verteilungsfreies) Verfahren gewählt werden; z.B. Kruskal-Wallis-Test.\n\n\nUnabhängige Variable\nEine unabhängige Variable mit zwei oder mehr Stufen (kategoriale Gruppenvariable).\nVerwenden eines anderen statistischen Verfahrens (z.B. Regression) oder Kategorisierung der UV.\n\n\nUnabhängigkeit der Messwerte\nDie Messwerte innerhalb der beiden Stichproben sind voneinander unabhängig. Es handelt sich um einfache, innerhalb der Stichprobe voneinander unabhängigen, Zufallsstichproben.\n\n\n\nUnabhängigkeit der Gruppen/Stichproben\nDie Messwerte zwischen den Stichproben sind voneinander unabhängig (unabhängige Gruppen). Eine Verletzung der Unabhängigkeitsannahme liegt vor, wenn die Annahme, dass die Messwerte zwischen den Stichproben unabhängig sind, nicht zutrifft, d.h. die Messwerte mit Messwiederholung vorliegen.\nFür die Abhängigkeit der Gruppen kann kontrolliert werden, indem z.B. ein Varianzanalyse mit Messwiederholung verwendet wird\n\n\nVarianzhomogenität / Homoskedastizität\nDie Varianzen zwischen den Teilpopulationen sind homogen (Homoskedastizität). Vor allem wenn die Stichproben unterschiedlich gross sind, bietet sich eine empirische Überprüfung der Varianzhomogenitätsannahme an.\nÜberprüfung der Varianzhomogenitätsannahme:  Der Vergleich Stichprobenvarianzen mittels F-Test oder Levene-Test (robuste Variante zum F-Test).  Bei Verletzung der Varianzhomogenitätsannahme (Heteroskedastizität), kann als Alternative auf robuste Verfahren oder den Welch-Test bzw. Brown-Forsythe-Test zurückgegriffen werden, die zur Berechnung der Teststatistik die unterschiedlichen Populationsvarianzen einbeziehen.\n\n\n\n\n\nAuf alternative statistische Verfahren bei Verletzung der Annahmen (z.B. Transformationen oder non-parametrische Verfahren) wird in diesem Semester nicht eingegangen.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova1.html#grundkonzepte-und-vorgehen",
    "href": "datenanalyse/anova1.html#grundkonzepte-und-vorgehen",
    "title": "11  Einfaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "11.3 Grundkonzepte und Vorgehen",
    "text": "11.3 Grundkonzepte und Vorgehen\n\n\n\nAllgemeiner Workflow der Datenanalyse\n\n\n\n11.3.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\nNotation\n\\(n\\): Stichprobengrösse insgesamt\n\\(J\\): Anzahl Faktorstufen\n\\(m\\): Beobachtungseinheit (Person)\n\\(j\\): Bedingung (Faktorstufe, Merkmalsausprägung der nominalskalierten unabhängigen Variable)\n\\(x_{mj}\\): \\(m\\)-te Person (oder Messung) in der \\(j\\)-ten Faktorstufe\nUngerichtete Hypothesen:\nMit der einfaktoriellen Varianzanalyse wird die Nullhypothese, dass die Mittelwerte in der Population für jede Gruppen gleich sind, überprüft.\n\n\\(H_0\\): Die Populationsmittelwerte der Gruppen unterscheiden sich nicht (d.h. haben eine Differenz gleich 0): \\(\\mu_1= \\mu_2= \\mu_3\\) bzw. \\(\\mu_i= \\mu_j\\) für alle Paare (\\(i\\), \\(j\\)), \\(i \\neq j\\)\n\\(H_1\\): Mindestens zwei Populationsmittelwerte der Gruppen unterscheiden sich (d.h. haben eine Differenz ungleich 0): \\(\\mu_i \\neq\\mu_j\\) für mindestens ein Paar (\\(i\\),\\(j\\)), \\(i \\neq j\\)\n\nBei \\(J=2\\) Faktorstufen ist der F-Test äquivalent zu einem t-Test für unabhängige Stichproben. Es gilt \\(t^2=F\\).\nBei \\(J&gt;2\\) Faktorstufen ist der F-Test ein Globaltest (Omnibus-Test), mit dem lediglich ermittelt werden kann, ob die Unterschiede zwischen den Bedingungsmittelwerten signifikant von 0 abweichen, daher werden auch die Hypothesen entsprechend formuliert. Häufig ist man jedoch daran interessiert, ob sich bestimmte Mittelwertspaare signifikant unterscheiden. Eine Möglichkeit dazu bieten Post-hoc-Tests oder Kontrastanalysen. Bei \\(J\\) Bedingungen gibt es \\(s = J \\cdot (J-1)/2\\) (nicht-redundante) Paarvergleiche.\nDa der F-Wert über die Quadratsummen berechnet wird, können F-Werte nur zwischen 0 und \\(+ \\infty\\) liegen. Das bedeutet, dass nur die rechte Seite der Verteilung zur Bestimmung der kritischen Werte verwendet wird. Die Alternativhypothese ist immer ungerichtet und wird einseitig getestet.\nMit sogenannten Post-hoc Paarvergleichen können jedoch auch gerichtete Hypothesen getestet werden, da diese mit einer t-Verteilung geprüft werden.\nSignifikanzniveau:\nWird ein Signifikanzniveau von \\(\\alpha = 0.05\\) festgelegt, bedeutet dies, dass bei der Verwerfung der Nullhypothese eine 5% Wahrscheinlichkeit besteht, dass eigentlich kein Unterschied zwischen den Mittelwerten besteht und irrtümlicherweise mindestens einer angenommen wurde.\n\n\nA-priori Poweranalyse durchführen\nMit einer a-priori Poweranalyse kann im Vornherein die Planung des optimalen Stichprobenumfangs vorgenommen werden. Dies wird hier im Rahmen dieser Veranstaltung nicht weiter vertieft.\nFür experimentellen Studien ist es jedoch sinnvoll gleich grosse Bedingungsstichproben zu wählen, da die Varianzanalyse unter dieser Bedingung robuster gegen Verletzungen ihrer Annahmen ist.\n\n\n\n11.3.2 Vorverarbeitung\n\nDaten einlesen, vorverarbeiten und visualisieren\nZuerst müssen die Daten eingelesen und bereinigt werden. Daten können diagnostisch visualisiert werden, um z.B. fehlende Werte zu entdecken oder Verteilungen der Daten visuell beurteilen und Extremwerte zu identifizieren.\nFür die einfaktorielle Varianzanalyse bzw. den F-Test mit dem Package {afex} werden die Daten in einem long-Format benötigt.\n\n\nVoraussetzungen überprüfen\nVarianzhomogenität\nDer F-Test für unabhängige Stichproben setzt Varianzhomogenität voraus. Dies kann in R mit dem Levene-Test car::leveneTest überprüft werden.\nDer Levene-Test geht von der Nullhypothese aus, dass sich die Varianzen zwischen den Bedingungen nicht unterscheiden. Ein nicht signifikantes Ergebnis bedeutet daher, dass sich die Varianzen nicht unterscheiden und somit Varianzhomogenität (sogenannte Homoskedastizität) besteht. Wenn der Test signifikant ist, wird Varianzheterogenität angenommen.\nFalls die Varianzen heterogen (unterschiedlich) sind , müssen die Freiheitsgrade des F-Wertes entsprechend angepasst werden. Vor allem wenn ungleichen Stichprobengrössen vorliegen, sollte auf den Welch-Test oder Brown-Forsythe-Test zurückgegriffen werden, die zur Berechnung der Teststatistik die unterschiedlichen Populationsvarianzen einbeziehen.\n\n\n\n11.3.3 Analyse\n\nDeskriptivstatistik und Visualisierung\nBei Gruppenunterschieden wird für jede Gruppe ein Lagemass (z.B. Mittelwert oder Median) sowie ein Streumass (z.B. Standardabweichung, Standardfehler, Konfidenzintervall) berechnet. Das Lagemass stellt die durchschnittliche Merkmalsausprägung pro Bedingung dar. Das Streumass zeigt den Streubereich der Daten pro Bedingung auf.\n\nGenauere Informationen zu Lage- und Streumassen sind im Kapitel: Deskriptive Statistik zu finden.\n\nZur Visualisierung von Unterschieden eignen sich Lagemasse mit Fehlerbalken. Boxplots eignen sich beispielsweise gut, um Grösse der Unterschiede (Effekte) und die Kohärenz der Datenpunkte (Ähnlichkeit der Werte innerhalb einer Bedingung/Gruppe) zu beurteilen.\nDurch die Visualisierung der Rohwerte, kann die Verteilung der Messungen gut eingeschätzt werden und Extremwerte werden deutlich sichtbar. Bei zu vielen Datenpunkten führt das Visualisieren der Rohwerte zu unübersichtlichen Grafiken.\n\n\nTeststatistik berechnen\nUm zu überprüfen, ob mindestens eine Mittelwertsdifferenz signifikant unterschiedlich von 0 ist, muss die Teststatistik berechnet werden.\nÜberprüfung der Nullhypothese mit dem F-Test\nUm die Nullhypothese zu prüfen, verwenden wir den F-Test als Prüfgrösse. Lehnt man die Nullhypothese einer Varianzanalyse mit \\(J&gt;2\\) Bedinungen ab, weiss man zwar, dass es Unterschiede gibt, man weiss jedoch noch nicht, welcher Stichprobenmittelwert von welchem anderen bedeutsam abweicht.\nDie Prüfgrösse berechnet sich als Verhältnis der zwei mittleren Quadratsummen:\n\\(F=\\frac{MQS_{zw}}{MQS_{inn}}\\)\n\nDie \\(H_0\\) wird beibehalten, wenn die empirische Prüfgrösse F kleiner als der kritische Wert ist. Die Gruppen unterscheiden sich nicht signifikant bzw. es konnte kein Einfluss der Gruppenvariable auf die AV gefunden werden.\nDie \\(H_0\\) wird abgelehnt, wenn die empirische Prüfgrösse F grösser als der kritische Wert ist. Die Gruppen unterscheiden sich signifikant bzw. es konnte ein Einfluss der Gruppenvariable auf die AV gefunden werden.\n\nQuadratsummenzerlegung\nBei der einfaktoriellen Varianzanalyse ohne Messwiederholung wird die Variation der Messwerte in zwei Quellen zerlegt: Unterschiede zwischen den Gruppen \\(QS_{zw}\\) und Unterschiede innerhalb der Gruppen \\(QS_{inn}\\).\nAdditivität der Quadratsummen\nDie totale Quadratsumme wird zerlegt in eine Quadratsumme, die die Variation zwischen den Bedingungen ausdrückt, und eine Quadratsumme, die die Variation zwischen den Messwerten innerhalb der Bedingungen ausdrückt :\n\\(QS_{tot}=QS_{zw}+QS_{inn}\\)\n\nTotale Quadratsumme (Prädiktionsfehler ohne Berücksichtigung der UV): \\(QS_{tot}=\\sum^J_{j=1} \\sum^{n_j}_{m=1} (x_{mj}- \\overline{x})^2\\)\nInnerhalb-Quadratsumme (Prädiktionsfehler mit Berücksichtigung der UV): \\(QS_{inn}=\\sum^J_{j=1} \\sum^{n_j}_{m=1} (x_{mj}- \\overline{x}_j)^2\\)\nZwischen-Quadratsumme (Reduktion des Prädiktionsfehlers durch die Berücksichtigung der UV): \\(QS_{zw}=\\sum^J_{j=1} \\sum^{n_j}_{m=1} (\\overline{x}_j- \\overline{x})^2=\\sum^J_{j=1} n_j\\cdot (\\overline{x}_j- \\overline{x})^2\\)\n\nMittlere Quadratesummen und ihre Freiheitsgrade\nFür die Berechnung der mittleren Quadratsummen werden die jeweiligen Quadratsummen durch ihre Freiheitsgrade dividiert.\n\\(MQS_{tot}=\\frac{QS_{tot}}{n-1}\\)\n\\(MQS_{zw}=\\frac{QS_{zw}}{J-1}\\)\n\\(MQS_{inn}=\\frac{QS_{inn}}{n-J}\\)\n\n\nEffektstärke bestimmen\nDie Effektgrösse beim F-Test sagt etwas darüber aus, wie gross der Unterschied zwischen den Populationsmittelwerten ist.\nHäufig wird dazu \\(\\eta^2\\) verwendet. Die standardisierte Effektgrösse \\(\\eta^2\\) für eine einfaktorielle Varianzanalyse ohne Messwiederholung lässt sich anhand des Quotienten aus der Zwischen-Quadratsumme und der Gesamtquadratsumme berechnen:\n\\(\\hat \\eta^2=\\frac{QS_{tot}-QS_{inn}}{QS_{tot}}=\\frac{QS_{zw}}{QS_{tot}}=\\frac{F \\cdot {df}_{zw}}{F \\cdot df_{zw} + df_{inn}}\\)\nDie Konventionen für \\(\\eta^2\\) lauten in Anlehnung an Cohen (1988):\n\n\\(\\eta^2=\\approx 0.01\\): kleiner Effekt\n\\(\\eta^2=\\approx 0.06\\): mittlerer Effekt\n\\(\\eta^2=\\approx 0.14\\): grosser Effekt\n\n\n\n\n11.3.4 Paarvergleiche und Post-hoc-Test\nPaarvergleiche\nBei drei Gruppen/Bedingungen sind \\(s = J \\cdot (J-1)/2=3\\) Paarvergleiche möglich.\n\n\\(\\mu_1 = \\mu_2\\)\n\\(\\mu_1 = \\mu_3\\)\n\\(\\mu_2 = \\mu_3\\)\n\nDer t-Wert für Post-hoc Paarvergleich wird folgendermassen berechnet (analog zum t-Wert bei unabhängigen Stichproben, aber mit Ergänzung der geschätzten Fehlervarianz über alle Bedingungen, \\(MQS_{inn}\\)):\n\\(t = \\frac{\\overline{x}_j - \\overline{x}_{j'}}{\\sqrt {(\\frac{1}{n_j}+\\frac{1}{n_{j'}}) \\cdot MQS_{inn}}}\\)\nUnter Gültigkeit der Nullhypothese folgt die Prüfgrösse einer t-Verteilung mit \\(df=n–J\\) Freiheitsgraden.\nMultiples Testen\nBei einer Verwerfung der Nullhypothese der Varianzanalyse mit \\(\\alpha = 0.05\\) beträgt die Wahrscheinlichkeit einer irrtümlichen Entscheidung (also dem Fehler 1. Art) \\(5 \\%\\).\nBei mehreren Paarvergleichen kumuliert sich hingegen dieser \\(\\alpha\\)-Fehler. Die Wahrscheinlichkeit bei mindestens einem der \\(s\\) Tests die Nullhypothese fälschlicherweise zu verwerfen, wird wie folgt berechnet:\n\\(\\alpha_{fam}=1-(1- \\alpha_r)^s\\)\nBei \\(s=3\\) und einem \\(\\alpha = 0.05\\) würde der \\(\\alpha\\)-Fehler bei \\(0.1425\\) (statt \\(0.005\\)) liegen, weil \\(\\alpha_{fam}=1-0.95^3=0.1425\\).\nAdjustierung der spezifischen Irrtumswahrscheinlichkeit\nEs ist daher sinnvoll, im vornherein ein strengeres Signifikanzniveau für jeden einzelnen der \\(s\\) Paarvergleiche anzusetzt. Aus der vorherigen Formel leitet sich ab, dass zur Verwerfung einer Globalhypothese mit \\(s\\) Vergleichen auf einem vorher festgelegten \\(\\alpha_{fam}\\)-Niveau mindestens ein Einzeltest die folgende Irrtumswahrscheinlichkeit \\(\\alpha_r\\) erreichen oder unterschreiten muss. Dies kann somit (nach Šidák) zur Adjustierung der Irrtumswahrscheinlichkeit genutzt werden.\n\\(\\alpha_r=1-\\sqrt[s]{1-\\alpha_{fam}}=1-\\sqrt[3]{1-0.05}=0.01695\\)\nBonferroni: Eine ähnliche, aber einfachere Korrektur, ist die Bonferroni-Adjustierung. Hier wird das \\(\\alpha_{fam}\\)-Niveau durch die Anzahl Paarvergleiche \\(s\\) geteilt und so adjustiert. Je mehr Mittelwertsvergleiche vorgenommen werden, umso stärker geht diese Strategie der Bonferroni-Korrektur mit einem Verlust an Power einher.\n\\(\\alpha_r=\\frac{\\alpha_{fam}}{s}=\\frac{0.05}{3}=0.01667\\)\nBonferroni-Holm: Eine etwas weniger strenge Adjustierung ist die “Bonferroni-Holm-Adjustierung”, die vier Schritte umfasst:\n\nFestlegung von \\(\\alpha_{fam}\\)\nDurchführung der \\(s\\) Paarvergleiche und Ermittlung der jeweiligen \\(p_r\\)-Werte. Ein \\(p_r\\)-Wert ist der \\(p\\)-Wert des \\(r\\)-ten Paarvergleichs.\nSortieren der Paarvergleiche nach den \\(p_r\\)-Werten in aufsteigender Reihenfolge (vom »signifikantesten« zum am wenigsten signifikanten Effekt). Hier können auch die \\(t\\)-Werte genutzt werden.\nBestimmung des adjustierten spezifischen Signifikanzniveaus auf der Basis der Gleichung: \\(\\alpha_r = \\frac {\\alpha_{fam}} {s-(r-1)}\\)\n\nDie \\(s\\) Paarvergleiche werden also auf unterschiedlich adjustierten spezifischen Signifikanzniveaus durchgeführt. Der Mittelwertsunterschied mit dem »signifikantesten« Effekt wird auf dem strengsten Niveau \\(\\alpha_1 = \\frac{\\alpha_{fam}}{s}\\) durchgeführt, der nächste mit \\(\\alpha_2 = \\frac{\\alpha_{fam}}{s-1}\\) usw.\nDer letzte Paarvergleich wird dann auf dem unadjustierten Signifikanzniveau \\(\\alpha_s=\\alpha_{fam}\\) getestet. Wenn bei einem Paarvergleich \\(p_r\\)&gt;\\(\\alpha_r\\), dann werden alle weiteren Paarvergleichs-Nullhypothesen nicht mehr abgelehnt. Die Bonferroni-Holm-Methode hat dadurch eine grössere Power als die Bonferroni-Adjustierung.\nPrüfen einer gerichteten Hypothese: Die Hypothese einer Varianzanalyse entspricht einem zweiseitigen t-Test und einer ungerichteten Hypothese. Wenn man hingegen eine gerichtete Hypothese testen will, was im Vornherein festgelegt werden muss, müssen die \\(p\\)-Werte halbiert werden.\nAdjustierung der kritischen Werte\nAnstatt der Irrtumswahrscheinlichkeit, können auch die kritischen Werte mit der Tukey-Adjustierung korrigiert werden.\nDer Tukey-Test setzt voraus, dass für alle J Bedingungen gleiche Stichprobengrössen vorliegen. Bei unbalancierten Stichproben wird der Tukey-Kramer-Test oder der Scheffé-Test verwendet. Nur die Tukey-Adjustierung ist eigentlich für einen vollständigen Paarvergleich aller Bedingungen wie hier geeignet, da sie mehr Power hat als Tests auf Basis der Bonferroni-Korrektur.\nDie anderen Adjustierungsmethoden sollten vorzugsweise für ein Subset von Bedingungsvergleichen benutzt werden. Diese müssten dann zuerst als ein Set von Kontrasten definiert werden. Wenn wir also alle Mittelwerte vergleichen wollen, wählen wir den Tukey-Test. Der Tukey-Test wird zweiseitig durchgeführt.\nWahl der Adjustierung\nAuf welche Strategie sollte man zurückgreifen? Hier gibt es lediglich gewisse Empfehlungen:\n\nWenn ein vollständiger Vergleich aller Mittelwertsunterschiede getestet werden soll bzw. wenn a priori keine gezielten Hypothesen vorliegen: Tukey-Test.\nWenn gezielte Mittelwertsunterschiede (bzw. Kontraste) getestet werden sollen: Bonferroni-Holm-Adjustierung. Diese ist der Bonferroni-Adjustierung vorzuziehen.\nBei einem unbalancierten Design, d.h. wenn nicht gleich grosse Gruppen vorliegen, sollte alternativ der Tueky-Kramer-Test oder der Scheffé-Test verwendet werden.\n\nDies ist jedoch keine abschliessende Liste, da es weitere Adjustierungsmöglichkeiten gibt, die je nach Datenstruktur, Design oder weitere Kriterien sinnvoll sind. Ausserdem ist eine Adjustierung weder immer nötig noch sinnvoll, da durch die Korrektur der Fehler 2. Art erhöht wird, was mit einer geringerer Power einher geht (Tabachnick & Fidell, 2007).\n\n\n11.3.5 Kontrastanalysen\nDie Kontrastanalyse kann als eine spezielle Form der Varianzanalyse verstanden werden. Mittels Kontrastanalyse können Kombinationen von Mittelwerten aber auch ein Einzelvergleich zweier Mittelwerte geprüft werden. Hat man eine spezifische Hypothese über die Struktur der Mittelwertsunterschiede, so können Hypothesen mithilfe spezifischer Werte für die Kontrastkoeffizienten, also die »Gewichte« der Mittelwerte, ausgedrückt werden.\nDas Ergebnis einer Kontrastanalyse ist von der Metrik der Kontrastkoeffizienten unabhängig. Die Summe der Kontrastkoeffizienten ergibt 0: \\(\\sum^J_{j=1} K_j=0\\)\nKontraste werden wie der Omnibustest der Varianzanalyse in der Regel mit einem F-Test geprüft. Daher wird eine ungerichtete Hypothese getestet. Um eine gerichtete Hypothese zu überprüfen, muss der \\(p\\)-Wert halbiert werden.\nEine Kontrastanalyse kann jedoch auch direkt anhand der Prüfgrösse t getestet werden. Dies hat den Vorteil, dass der t-Test eine direkte Testung einer gerichteten Hypothese erlaubt. In R wird der t-Wert und der \\(p\\)-Wert für die ungerichtete Hypothese ausgegeben. Um eine gerichtete Hypothese zu überprüfen, muss der \\(p\\)-Wert halbiert werden.\n\nEinfacher Kontrast: Test auf Abweichung zweier Gruppen\n\n\nAlternativhypothese\nK1\nK2\nK3\nK4\n\\(\\sum\\)\n\n\n\n\n\\(\\mu_1 &lt; \\mu_2\\)\n-1\n1\n0\n0\n0\n\n\n\\(\\mu_1 &lt; \\mu_3\\)\n-1\n0\n1\n0\n0\n\n\n\\(\\mu_1 &lt; \\mu_4\\)\n-1\n0\n0\n1\n0\n\n\n\n\nAbweichungskontrast: Test auf Abweichung einer Gruppe vom Mittel aller anderen Gruppen\n\n\n\n\n\n\n\n\n\n\nAlternativhypothese\nK1\nK2\nK3\nK4\n\\(\\sum\\)\n\n\n\n\n\\(\\mu_1&lt;\\frac{\\mu_2 + \\mu_3 + \\mu_4}{3}\\)\n-3\n1\n1\n1\n0\n\n\n\\(\\mu_2&lt;\\frac{\\mu_1 + \\mu_3 + \\mu_4}{3}\\)\n1\n-3\n1\n1\n0\n\n\n\n\n\n11.3.6 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nDie Ergebnisse der Varianzanalyse werden in der Regel mit dem empirischen F-Wert, den Freiheitsgraden, dem entsprechenden p-Wert und/oder Konfidenzintervall und einer Effektgrösse berichtet.\nInferenzstatistische Kennwerte (z.B. t und F) werden mit zwei Dezimalen berichtet.1 In den Klammern werden bei einer Varianzanalyse die Freiheitsgrade des Zählers (\\(df_{zw}\\)) und des Nenners (\\(df_{inn}\\)) angegeben. Als Effektgrössenschätzer wird häufig \\(\\eta^2\\) angegeben.\n\nDie einfaktorielle Varianzanalyse ergab, dass sich die Gruppen signifikant in ihrer kognitiven Leistung unterscheiden, F(2, 12) = 10.87, p = .002, \\(\\eta^2\\) = 0.64. Post-hoc-Tests mit Bonferroni-Holm-Korrektur zeigten, dass die Gruppe “kognitive Umstrukturierung” (M = 2, SD = 1.41) signifikant niedrigere Werte aufwies als die Gruppe “Mindfulness” (M = 6, SD = 2.34), F(12) = 11,43, p = .011, und die Gruppe “Entspannung” (M = 7, SD = 1.87), F(12) = 17.86, p = .004. Die Ergebnisse deuten darauf hin, dass kognitive Umstrukturierung im Vergleich zu Mindfulness und Entspannung einen positiven Effekt auf die Verringerung von Angstsymptomen hat.\n\n\nThe one-way ANOVA revealed a significant effect of condition on anxiety symptoms, F(2, 12) = 10.87, p = .002, \\(\\eta^2\\) = 0.64. Post hoc comparisons using Bonferroni-Holm-Test indicated that group restructuring (M = 2, SD = 1.41) had significantly lower scores than group mindfulness (M = 6, SD = 2.34), F(12) = 11.43, p = .011, and group relaxation (M = 7, SD = 1.87), F(12) = 17.86, p = .004. The results suggest that restructuring had a positive effect on reducing anxiety symptoms compared to mindfulness and relaxation.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova1.html#anwendungsbeispiel-in-r",
    "href": "datenanalyse/anova1.html#anwendungsbeispiel-in-r",
    "title": "11  Einfaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "11.4 Anwendungsbeispiel in R",
    "text": "11.4 Anwendungsbeispiel in R\n\n\n\n\n\n\nBeispiel: Therapiemethoden bei Angstsymptomatik\n\n\n\nIn einem fiktiven Experiment wurden drei verschiedene Therapiemethoden verglichen und untersucht, welchen Effekt die Therapiemethode auf die Angstsymptomatik hat. Dazu wurden 15 Personen zufällig auf die drei Bedingungen aufgeteilt.\n\nDie unabhängige Variable sind die Therapiemethoden mit 3 Faktorstufen (Mindfulness, Entspannung, Kognitive Umstrukturierung)\nDie abhängige Variable entspricht der Höhe der Angstsymptomatik nach dem Treatment (metrisch).\n\n\n\n\n11.4.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\n\\(H_0\\): Die Therapiemethode hat keinen Einfluss auf die Angstsymptome: \\(\\mu_1=\\mu_2=\\mu_3\\)\n\\(H_1\\): Die Therapiemethode hat einen Einfluss auf die Angstsymptome: \\(\\mu_i \\neq\\mu_j\\) für mindestens ein Paar (\\(i\\),\\(j\\)), \\(i \\neq j\\)\nDas Alphaniveau wird auf \\(5 \\%\\) festgelegt. Es handelt sich um eine ungerichtete Hypothese, die Testung erfolgt mit dem F-Test jedoch immer einseitig.\n\n\nA-priori Poweranalyse durchführen\n\nDie a-priori Poweranalyse bei einer Varianzanalyse wird in diesem Semester nicht behandelt.\n\n\n\n\n11.4.2 Vorverarbeitung\n\nDaten einlesen und vorverarbeiten\n\n\n\n\n\n\nHands-on: Beispieldatensatz Therapiemethode\n\n\n\nDaten herunterladen und einlesen\nHier kann der Projektordner mit den Daten heruntergeladen werden. Vor dem ersten Verwenden muss der Ordner entzippt werden, dann kann das RProject namens anova.Rproj geöffnet werden. Der Ordner enthält:\n\nRProject namens anova.Rproj\nDatensatz anova_therapy.csv und anova_music.csv in data-Ordner\nRNotebook namens einfaktorielleanova.Rmd\nEs werden folgende Packages verwendet: {tidyverse}, {afex}, {emmeans}, {beeswarm}, {effectsize}\nDatensatz anova_therapy.csv einlesen:\n\n\n# Package laden\nlibrary(tidyverse)\n\n# Daten laden und anschauen\nd_therapy3 &lt;- read.csv(\"data/anova_therapy.csv\") |&gt;\n    glimpse() \n\nRows: 15\nColumns: 3\n$ id        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n$ condition &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"mindfulness\", \"mindfulness\", …\n$ symptoms  &lt;int&gt; 6, 9, 7, 3, 5, 9, 7, 8, 4, 7, 1, 3, 4, 1, 1\n\n\nDatensatz transformieren\nDie Daten liegen bereits im long Format vor. Die Variablen id und condition müssen jedoch noch zu einem Faktor konvertiert werden.\n\n# Faktoren definieren \nd_therapy3 &lt;- d_therapy3 |&gt;\n  mutate(id = as.factor(id)) |&gt;\n  mutate(condition = as.factor(condition)) |&gt;\n  glimpse()\n\nRows: 15\nColumns: 3\n$ id        &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n$ condition &lt;fct&gt; mindfulness, mindfulness, mindfulness, mindfulness, mindfuln…\n$ symptoms  &lt;int&gt; 6, 9, 7, 3, 5, 9, 7, 8, 4, 7, 1, 3, 4, 1, 1\n\n\n\n\n\n\nVoraussetzungen überprüfen\nDer F-Test für eine einfaktorielle Varianzanalyse setzt voraus, dass die AV in der Population stetig und normalverteilt ist und die Populationsvarianzen homogen sind.\n\nDie Voraussetzung der Normalverteilung wird in diesem Semester nicht überprüft.\n\nDie Varianzhomogenität (Homoskedastizität) kann mit dem Levene-Test leveneTest(y ~ x, data = dataset) überprüft werden. Die Funktion leveneTest() stammt aus dem Package {car}. Ein Levene-Test mit \\(p &lt; 0.05\\) bedeutet, dass der Varianzunterschied signifikant ist. Die Nullhypothese, dass die beiden Varianzen auf Populationsebene identisch sind, muss in diesem Fall verworfen werden.\n\nVor dem ersten Verwenden der Funktion leveneTest() muss das Package {car} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"car\").\n\n\n# Levene-Test mit dem package {car}\ncar::leveneTest(symptoms ~ condition, # av ~ uv\n                data = d_therapy3) # Datensatz\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  2  0.2545 0.7794\n      12               \n\n\nDer Test ist hier nicht signifikant (\\(p = .779\\)), daher wird davon ausgegangen, dass die Varianzen in den Gruppen homogen sind und die Voraussetzung der Varianzhomogenität erfüllt ist.\n\n\n\n11.4.3 Analyse\n\nDeskriptivstatistik und Visualisierungn\nFür die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden.\n\n# Nach condition gruppieren und symptoms zusammenfassen\nd_summary &lt;- d_therapy3 |&gt;\n  group_by(condition) |&gt; # Gruppieren\n  summarise(mean_symptoms = mean(symptoms), # Mittelwert\n            sd_symptoms = sd(symptoms)) # Standardabweichung\nd_summary\n\n# A tibble: 3 × 3\n  condition     mean_symptoms sd_symptoms\n  &lt;fct&gt;                 &lt;dbl&gt;       &lt;dbl&gt;\n1 mindfulness               6        2.24\n2 relaxation                7        1.87\n3 restructuring             2        1.41\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeststatistik berechnen\nFalls der empirische F-Wert grösser als der kritische F-Wert ist, wird von einem signifikanten Unterschied zwischen mindestens zwei Mittelwerten ausgegangen.\nBerechnung Teststatistik in R mit der Funktion aov_4()\nEine einfaktorielle Varianzanalyse kann mit der Funktion aov_4(av ~ uv, + (1 | id), data) aus dem Package {afex} berechnet werden.\n\nav: Abhängige Variable (metrisch)\nuv: Unabhängige Variable (Bedingung oder Gruppenvariable)\n(1 | id): Die Funktion benötigt eine Identifikationsvariable (hier id), d.h. eine Variable, in der jede Person einen einzigartigen Wert hat. Da wir keine Messwiederholung haben, wird eine 1 vor dem | verwendet. Bei Messwiederholung wird hier spezifiziert, welche Variable sich innerhalb von id wiederholt.\n\n\nVor dem ersten Verwenden muss das Package {afex} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"afex\").\n\n\nlibrary(afex)\n\n# Einfaktorielle Anova ohne Messwiederholung berechnen\nm_anova1 &lt;- aov_4(symptoms ~ condition + (1 | id), # av ~ uv + (1 | Identifikationsvariable)\n                data = d_therapy3) # dataset\nsummary(m_anova1) \n\nAnova Table (Type 3 tests)\n\nResponse: symptoms\n          num Df den Df MSE  F   ges   Pr(&gt;F)   \ncondition      2     12 3.5 10 0.625 0.002781 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm_anova1$Anova\n\nAnova Table (Type III tests)\n\nResponse: dv\n            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)    375  1  107.14 2.464e-07 ***\ncondition       70  2   10.00  0.002781 ** \nResiduals       42 12                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDie Mittelwerte der Bedingungen unterscheiden sich signifikant auf dem \\(5 \\%\\)-Niveau. Die Nullhypothese, wonach sich die Mittelwerte nicht unterscheiden, kann verworfen werden. Die Therapiemethode hat somit einen Einfluss auf die Angstsymptomatik. Aufgrund dieser Analyse ist hingegen (noch) nicht klar, welche Bedingungen sich unterscheiden. Dies wird in einem nächsten Schritt mit sogenannten Post-hoc-Vergleichen überprüft.\nZur Visualisierung der Ergebnisse eignet sich ein Plot, der die Mittelwerte und Standardfehler abbildet. Dazu kann die Funktion afex_plot aus dem Package {afex} verwendet werden. Um die Standardfehler, anstelle der Konfidenzintervall, anzuzeigen, kann error_ci = FALSE verwendet werden.\n\n# Plot\nplot_anova &lt;- afex_plot(object = m_anova1, # Objekt mit Anovamodell\n          x = \"condition\",  # uv (Faktor)\n          error_ci = FALSE) + # Anzeigen von Standardfehler der Mittelwerte\n          theme_minimal()\nplot_anova\n\n\n\n\n\n\n\n\nPost-hoc-Vergleiche\nZuerst muss dazu mit der Funktion emmeans() aus dem Package {emmeans} ein Objekt, z.B. m_anova1_results, erstellt werden. Darin werden die “Estimated Marginal Means” gespeichert.\n\nVor dem ersten Verwenden muss das Package {emmeans} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"emmeans\").\n\n\n# Package emmeans laden\nlibrary(emmeans)\n\nWarning: package 'emmeans' was built under R version 4.4.3\n\n# Resultate (estimated marginal means) speichern\nm_anova1_result &lt;- emmeans(object = m_anova1, specs = ~ condition) # object = anova modell, ~ uv\nm_anova1_result\n\n condition     emmean    SE df lower.CL upper.CL\n mindfulness        6 0.837 12    4.177     7.82\n relaxation         7 0.837 12    5.177     8.82\n restructuring      2 0.837 12    0.177     3.82\n\nConfidence level used: 0.95 \n\n\nAus dem Beispiel ergeben sich folgende Mittelwertsunterschiede:\n\nMindfulness vs. Relaxation: \\(\\overline{x}_1-\\overline{x}_2=6-7=-1\\)\nMindfulness vs. Restructuring: \\(\\overline{x}_1-\\overline{x}_3=6-2=4\\)\nRelaxation vs. Restructuring: \\(\\overline{x}_2-\\overline{x}_3=7-2=5\\)\n\nPaarvergleiche können mit der Funktion pairs(x = model, adjust = \"none\") ausgegeben werden. Unter adjust = \"___\" wird definiert, welche Adjustierung vorgenommen wird.\n\n# Post-hoc-Paarvergleich ohne Adjustierung\npairs(x = m_anova1_result, adjust = \"none\") \n\n contrast                    estimate   SE df t.ratio p.value\n mindfulness - relaxation          -1 1.18 12  -0.845  0.4146\n mindfulness - restructuring        4 1.18 12   3.381  0.0055\n relaxation - restructuring         5 1.18 12   4.226  0.0012\n\n\nDie wichtigsten Adjustierungen sind:\n\nBonferroni: \"bonferroni\"\nBonferroni-Holm: \"holm\"\nTukey: \"tukey\"\nScheffé: \"scheffe\"\n\nPaarvergleiche mit dem Tukey-Test\nDer Tukey-Test wird verwendet, wenn sämtliche Mittelwertspaare verglichen werden sollen.\n\n# Post-hoc-Paarvergleich mit Tukey-Test\npairs(x = m_anova1_result, adjust = \"tukey\") \n\n contrast                    estimate   SE df t.ratio p.value\n mindfulness - relaxation          -1 1.18 12  -0.845  0.6833\n mindfulness - restructuring        4 1.18 12   3.381  0.0140\n relaxation - restructuring         5 1.18 12   4.226  0.0031\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nPaarvergleiche mit der Bonferroni-Holm-Adjusierung\nMit der Bonferroni-Holm-Korrektur können wir einzelne, vorher definierte, Paarvergleiche überprüfen, beispielsweise ob Kognitive Umstrukturierung weniger Angstsymptome “bewirkt”, als Mindfulness oder Entspannung.\n\n# Post-hoc-Paarvergleich mit Bonferroni-Holm-Adjustierung\npairs(x = m_anova1_result, adjust = \"holm\") \n\n contrast                    estimate   SE df t.ratio p.value\n mindfulness - relaxation          -1 1.18 12  -0.845  0.4146\n mindfulness - restructuring        4 1.18 12   3.381  0.0109\n relaxation - restructuring         5 1.18 12   4.226  0.0035\n\nP value adjustment: holm method for 3 tests \n\n\nKontrastanalyse\nMit der Funktion levels() kann im Datensatz überprüft werden, in welcher Reihenfolge die Stufen des Faktors condition geordnet sind. Dies ist wichtig, um nun die Kontrasthypothesen richtig zu spezifizieren.\n\nlevels(d_therapy3$condition)\n\n[1] \"mindfulness\"   \"relaxation\"    \"restructuring\"\n\n\nKontrastanalysen erfordern das Definieren von Kontrasten. Ein Kontrast in diesem Beispiel besteht aus drei Werten. In der Summe ergeben die Werte eines Kontrastes 0.\nUngerichtete Hypothese:\n\nDer Mittelwert der Angstsymptome in der Bedingung “Kognitive Umstrukturierung” unterscheidet sich vom Durchschnitt der Mittelwerte in den anderen beiden Bedingungen.\n\nKontraste müssen in R zuerst als Listenobjekt mit list definiert werden. Anschliessend wird das Listenobjekt als method-Argument in der Funktion contrast() verwendet:\n\n# Kontrastanalyse\n## H: Kognitive Umstukturierung unterscheidet sich von anderen Bedingungen\nm_anova1_contrast1 &lt;- list(\"restructuring vs. rest\" = c(-0.5, -0.5, 1)) # Kontrast definieren (Summe 0!)\ncontrast(object = m_anova1_result, method = m_anova1_contrast1) \n\n contrast               estimate   SE df t.ratio p.value\n restructuring vs. rest     -4.5 1.02 12  -4.392  0.0009\n\n\n\nDer Mittelwert der Angstsymptome in der Bedingung “Mindfulness” unterscheidet sich vom Mittelwert der Bedingung “Entspannung”.\n\n\n# Kontrastanalyse\n## H: Mindfulness unterscheidet sich von Entspannung\nm_anova1_contrast2 &lt;- list(\"mindfulness vs. relaxation\" = c(1, -1, 0)) # Kontrast definieren (Summe 0!)\ncontrast(object = m_anova1_result, method = m_anova1_contrast2)\n\n contrast                   estimate   SE df t.ratio p.value\n mindfulness vs. relaxation       -1 1.18 12  -0.845  0.4146\n\n\nBei einer a priori gerichtet formulierten Hypothese, müsste der \\(p\\)-Wert hier noch halbiert werden.\nJe mehr Kontraste überprüft werden, umso stärker steigt der \\(\\alpha_{fam}\\)-Fehler für eine Familie von Kontrasten an. Es ist daher wichtig, dass die Kontraste vorher definiert werden und die entsprechende Korrektur vorgenommen wird.\n\n\nEffektstärke bestimmen\nBerechnung der Effektgrösse \\(\\eta^2\\)\nDie Effektgrösse \\(\\eta^2\\) lässt sich anhand des Quotienten aus der Zwischen-Quadratsumme und der Gesamtquadratsumme berechnen. In R kann dieses Mass direkt mit der Funktion eta_squared() aus dem Package {effectsize} berechnet werden. Als Argument für die Funktion muss das Anova-Modell (Objekt), also hier m_anova1, eingegeben werden.\n\nVor dem ersten Verwenden muss das Package {effectsize} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"effectsize\").\n\n\n# Effektgrösse berechnen\neffectsize::eta_squared(m_anova1)\n\n# Effect Size for ANOVA (Type III)\n\nParameter | Eta2 |       95% CI\n-------------------------------\ncondition | 0.62 | [0.25, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nDie Effektgrösse liegt bei \\(\\eta^2=0.62\\). Es handelt sich nach der Taxonomie von Cohen (1988) um einen grossen Effekt.\n\n\n\n11.4.4 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\na. Ergebnisse der einfaktoriellen Varianzanalyse ohne Messwiederholung__\nDas Ergebnis ist auf dem \\(5 \\%\\)-Niveau signifikant und die Nullhypothese kann somit verworfen werden: Die Therapiemethode beeinflusst die Höhe der Angstsymptomatik. Es handelt sich nach der Taxonomie von Cohen (1988) um einen grossen Effekt (\\(\\eta^2=0.62\\)).\n\nWe examined whether the therapy methods had an effect on anxiety symptoms. The one-way ANOVA revealed a significant effect of the therapy condition on anxiety symtoms, F(2, 12) = 10.00, p = .003, \\(\\eta^2\\) = 0.62). This indicates a large effect of the therapy condition on anxiety symptoms according to Cohen’s convention (1988).\n\nb. Ergebnisse von Post-hoc-Tests und Kontrastanalysen\n\nPost hoc comparisons using Tukey’s Test indicated that group relaxation (M = 6, SD = 2.34) had significantly higher anxiety symptoms than group restructuring (M = 2, SD = 1.41), F(12) = 17.86, p = .003. Additionally, group mindfulness (M = 7, SD = 1.87) scored also significantly higher than group restructuring, F(12) = 11.43, p = .014. However, group mindfulness and relaxation did not differ significantly, F(12) = 0.71, p = .683. The results suggest that restructuring had a positive effect on reducing anxiety symptoms compared to mindfulness and relaxation.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova1.html#footnotes",
    "href": "datenanalyse/anova1.html#footnotes",
    "title": "11  Einfaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "",
    "text": "https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf↩︎",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova2.html",
    "href": "datenanalyse/anova2.html",
    "title": "12  Zweifaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "",
    "text": "12.1 Anwendungsbeispiel in R",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Zweifaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova2.html#anwendungsbeispiel-in-r",
    "href": "datenanalyse/anova2.html#anwendungsbeispiel-in-r",
    "title": "12  Zweifaktorielle Varianzanalyse ohne Messwiederholung",
    "section": "",
    "text": "Beispiel: Therapiemethoden bei Angstsymptomen für Erwachsene und Jugendliche\n\n\n\nIn einem fiktiven Experiment wurden zwei verschiedene Therapiemethoden verglichen und untersucht, welchen Effekt die zwei Therapiemethoden bei Jugendlichen und Erwachsenen auf ihre Angstsymptomatik haben. Dazu wurden je 12 erwachsene und 12 jugendliche Personen zufällig auf die zwei Bedingungen aufgeteilt.\n\nDie unabhängige Variable A sind die Altersgruppen mit 2 Faktorstufen (Jugendliche, Erwachsene).\nDie unabhängige Variable B sind die Therapiemethoden mit 2 Faktorstufen (Mindfulness, Kognitive Umstrukturierung).\nDie abhängige Variable entspricht der Höhe der Angstsymptome nach der Therapie (metrisch).\n\n\n\n\n12.1.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\n\\(H_0\\) für Haupteffekt A: Die Angstsymptome unterscheiden sich nicht zwischen den Altersgruppen: \\(\\mu_{j \\bullet} - \\mu = 0\\) für alle \\(j\\)\n\\(H_0\\) für Haupteffekt B: Die Angstsymptome unterscheiden sich nicht zwischen den Therapiemethoden: \\(\\mu_{ \\bullet k} - \\mu = 0\\) für alle \\(k\\)\n\\(H_0\\) für den Interaktionseffekt A x B: Die Angstsymptome unterscheiden sich nicht zwischen den Therapiemethoden in Abhängigkeit der Altersgruppen: \\(\\mu_{jk} - (\\mu_{j \\bullet} - \\mu) - (\\mu_{ \\bullet k} - \\mu) + \\mu = 0\\) für alle \\(jk\\)\n\\(H_1\\) für den Haupteffekt A (B, A x B analog): Die Altersgruppen unterscheiden sich bezüglich den Angstsymptomen: \\(\\mu_{j \\bullet} - \\mu \\neq 0\\) für mindestens ein \\(j\\)\nDas Alphaniveau wird auf \\(5 \\%\\) festgelegt. Es handelt sich um eine ungerichtete Hypothese, die Testung erfolgt mit dem F-Test dabei einseitig.\n\n\n\n12.1.2 Vorverarbeitung\n\nDaten einlesen und vorverarbeiten\n\n\n\n\n\n\nHands-on: Beispieldatensatz Therapiemethode und Altersgruppen\n\n\n\nDaten herunterladen und einlesen\nDer Datensatz anova_therapy_age.csv kann hier heruntergeladen werden. Der Datensatz muss im data-Ordner des RProject namens anova.Rproj abgespeichert werden.\n\nEs werden folgende Packages verwendet: {tidyverse}, {afex}, {emmeans}, {effectsize}\nDatensatz anova_therapy_age.csv einlesen:\n\n\n# Package laden\nlibrary(tidyverse)\n\n# Daten laden und anschauen\nd_therapy_age &lt;- read.csv(\"data/anova_therapy_age.csv\") |&gt;\n    glimpse() \n\nRows: 24\nColumns: 4\n$ agegroup &lt;chr&gt; \"adult\", \"adult\", \"adult\", \"adult\", \"adult\", \"adult\", \"adult\"…\n$ method   &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"mindfulness\", \"mindfulness\", \"…\n$ symptoms &lt;int&gt; 9, 7, 8, 4, 7, 1, 1, 3, 4, 1, 1, 2, 5, 2, 3, 4, 5, 6, 3, 3, 4…\n$ id       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n\n\nDatensatz transformieren\nDie Daten liegen bereits im long Format vor. Die Variablen id, agegroup und method müssen jedoch noch zu Faktoren konvertiert werden.\n\n# Faktoren konvertieren\nd_therapy_age &lt;- d_therapy_age |&gt;\n  mutate(id = as.factor(id)) |&gt;\n  mutate(agegroup = as.factor(agegroup)) |&gt;\n  mutate(method = as.factor(method)) |&gt;\n  select (id, agegroup, method, symptoms)\n\n# Datensatz anschauen\nglimpse(d_therapy_age)\n\nRows: 24\nColumns: 4\n$ id       &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ agegroup &lt;fct&gt; adult, adult, adult, adult, adult, adult, adult, adult, adult…\n$ method   &lt;fct&gt; mindfulness, mindfulness, mindfulness, mindfulness, mindfulne…\n$ symptoms &lt;int&gt; 9, 7, 8, 4, 7, 1, 1, 3, 4, 1, 1, 2, 5, 2, 3, 4, 5, 6, 3, 3, 4…\n\n\n\n\n\n\nVoraussetzungen überprüfen\nDer F-Test für eine zweifaktorielle Varianzanalyse setzt voraus, dass die AV in der Population stetig und normalverteilt ist und die Populationsvarianzen homogen sind.\nDie Varianzhomogenität (Homoskedastizität) kann mit dem Levene-Test leveneTest(y ~ x, data = dataset) überprüft werden. Die Funktion leveneTest() stammt aus dem Package {car}. Ein Levene-Test mit \\(p &lt; 0.05\\) bedeutet, dass der Varianzunterschied signifikant ist. Die Nullhypothese, dass die Varianzen auf Populationsebene identisch sind, müsste in diesem Fall verworfen werden.\n\nVor dem ersten Verwenden der Funktion leveneTest() muss das Package {car} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"car\").\n\n\n# Levene-Test mit dem package {car}\ncar::leveneTest(symptoms ~ agegroup * method, # av ~ uv1 * uv2\n                data = d_therapy_age) # Datensatz\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  3  0.6121  0.615\n      20               \n\n\nDer Test ist hier nicht signifikant (\\(p = .615\\)), daher wird davon ausgegangen, dass die Varianzen in den Gruppen homogen sind und die Voraussetzung der Varianzhomogenität erfüllt ist.\n\n\n\n12.1.3 Analyse\n\nDeskriptivstatistik und Visualisierungen\nFür die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden. Hier werden die Funktionen group_by() und summarise() genutzt. Bei group_by() müssen beide Faktoren angegeben werden.\n\n# Mittelwerte und Standardabweichungen berechnen\nd_summary &lt;- d_therapy_age |&gt;\n  group_by(agegroup, method) |&gt; # Gruppierung mit beiden Faktoren\n  summarise(mean_symptoms = mean(symptoms), # Mittelwert\n            sd_symptoms = sd(symptoms)) # Standardabweichung\n\n`summarise()` has grouped output by 'agegroup'. You can override using the\n`.groups` argument.\n\nd_summary\n\n# A tibble: 4 × 4\n# Groups:   agegroup [2]\n  agegroup   method        mean_symptoms sd_symptoms\n  &lt;fct&gt;      &lt;fct&gt;                 &lt;dbl&gt;       &lt;dbl&gt;\n1 adolescent mindfulness            4.17        1.47\n2 adolescent restructuring          4           1.67\n3 adult      mindfulness            6           2.97\n4 adult      restructuring          2           1.26\n\n\n\n\nTeststatistik berechnen\nFalls der empirische F-Wert grösser als der kritische F-Wert ist, wird von einem signifikanten Unterschied zwischen mindestens zwei Zellmittelwerten ausgegangen.\nBerechnung Teststatistik in R mit der Funktion aov_4()\nEine zweifaktorielle Varianzanalyse kann mit der Funktion aov_4(av ~ uv1 * uv2, + (1 | id), data) aus dem Package {afex} berechnet werden.\n\nav: Abhängige Variable (metrisch)\nuv1: Unabhängige Variable A (Bedingung oder Gruppenvariable)\nuv2: Unabhängige Variable B (Bedingung oder Gruppenvariable)\n(1 | id): Die Funktion benötigt eine Identifikationsvariable (hier id), d.h. eine Variable, in der jede Person einen einzigartigen Wert hat. Da wir keine Messwiederholung haben, wird eine 1 vor dem | verwendet. Bei Messwiederholung wird hier spezifiziert, welche Variable sich innerhalb von id wiederholt.\n\n\nVor dem ersten Verwenden muss das Package {afex} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"afex\").\n\n\n# afex laden\nlibrary(afex)\n\n# Zweifaktorielle Anova ohne Messwiederholung\nm_anova2x2 &lt;- aov_4(symptoms ~ agegroup * method + (1 | id), # av ~ uv1 * uv2 + (1 | Versuchspersonenidentifikation)\n                  data = d_therapy_age) # Datensatz\n\n# Resultate ausgeben\nsummary(m_anova2x2) \n\nAnova Table (Type 3 tests)\n\nResponse: symptoms\n                num Df den Df    MSE      F      ges  Pr(&gt;F)  \nagegroup             1     20 3.8417 0.0108 0.000542 0.91809  \nmethod               1     20 3.8417 6.7787 0.253139 0.01699 *\nagegroup:method      1     20 3.8417 5.7375 0.222925 0.02651 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm_anova2x2$Anova\n\nAnova Table (Type III tests)\n\nResponse: dv\n                Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)     392.04  1 102.0499 2.667e-09 ***\nagegroup          0.04  1   0.0108   0.91809    \nmethod           26.04  1   6.7787   0.01699 *  \nagegroup:method  22.04  1   5.7375   0.02651 *  \nResiduals        76.83 20                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nEs gibt einen signifikanten Haupteffekt B der Therapiemethode (method). Das bedeutet, dass mindestens ein Haupteffekt des Faktors B signifikant von 0 verschieden ist (\\(p = .017\\)).\nEs gibt ausserdem mindestens einen Interaktionseffekt AxB (agegroup * method), der signifikant von 0 verschieden ist (\\(p = .027\\)).\nEs gibt jedoch keinen Haupteffekt A der Altersgruppen (agegroup), da dieser Effekt nicht signifikant von 0 verschieden ist (\\(p = .918\\)).\n\nDa bei einer zweifaktoriellen Varianzanalyse mit einem 2x2-Design beide Faktoren nur zwei Stufen aufweisen und sich die Effekte zu 0 aufaddieren, bedeutet dies, dass alle Haupteffekte des Faktors B und alle Interaktionseffekte von 0 verschieden sind.\nDie Mittelwerte der Bedingungen unterscheiden sich signifikant auf dem \\(5 \\%\\)-Niveau. Die Nullhypothese, wonach sich die Mittelwerte nicht unterscheiden, kann verworfen werden. Die Therapiemethode hat somit einen Einfluss auf die Angstsymptomatik. Bei mehr als zwei Faktorstufen wäre aufgrund der Analyse hingegen (noch) nicht klar, welche Bedingungen sich unterscheiden.\nZur Visualisierung der Ergebnisse eignet sich ein Plot, der die Mittelwerte und Standardfehler abbildet. Dazu kann die Funktion afex_plot aus dem Package {afex} verwendet werden. Um die Standardfehler, anstelle der Konfidenzintervall, anzuzeigen, kann error_ci = FALSE verwendet werden.\n\n# Grafische Darstellung der zweifaktoriellen Varianzanalyse (Variante 1)\nafex_plot(object = m_anova2x2,\n          x = \"agegroup\",\n          trace = \"method\",\n          mapping = c(\"color\", \"shape\"),\n          error_ci = FALSE,\n          legend_title = \"method\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHier ist ersichtlich, dass sich die Zellmittelwerte “nur” in der Altersgruppe “Erwachsene” zwischen den beiden Methoden unterscheidet. Dies deutet darauf hin, dass der Haupteffekt der Therapiemethode lediglich durch die grosse Mittelwertsdifferenz zwischen den beiden Methoden bei Erwachsenen zustande kommt und dass es (trotz signifikantem Haupteffekt) keinen allgemeinen Effekt der Therapiemethode gibt.\n\nEs gilt also Vorsicht bei der Interpretation von Haupteffekten, wenn Interaktionseffekte vorliegen, da grosse Haupteffekte auch durch grosse bedingte Haupteffekt zustande kommen können.\n\nDer Plot kann auch mit Faktor B auf der x-Achse ausgegeben werden.\n\n# Grafische Darstellung der zweifaktoriellen Varianzanalyse (Variante 2)\nafex_plot(object = m_anova2x2,\n          x = \"method\",\n          trace = \"agegroup\",\n          mapping = c(\"color\", \"shape\"),\n          error_ci = FALSE,\n          legend_title = \"agegroup\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHier handelt es sich um die genau gleichen Daten, die aber anders dargestellt werden. Wir sehen aber auch, dass sich Adoleszente (rot) nicht zwischen den Therapiemethoden unterscheiden, bei den Erwachsenen (blau) aber ein Unterschied besteht. Dies kann in einem nächsten Schritt mit weiteren Analysen bestätigt werden, indem die bedingten Haupteffekte berechnet werden.\nBedingte Haupteffekte\nMit der Funktion joint_tests() aus dem Package {emmeans} können die bedingten Haupteffekte berechnet werden. Dies ist sowohl für Faktor A, aber auch für Faktor B möglich und hängt von der Fragestellung ab.\n\nVor dem ersten Verwenden muss das Package {emmeans} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"emmeans\").\n\n\nlibrary(emmeans)\n\nWarning: package 'emmeans' was built under R version 4.4.3\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\n# Bedingte Haupteffekte Faktor B\njoint_tests(m_anova2x2, # Modell\n            by = \"agegroup\") # in Faktorstufen a1/a2\n\nagegroup = adolescent:\n model term df1 df2 F.ratio p.value\n method       1  20   0.022  0.8844\n\nagegroup = adult:\n model term df1 df2 F.ratio p.value\n method       1  20  12.495  0.0021\n\n\nDer bedingte Haupteffekt des Faktors B (method) (mindfulness vs. restructuring), wenn Personen in der Altersgruppe “Jugendliche” (\\(a_2\\)) sind, ist nicht signifikant (\\(p = .884\\)).\nHingegen ist der bedingte Haupteffekt des Faktors B (method) (mindfulness vs. restructuring) signifikant, wenn Personen in der Altersgruppe “Erwachsene” (\\(a_1\\)) sind (\\(p = .002\\)).\n\nlibrary(emmeans)\n\n# Bedingte Haupteffekte Faktor A\njoint_tests(m_anova2x2, # Modell\n            by = \"method\") # in Faktorstufen b1/b2\n\nmethod = mindfulness:\n model term df1 df2 F.ratio p.value\n agegroup     1  20   2.625  0.1209\n\nmethod = restructuring:\n model term df1 df2 F.ratio p.value\n agegroup     1  20   3.124  0.0924\n\n\nDie bedingten Haupteffekte des Faktors A (agegroup) (adolescent vs. adult) für beide Therapiemethoden (\\(b_1\\) und \\(b_2\\)) sind nicht signifikant.\nGesamteffekt\nUm den Gesamteffekt zu berechnen, kann die Funktion lm() verwendet werden. In der letzten Zeile wird der \\(p\\)-Wert des Gesamteffekts ausgegeben. Dies ist relevant, da bei nicht signifikantem Gesamteffekt die Interpretation der signifikanten Haupt- oder Interaktionseffekte problematisch ist.\n\n# Berechnung des Gesamteffekts\nsummary(lm(symptoms ~ agegroup * method, # av ~ uv1 * uv2\n           data = d_therapy_age)) # Datensatz\n\n\nCall:\nlm(formula = symptoms ~ agegroup * method, data = d_therapy_age)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.000 -1.000  0.000  1.208  3.000 \n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         4.1667     0.8002   5.207 4.28e-05 ***\nagegroupadult                       1.8333     1.1316   1.620   0.1209    \nmethodrestructuring                -0.1667     1.1316  -0.147   0.8844    \nagegroupadult:methodrestructuring  -3.8333     1.6003  -2.395   0.0265 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.96 on 20 degrees of freedom\nMultiple R-squared:  0.3851,    Adjusted R-squared:  0.2929 \nF-statistic: 4.176 on 3 and 20 DF,  p-value: 0.01895\n\n\nDer Gesamteffekt ist mit \\(p = .019\\) signifikant von 0 verschieden, wodurch die signifikanten Haupt- und Interaktionseffekte grundsätzlich interpretiert werden können.\n\n\nEffektstärke bestimmen\nBerechnung der Effektgrösse \\(\\eta^2\\) und \\(\\eta^2_p\\)\nFür jede Effektgruppe lässt sich mit dem nicht-partiellen \\(\\eta^2\\) angeben, wie gross der Anteil der durch sie aufgeklärten Varianz an der Gesamtvarianz ist. Der Nachteil des nicht-partiellen Effektstärkenmasses besteht darin, dass die Grösse eines bestimmten Effekts abhängig davon ist, aus welchen anderen Faktoren das jeweilige varianzanalytische Design besteht. Daher ist es nicht über Studien hinweg vergleichbar.\nZur besseren Vergleichbarkeit kann das partielle \\(\\eta^2_p\\) berechnet werden. Der Nachteil des partiellen Effektstärkemasse ist, dass sie sich innerhalb einer Studie nicht mehr zu einem Gesamteffekt, d. h. dem Anteil der insgesamt aufgeklärten Varianz an der Gesamtvarianz, aufaddieren.\nWill man also die Grösse unterschiedlicher Effekte innerhalb der gleichen Studie in Relation zueinander setzen, bietet es sich an, das nicht-partielle Effektstärkemass zu verwenden. Für Vergleiche von Effektgrössen zwischen Studien ist das partielle Effektstärkemass geeignet.\nUm die Effektgrössen zu berechnen, kann in R die Funktion eta_squared() aus dem Package {effectsize} verwendet werden. Als Argument für die Funktion muss das Anova-Modell (Objekt), also hier m_anova2x2, verwendet werden. Wird das Argument partial auf TRUE gesetzt (partial = TRUE) berechnet R das partielle Etaquadrat, welches über Studien hinweg verglichen werden kann.\n\nVor dem ersten Verwenden muss das Package {effectsize} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"effectsize\").\n\n\nlibrary(effectsize)\n\nWarning: package 'effectsize' was built under R version 4.4.3\n\neta_squared(m_anova2x2, # Funktion, Modell\n            partial = FALSE) # nicht-partielles Eta\n\n# Effect Size for ANOVA (Type III)\n\nParameter       |     Eta2 |       95% CI\n-----------------------------------------\nagegroup        | 3.33e-04 | [0.00, 1.00]\nmethod          |     0.21 | [0.01, 1.00]\nagegroup:method |     0.18 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\neta_squared(m_anova2x2, # Funktion, Modell\n            partial = TRUE) # partielles Eta\n\n# Effect Size for ANOVA (Type III)\n\nParameter       | Eta2 (partial) |       95% CI\n-----------------------------------------------\nagegroup        |       5.42e-04 | [0.00, 1.00]\nmethod          |           0.25 | [0.03, 1.00]\nagegroup:method |           0.22 | [0.02, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nDie Effektgrösse liegt für den Faktor A (agegroup) bei \\(\\eta^2_p&lt;.001\\), für den Faktor B (method) bei \\(\\eta^2_p = .25\\) und für die Interaktion AxB (agegroup:method) bei \\(\\eta^2_p=.22\\).\nEs handelt sich nach der Taxonomie von Cohen (1988) für Therapiemethode und Interaktion um grosse Effekte.\n\n\n\n12.1.4 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nErgebnisse der zweifaktoriellen Varianzanalyse ohne Messwiederholung\n\nA two-way analysis of variance (ANOVA) was conducted to examine the effects of Factor A (e.g., age group: adult vs. adolescent) and Factor B (therapy method: mindfulness vs. restructuring) on anxiety symptoms.\n\n\nThe main effect of age group was not significant, F(1, 20) = 0.01, p = .918, suggesting that there was no overall difference in anxiety symptoms between adolescents and adults. The analysis revealed a significant main effect of therapy method, F(1, 20) = 6.78, p = .017, \\(\\eta^2_p\\) = .25, indicating that the mean anxiety symptoms significantly differed between the mindfulness and restructuring method.\n\n\nHowever, the interaction between age group and therapy method was significant, F(1, 20) = 5.74, p = .027, \\(\\eta^2_p\\) = .22, indicating that the effect of therapy method depended on age group. A simple effects analysis for therapy method revealed a significant effect for adults (p = .002), but not for adolescents (p = .884). This indicates a differential effect of therapy method regarding age groups. Figure 12.1 illustrates the interaction effect.\n\n\n\n\n\n\n\n\n\n\nFigure 12.1: Main and interaction effects of therapy methods mindfulness and restructuring on anxiety symptoms in adults and adolescents.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Zweifaktorielle Varianzanalyse ohne Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova3.html",
    "href": "datenanalyse/anova3.html",
    "title": "13  Einfaktorielle Varianzanalyse mit Messwiederholung",
    "section": "",
    "text": "13.1 Anwendungsbeispiel in R",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse mit Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/anova3.html#anwendungsbeispiel-in-r",
    "href": "datenanalyse/anova3.html#anwendungsbeispiel-in-r",
    "title": "13  Einfaktorielle Varianzanalyse mit Messwiederholung",
    "section": "",
    "text": "Beispiel: Therapiemethoden bei Angstsymptomen\n\n\n\nIn einem fiktiven Experiment wurden drei verschiedene Therapiemethoden verglichen und untersucht, welchen Effekt die drei Therapiemethoden bei Patient:innen mit Angstsymptomatik haben. Dazu wurden fünf Personen untersucht und alle Personen absolvierten die drei Bedingungen in derselben Reihenfolge.\n\nDie unabhängige Variable condition: Therapiemethoden mit drei Faktorstufen (mindfulness, relaxation, restructuring) (messwiederholter Faktor)\nDie abhängige Variable symptoms: Höhe der Angstsymptome nach jeder Therapiemethode (metrisch)\n\nForschungsfrage: Beeinflusst die Bedingung Therapiemethode die Angstsymptome?\n\n\n\n13.1.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\n\\(H_0\\) : Die Angstsymptome (Bedingungsmittelwerte in der Population) unterscheiden sich nicht: \\(\\mu_{\\bullet 1} = \\mu_{\\bullet 2} = \\mu_{\\bullet 3}\\) oder allgemein \\(\\mu_{\\bullet j} - \\mu = 0\\) für alle \\(j\\)\n\\(H_1\\): Mindestens zwei Bedingungsmittelwerte der Angstsymptome unterscheiden sich, bzw. mindestens ein Bedingungseffekt ist ungleich null. \\(\\mu_{\\bullet j} - \\mu \\neq 0\\) für mindestens ein \\(j\\)\nDas Alphaniveau wird auf \\(5 \\%\\) festgelegt.\n\n\n\n13.1.2 Vorverarbeitung\n\nDaten einlesen und vorverarbeiten\n\n\n\n\n\n\nHands-on: Beispieldatensatz Therapiemethoden\n\n\n\nDaten herunterladen und einlesen\nDer Datensatz anova_therapy_rm.csv kann hier heruntergeladen werden. Der Datensatz muss im data-Ordner des RProject namens anova.Rproj abgespeichert werden.\n\nEs werden folgende Packages verwendet: {tidyverse}, {afex}, {emmeans}, {effectsize}\nDatensatz anova_therapy_rm.csv einlesen:\n\n\n# Package laden\n  library(tidyverse)\n\n# Daten laden und anschauen\nd_therapy_rm &lt;- read.csv(\"data/anova_therapy_rm.csv\") |&gt;\n    glimpse() \n\nRows: 15\nColumns: 3\n$ id        &lt;chr&gt; \"sub-001\", \"sub-002\", \"sub-003\", \"sub-004\", \"sub-005\", \"sub-…\n$ condition &lt;chr&gt; \"t1_mindfulness\", \"t1_mindfulness\", \"t1_mindfulness\", \"t1_mi…\n$ symptoms  &lt;int&gt; 6, 9, 7, 5, 3, 9, 7, 8, 7, 4, 1, 3, 1, 1, 4\n\n\nDatensatz transformieren\nDie Daten liegen bereits im long Format vor. Jede Person (sub-001 bis sub-005) hat drei Messwerte. Die Variablen id und condition müssen zu Faktoren konvertiert werden. Schauen Sie sich den Datensatz mit glimpse() an.\n\n# Faktoren konvertieren\nd_therapy_rm &lt;- d_therapy_rm |&gt;\n  mutate(id = as.factor(id)) |&gt;\n  mutate(condition = as.factor(condition)) \n\n# Datensatz anschauen\nglimpse(d_therapy_rm)\n\nRows: 15\nColumns: 3\n$ id        &lt;fct&gt; sub-001, sub-002, sub-003, sub-004, sub-005, sub-001, sub-00…\n$ condition &lt;fct&gt; t1_mindfulness, t1_mindfulness, t1_mindfulness, t1_mindfulne…\n$ symptoms  &lt;int&gt; 6, 9, 7, 5, 3, 9, 7, 8, 7, 4, 1, 3, 1, 1, 4\n\n\n\n\n\n\nVoraussetzungen überprüfen\nDas Modell der einfaktoriellen Varianzanalyse mit Messwiederholung nimmt an, dass die Messwerte normalverteilt sind, eine konstante Varianz in allen Faktorstufen und eine konstante Kovarianz zwischen allen Faktorstufen-Paaren vorliegt (Compound-Symmetry-Annahme).\nEine Möglichkeit, die Abweichung der empirischen Kovarianzmatrix von einer perfekt sphärischen Matrix zu testen, stellt der Mauchly-Test dar. Üblicherweise wird der Test auf dem \\(\\alpha = 0.05\\)-Niveau durchgeführt.\nIst die Sphärizitätsannahme verletzt, sollte der F-Test nur mit Vorsicht interpretiert werden, da er dann zu liberal wird.\nIn diesem Fall empfiehlt es sich, den F-Test strenger machen, indem man die Freiheitsgrade zur Bestimmung des kritischen F-Wertes reduziert und somit den kritischen Wert erhöht.\nJe weiter die Kovarianzmatrix von einer sphärischen Matrix abweicht, desto kleiner wird der Index \\(\\varepsilon\\).\n\nBei einer starken Verletzung der Sphärizitätsannahme (\\(\\varepsilon_{GG} &lt; 0.75\\)) wird die Greenhouse-Geisser-Korrektur gewählt.\nBei einer schwachen Verletzung der Sphärizitätsannahme (\\(\\varepsilon_{GG} &gt; 0.75\\)) wird die Huynh-Feldt-Korrektur gewählt.\n\nIn R wird die Teststatistik zur Überprüfung der Sphärizitätsannahme gleichzeitig mit dem Anova-Modell ausgegeben (siehe unten).\n\n\n\n13.1.3 Analyse\n\nDeskriptivstatistik und Visualisierungen\nFür die deskriptive Statistik können die Daten nach Bedingung gruppiert und dann die Kennwerte berechnet werden. Hier werden die Funktionen group_by() und summarise() genutzt.\n\n# Mittelwerte und Standardabweichungen berechnen\nd_summary &lt;- d_therapy_rm |&gt;\n  group_by(condition) |&gt; # Gruppierung \n  summarise(mean_symptoms = mean(symptoms), # Mittelwert\n            sd_symptoms = sd(symptoms)) # Standardabweichung\nd_summary\n\n# A tibble: 3 × 3\n  condition        mean_symptoms sd_symptoms\n  &lt;fct&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n1 t1_mindfulness               6        2.24\n2 t2_relaxation                7        1.87\n3 t3_restructuring             2        1.41\n\n\n\n\nTeststatistik berechnen\nFalls der empirische F-Wert grösser als der kritische F-Wert ist, wird von einem signifikanten Unterschied zwischen mindestens zwei Bedingungen ausgegangen.\nBerechnung Teststatistik in R mit der Funktion aov_4()\nEine einfaktorielle Varianzanalyse mit Messwiederholung kann mit der Funktion aov_4(av ~ 1 + (uv | id), data) aus dem Package {afex} berechnet werden.\n\nav: Abhängige Variable (metrisch)\nuv: Unabhängige Variable (Bedingung)\n1: Definiert, dass im Modell jede Person einen eigenen Intercept (Grundniveau) haben darf.\n(uv | id): Die Funktion benötigt eine Identifikationsvariable (hier id), d.h. eine Variable, in der jede Person einen einzigartigen Wert hat. Bei einem messwiederholten Faktor wird ausserdem der Faktor definiert, der sich innerhalb von id wiederholt.\n\n\nVor dem ersten Verwenden muss das Package {afex} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"afex\").\n\n\n# afex laden\nlibrary(afex)\n\n# Einfaktorielle Anova mit Messwiederholung\nm_anova_rm &lt;- aov_4(symptoms ~ 1 + (condition | id),  # av ~ 1 + (uv | id)\n                      data = d_therapy_rm) # Datensatz\n\n# Resultate ausgeben\nsummary(m_anova_rm)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n            Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept)    375      1   12.667      4 118.4211 0.0004048 ***\ncondition       70      2   29.333      8   9.5455 0.0076044 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n          Test statistic p-value\ncondition        0.71281 0.60181\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n           GG eps Pr(&gt;F[GG])  \ncondition 0.77689    0.01517 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n            HF eps  Pr(&gt;F[HF])\ncondition 1.179134 0.007604412\n\nm_anova_rm$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: symptoms\n          num Df den Df    MSE      F   ges  Pr(&gt;F)  \ncondition 1.5538 6.2151 4.7197 9.5455 0.625 0.01517 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nSchritt 1: Zuerst wird die Annahme der Sphärizität mit dem Mauchly-Test überprüft.\nSchritt 2: Falls die Sphärizitätsannahme verletzt ist, ist eine Korrektur der Freiheitsgrade empfohlen. Dabei kann anhand von \\(\\varepsilon_{GG}\\) eruiert werden, inwiefern die Sphärizität verletzt ist. Ein Wert von 1 bedeutet keine Abweichung von der Sphärizität (alle Varianzen der Bedingungsunterschiede sind gleich). Ein Verstoss gegen die Sphärizität führt zu einem \\(\\varepsilon_{GG}\\) unter 1. Je weiter \\(\\varepsilon\\) von 1 entfernt ist, desto schlimmer ist der Verstoss. Bei \\(\\varepsilon_{GG} &lt; 0.75\\) wird die Greenhouse-Geisser-Korrektur verwendet. Bei \\(\\varepsilon_{GG} &gt; 0.75\\) wird die Huynh-Feldt-Korrektur angewendet.\nSchritt 3: Erst nach der allfälligen Korrektur kann das Ergebnis der Varianzanalyse interpretiert werden.\n\nIn diesem Beispiel ist der Mauchly-Test nicht signifikant \\(p = .602\\) und wir nehmen daher Sphärizität an. Der F-Test muss nicht korrigiert werden. Der F-Wert \\(F = 9.55\\) liegt über dem kritischen Wert von \\(F_{0.95;2;8}=4.56\\). Die Bedingungen unterscheiden sich signifikant, \\(p = .007\\). Die Therapiemethode hat somit einen Einfluss auf die Angstsymptome. Jedoch ist nicht klar, welche Bedingungen sich unterscheiden. Dies kann mit einem generellen Post-hoc Test oder geplanten Kontrastanalysen überprüft werden.\nPost-hoc Tests\nEine Variante, um sämtliche Unterschiede zwischen den Bedingungen zu testen, ist ein Post-Hoc Test ohne konkrete a-priori Hypothesen. Wir untersuchen lediglich, welche Bedingungen sich unterscheiden. Für einen vollständigen Paarvergleich mit ausbalanciertem Design sollte der Tukey-Test verwendet werden.\n\n# Package emmeans laden\nlibrary(emmeans)\n\nWarning: package 'emmeans' was built under R version 4.4.3\n\n# Resultate in Objekt speichern\nresult_anova_rm &lt;- emmeans(object = m_anova_rm, specs = ~ condition)\nresult_anova_rm\n\n condition        emmean    SE df lower.CL upper.CL\n t1_mindfulness        6 1.000  4    3.224     8.78\n t2_relaxation         7 0.837  4    4.677     9.32\n t3_restructuring      2 0.632  4    0.244     3.76\n\nConfidence level used: 0.95 \n\n# Post-hoc Test\npairs(x = result_anova_rm, adjust = \"tukey\")\n\n contrast                          estimate    SE df t.ratio p.value\n t1_mindfulness - t2_relaxation          -1 0.837  4  -1.195  0.5157\n t1_mindfulness - t3_restructuring        4 1.300  4   3.068  0.0783\n t2_relaxation - t3_restructuring         5 1.410  4   3.536  0.0513\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nMindestens zwei Bedingungen unterscheiden sich zwar signifikant, aber durch die Adjustierung sind keine zwei Bedingungen signifikant unterschiedlich im Vergleich.\n\n\nEffektstärke bestimmen\nBerechnung der Effektgrösse \\(\\eta^2_p\\)\nUm die Effektgrösse \\(\\eta^2_p\\) zu berechnen, kann in R die Funktion eta_squared() aus dem Package {effectsize} verwendet werden. Als Argument für die Funktion muss das Anova-Modell (Objekt) verwendet werden. Durch partial = TRUE berechnet R hier das partielle Etaquadrat.\n\nVor dem ersten Verwenden muss das Package {effectsize} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"effectsize\").\n\n\n\n\n\n\n\nHinweis\n\n\n\nFür messwiederholte Daten ergeben sich einige Herausforderungen, die hier nicht weiter angeschaut werden. Der Vergleich über Studien hinweg ist nicht ohne weiteres möglich, da der Anteil stabiler interindividueller Unterschiede berücksichtigt werden muss. Dies ist mit der Intraklassen-Korrelation möglich, welcher zur Korrektur \\(\\eta^2\\) verwendet werden kann.\n\n\n\nlibrary(effectsize)\n\nWarning: package 'effectsize' was built under R version 4.4.3\n\n# Effektstärke partielles Etaquadrat berechnen\neta_squared(m_anova_rm, # Funktion, Modell\n            partial = TRUE)\n\n# Effect Size for ANOVA (Type III)\n\nParameter | Eta2 (partial) |       95% CI\n-----------------------------------------\ncondition |           0.70 | [0.25, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\n\n\n13.1.4 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nErgebnisse der einfaktoriellen Varianzanalyse mit Messwiederholung\n\nA one-way repeated measures ANOVA was conducted to examine the effects of therapy method (mindfulness, relaxation, and restructuring) on anxiety symptoms. Mauchly’s test indicated that the assumption of sphericity was met, \\(W\\) = 0.71, p = .602, and sphericity could be assumed.\n\n\nThe main effect of therapy method was significant, F(2, 8) = 9.55, p = .008, suggesting that there was an overall difference in anxiety symptoms between the conditions.\n\n\nHowever, the tukey post-hoc test revealed no significant differences between specific conditions. This indicates that no therapy method is significantly better compared to other.\n\n\nmit Korrektur \\(\\varepsilon &lt; .75\\): Mauchly’s test indicated that the assumption of sphericity had been violated, \\(W\\) = 0.25, p = .005. Therefore, degrees of freedom were corrected using Greenhouse-Geisser (\\(\\varepsilon_{GG}\\) = 0.58).\n\n\nmit Korrektur \\(\\varepsilon &gt; .75\\): Mauchly’s test indicated that the assumption of sphericity had been violated, \\(W\\) = 0.68, p = .030. Therefore, degrees of freedom were corrected using Huynh-Feldt (\\(\\varepsilon_{GG}\\) = 0.78).",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Einfaktorielle Varianzanalyse mit Messwiederholung</span>"
    ]
  },
  {
    "objectID": "datenanalyse/einfachelineareregression.html",
    "href": "datenanalyse/einfachelineareregression.html",
    "title": "14  Einfache lineare Regression",
    "section": "",
    "text": "14.1 Anwendungsbereich\nDie einfache lineare Regression wird zur Vorhersage einer metrischen Variable durch eine metrische Variable verwendet.\nDer Zusammenhang wird als Einfluss einer erklärenden Variable1 (predictor variable) auf eine zu erklärende Variable2 (outcome/response variable) quantifiziert. Dabei ist wichtig, dass mit Zusammenhang nicht zwingend ein Kausalzusammenhang gemeint ist. Kausalzusammenhänge müssen zusätzlich theoretisch begründet und methodisch implementiert (z.B. durch ein experimentelles Design) sein.\nDie lineare Regression modelliert den Zusammenhang zweier Variablen mit einer linearen Funktion (Gerade). Hierbei werden die Werte der zu erklärenden Variablen \\(y\\) als Funktion der erklärenden Variable \\(x\\) modelliert, \\(y = f(x)\\). Berechnet wird ein Achsenabschnitt (intercept) und ein Regressionskoeffizient für die Steigung (slope) der Gerade, um zu quantifizieren, wie stark sich ein Variablenwert verändert wenn die andere Variable um eine Einheit zu nimmt. Dies dient der Vorhersage der Ausprägung einer Kriteriumsvariable (Regressand) aus der Ausprägung einer Prädiktorvariablen (Regressor).\nDiese Methode ermöglicht:\nTypische Fragestellungen:",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Einfache lineare Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/einfachelineareregression.html#anwendungsbereich",
    "href": "datenanalyse/einfachelineareregression.html#anwendungsbereich",
    "title": "14  Einfache lineare Regression",
    "section": "",
    "text": "Beschreiben von Merkmalsunterschieden/-zusammenhängen ohne Wirkrichtung bzw. ohne kausalen Zusammenhang\nBeschreiben/Feststellen von kausalen Zusammenhängen (bei theoretischer Begründung und methodischer Implementation/experimenteller Studie)\nPrognose bzw. Vorhersage/Prädiktion von Merkmalsausprägungen für neue Datenpunkte\nPrädiktion von neuen Werten\n\n\n\nWie wirkt sich die wöchentliche Trainingszeit in einer Aufgabe auf die Reaktionszeit aus?\nBeeinflusst die Berufserfahrung in Jahren das Jahreseinkommen?\nSteigt das Risiko einer psychischen Erkrankung mit zunehmendem Alter?\nWie gross ist das Risiko einer Erkrankung bei vorliegendem Testscore?",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Einfache lineare Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/einfachelineareregression.html#voraussetzungen",
    "href": "datenanalyse/einfachelineareregression.html#voraussetzungen",
    "title": "14  Einfache lineare Regression",
    "section": "14.2 Voraussetzungen",
    "text": "14.2 Voraussetzungen\n\nVoraussetzungen einfache lineare Regression, Überprüfung und mögliche Alternativen bei Verletzung der Annahmen\n\n\n\n\n\n\n\nVoraussetzung\nBeschreibung\nVorgehen bei Verletzung\n\n\n\n\nAbhängige Variable\neine abhängige Variable mit metrischem Skalenniveau\nbei kategorialer Variable: logistische Regression.\n\n\nUnabhängige Variable\neine unabhängige Variable mit metrischem Skalenniveau\nVerwenden eines anderen statistischen Verfahrens (z.B. t-Test, ANOVA) oder Kodierung der UV durch Kodiervariablen (Dummy-Codierung)\n\n\nLinearität\nLinearer Zusammenhang zwischen den beiden Variablen. Die Linearitätsannahme kann durch die visuelle Inspektion des Punktediagramms (Scatterplot) überprüft werden.\nbei nichtlinearem Zusammenhang zwischen den Variablen: Variablen transformieren (z.B. Logarithmierung) oder Anwenden von Multipler Regressionsanalyse zur Analyse nichtlinearer Zusammenhänge\n\n\nVarianzhomogenität / Homoskedastizität\nDie Abweichung von \\(y\\) von der Regressionsgeraden sollte über verschiedene Werte der Prädiktorvariablen \\(x\\) ähnlich sein und nimmt nicht signifikant zu oder ab.\nTransformation von \\(y\\), alternative Schätzmethoden oder Bootstrapping\n\n\nNormalverteilung der Residuen\nOb die Residuen normalverteilt sind, kann mit einem Q-Q-Plot und dem Shapiro-Wilk-Test überprüft werden.\nTransformation von \\(y\\), alternative Schätzmethoden oder Bootstrapping\n\n\nUnabhängigkeit der Fehler\nDie Stichprobe muss so erhoben werden, dass die Merkmalsträger voneinander unabhängig sind.\nHierarchisch lineares Modell, dass die Abhängigkeit innerhalb der Datenstruktur berücksichtigt.\n\n\n\n\n\nAuf alternative statistische Verfahren bei Verletzung der Annahmen (z.B. Transformationen oder Multiple Regressionsanalyse für nichtlineare Zusammenhänge) wird in diesem Semester nicht eingegangen.\n\n\n\n\n\n\n\nMetrische Prädiktoren\n\n\n\nIn diesem Kapitel werden Modelle für metrische Prädiktoren behandelt.\nIm Kapitel Allgemeines lineares Modell wird darauf eingegangen, dass Regressionen auch mit kategorialen Prädiktoren verwendet berechnet werden können.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Einfache lineare Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/einfachelineareregression.html#grundkonzepte-und-vorgehen",
    "href": "datenanalyse/einfachelineareregression.html#grundkonzepte-und-vorgehen",
    "title": "14  Einfache lineare Regression",
    "section": "14.3 Grundkonzepte und Vorgehen",
    "text": "14.3 Grundkonzepte und Vorgehen\n\n\n\nAllgemeiner Workflow der Datenanalyse\n\n\n\n14.3.1 Vorverarbeitung\n\nDaten einlesen, vorverarbeiten und visualisieren\nZuerst müssen die Daten eingelesen und je nach Bedarf vorverarbeitet werden.\nDaten für eine einfache lineare Regression können mit einem Punktediagramm (scatterplot) diagnostisch visualisiert werden. Üblicherweise (aber nicht zwingend) wird die Prädiktorvariable (unabhängige Variable) auf der \\(x\\)-Achse und Kriteriumsvariable (abhängige Variable) auf der \\(y\\)-Achse abgetragen.\nScatterplots eignen sich besonders gut, um folgende Probleme zu identifizieren:\n\nSchlechte Datenqualität durch fehlende Werte\nVerzerrung der Resultate durch Extremwerte (Outlier)\nNichtlinearer Zusammenhang der beiden Variablen\n\n\n\nVoraussetzungen überprüfen\nVor dem Berechnen der Regressionsanalyse\n\nSkalenniveau der beiden Variablen: Beide Variablen sollten metrisch sein.\nLinearitätsannahme: Durch ein Punktediagramm bzw. Scatterplot kann ein starker, nichtlinearer Zusammenhang der Variablen ausgeschlossen werden. Die meisten Zusammenhänge in der Psychologie und in den Verhaltenswissenschaften sind nur annähernd linear. Bei leichten Abweichungen kann trotzdem eine einfache lineare Regression ausgeführt werden.\n\n\n\n\nPunktediagramme für Datensätze mit gegebener und nicht gegebener Linearität\n\n\nNach dem Berechnen der Regressionsanalyse\n\nHomoskedastizität\nNormalverteilung der Fehlervariablen\nUnabhängigkeit der Fehler\n\n\n\n\n\n14.3.2 Analyse\n\nRegressionsgleichung\nBei der Regressionsanalyse wird eine Regressionsgerade in die Datenpunkte gelegt.\nDie Regressionsgerade wird durch den Achsenabschnitt \\(b_0\\) (intercept) und den Regressionskoeffizienten \\(b_1\\) (slope) definiert.\nDie Bestimmungsgleichung für die Regressionsgerade lautet:\n\\(\\hat{y} = b_0 + b_1 \\cdot x\\)\nFür einzelne Datenpunkte lautet die Bestimmungsgleichung\n\\(\\hat{y}_m = b_0 + b_1 \\cdot x_m\\)\nwobei\n\n\\(m\\): Beobachtungseinheit (Person)\n\\(y_m\\): Wert der Kriteriumsvariable (AV) der Beobachtungseinheit \\(m\\)\n\\(x_m\\): Wert der Prädiktorvariable (UV) der Beobachtungseinheit \\(m\\)\n\\(b_0\\): Achsenabschnitt (intercept): Wert, welcher \\(y\\) annimmt, wenn \\(x = 0\\) bzw. bei welchem die Regressionsgerade die y-Achse schneidet beim Wert 0 auf der x-Achse.\n\\(b_1\\): Regressionskoeffizient/Steigung (slope): Steigung der Regressionsgeraden.\n\n\n\n\n\nRegressionsmodell\n\n\n\n\n\nBestimmung des Regressionskoeffizienten \\(b_1\\)\nDer Regressionskoeffizient bzw. die Steigung (slope) wird mit folgender Gleichung bestimmt:\n\\(b_1 = r_{xy} \\cdot \\frac{s_y}{s_x} = \\frac{s_{xy}}{s^2_x}\\)\nwobei\n\n\\(r_{xy}\\): Produkt-Moment-Korrelation von \\(x\\) und \\(y\\)\n\\(s_y\\): Standardabweichung von \\(y\\)\n\\(s_x\\): Standardabweichung von \\(x\\)\n\\(s_{xy}\\): Kovarianz von \\(x\\) und \\(y\\)\n\nBei der Regression standardisierter Werte entspricht die Steigung \\(b_{1s}\\) der Produkt-Moment-Korrelation \\(r_{xy}\\) zwischen den beiden Variablen.\n\n\nBestimmung des Achsenabschnitts \\(b_0\\)\nDer Achsenabschnitt (intercept) wird mit folgender Gleichung bestimmt:\n\\(b_0 = \\bar{y} - b_1 \\cdot \\bar{x}\\)\nwobei\n\n\\(\\bar{x}\\): Mittelwert von \\(x\\)\n\\(\\bar{y}\\): Mittelwert von \\(y\\)\n\nBei der Regression standardisierter Werte entspricht der Achsenabschnitt immer 0, also \\(b_{0s} = 0\\).\n\n\nPrädiktion neuer Werte\nWenn \\(b_0\\) und \\(b_1\\) bekannt sind, kann ein beliebiger Wert \\(x_m\\) gewählt3 und der dazugehörige Wert \\(\\hat{y}_m\\) geschätzt werden.\n\\(\\hat{y}_m = b_0 + b_1 \\cdot x_m\\)\nFür die Vorhersage neuer Werte wird der Fehlerterm \\(e\\) hierbei weggelassen. Sollen Daten simuliert werden (beispielsweise zur Planung von Datenanalysen wie Poweranalysen oder Präregistrationen), kann der Fehlerterm hinzugefügt werden, um möglichst “natürliche” Daten zu erhalten.\n\n\nRegressionsresiduum, Quadratsummenzerlegung und Varianzzerlegung\nDie Differenz zwischen dem durch die Regressionsgleichung vorhergesagten Wert (\\(\\hat{y}_m\\)) und dem tatsächlichen (beobachteten) Wert (\\(y_m\\)) wird Regressionsresiduum/Fehlerwert genannt.\n\\(y_m = \\hat{y}_m + e = b_0 + b_1 \\cdot x_m + e_m\\)\nwobei\n\n\\(e_m\\): Regressionsresiduum/Fehlerwert (Unterschied zwischen dem vorhergesagten und tatsächlichen Wert) der Beobachtungseinheit \\(m\\)\n\nDer Fehlerterm ist nötig, weil in der Praxis die Regressionsgerade nie genau auf allen Punkten zu liegen kommt, dh. kein perfekter Zusammenhang der Variablen vorhanden ist.\n\n\n\nRegressionsmodell\n\n\nDie Residualvarianz (Fehlervarianz) wird berechnet mit\n\\(s^2_e =\\frac{\\sum^n_{m=1} (y_{m} - \\hat{y}_m)^2}{n}\\).\nDie Standardabweichung des Regressionsresiduums ist die Quadratwurzel daraus\n\\(s_e = \\sqrt{s^2_e} = \\sqrt{\\frac{\\sum^n_{m=1} (y_{m}- \\hat{y}_m)^2}{n}}\\)\nEs gilt\n\\(s_e = s_y \\cdot \\sqrt{1 - r^2_{xy} }\\)\nDie Quadratsumme beobachteten Abweichungen \\(QS_y\\) besteht aus der Quadratsumme der Regressionsresiduen \\(QS_e\\) und der geschätzten \\(y\\)-Werte \\(QS_\\hat{y}\\).\n\\(\\sum^n_{m=1}(y_{m}- \\bar{y})^2 = \\sum^n_{m=1} (y_{m}- \\hat{y}_m)^2 + \\sum^n_{m=1} (\\hat{y}_m - \\bar{y})^2\\)\n\\(QS_y = QS_e + QS_\\hat{y}\\)\nDie Varianz kann wie folgt zerlegt werden\n\\(\\frac{\\sum^n_{m=1}(y_{m}- \\bar{y})^2}{n} = \\frac{\\sum^n_{m=1} (y_{m}- \\hat{y}_m)^2}{n} + \\frac{\\sum^n_{m=1} (\\hat{y}_m - \\bar{y})^2}{n}\\)\n\\(s^2_y = s^2_e + s^2_\\hat{y}\\).\n\n\nDeterminations- und Indeterminationskoeffizient\nDer Determinationskoeffizient \\(R^2\\) kann einen Wert zwischen 0 und 1 annehmen. Bei keiner Korrelation entspricht \\(R^2 = 0\\), bei einer perfekten Korrelation entspricht \\(R^2 = 1\\). Für Werte zwischen 0 und 1 gilt, dass \\(c \\cdot 100%\\) der Varianz in \\(y\\) durch Variation in \\(x\\) erklärt wird, also zurückgeführt werden kann. Ein Determinationskoeffizient von \\(0.45\\) bedeutet also, dass 45% der Varianz in \\(y\\) durch Variation in \\(x\\) erklärt werden kann.\nDeterminationskoeffizient: \\(R^2 = \\frac{s^2_\\hat{y}}{s^2_y}\\)\nIndeterminationskoeffizient: \\(1- R^2 = \\frac{s^2_e}{s^2_y}\\)\n\n\nTeststatistik berechnen\nUm zu überprüfen, ob die beiden Variablen signifikant zusammenhängen, kann die Teststatistik berechnet werden. Die Nullhypothese kann durch das Vergleichen des Prüfwerts mit einer \\(t\\)-Verteilung mit \\(df = n-2\\) Freiheitsgraden und/oder durch das Konstruieren von Konfidenzintervallen überprüft werden.\nRegressionskoeffizient \\(b_1\\) überprüfen\nDie Nullhypothese lautet üblicherweise\n\\(H_0: \\beta_1 = \\beta_{10}\\)\nWenn \\(\\beta_{10} = 0\\): Der Regressionskoeffizient unterscheidet sich nicht von 0.4\nZur Überprüfung der Nullhypothese wird die Prüfgrösse berechnet, die einer \\(t\\)-Verteilung folgt mit \\(df = 2\\)\n\n\\(t_{emp} : \\frac{b_1 - \\beta_{10}}{\\hat{\\sigma}_{B_1}}\\)\n\\(t_{krit}: t_{(1-\\frac{\\alpha}{2};n-2)}\\)\n\nWenn \\(t_{emp} &gt; t_{krit}\\) kann die Nullhypothese abgelehnt werden.\n\n\n\n\n\n\nGeschätzte Populationsresidualvarianz \\(\\hat{\\sigma}^2_{\\varepsilon}\\) und Varianz von \\(B_1\\) \\(\\hat{\\sigma}^2_{B_1}\\)\n\n\n\n\n\nDie geschätzte Varianz (quadrierter Standardfehler) von \\(B_1\\), \\(\\hat{\\sigma}^2_{B_1}\\) kann berechnet werden mit:\n\\(\\hat{\\sigma}^2_{B_1} = \\frac{\\hat{\\sigma}_{\\varepsilon}}{\\sqrt{n - s^2_x}}\\)\nwobei:\n\nDie Populationsresidualvarianz \\(\\sigma^2_{\\varepsilon}\\) meist nicht bekannt ist und geschätzt wird mit\n\n\\(\\hat{\\sigma}^2_{\\varepsilon} = \\frac{\\sum^n_{m=1} e^2_m}{n-2} = \\frac{\\sum^n_{m=1} (y_m - \\hat{y}_m)^2}{n-2}\\).\n\nDer geschätzte Standardschätzfehler (die geschätzte Standardabweichung der Residuen) entspricht somit\n\n\\(\\hat{\\sigma}_{\\varepsilon} = \\sqrt{\\frac{\\sum^n_{m=1} e^2_m}{n-2}} = \\sqrt{\\frac{\\sum^n_{m=1} (y_m - \\hat{y}_m)^2}{n-2}}\\).\n\n\n\nResidualwerte\n\n\n\n\n\nDas Konfidenzintervall entspricht\n[\\(b_1 - t_{(1-\\frac{\\alpha}{2};n-2)} \\cdot \\hat{\\sigma}_{B_1}\\) ; \\(b_1 + t_{(1-\\frac{\\alpha}{2};n-2)} \\cdot \\hat{\\sigma}_{B_1}\\)].\nWenn das Konfidenzintervall 0 nicht enthält, kann die Nullhypothese abgelehnt werden.\nAchsenabschnitt \\(b_0\\) überprüfen:\n\n\\(H_0: \\beta_0 = \\beta_{00}\\)\n\nWenn \\(\\beta_{00} = 0\\): Der Achsenabschnitt unterscheidet sich nicht von Null.5\nZur Überprüfung der Nullhypothese wird die Prüfgrösse berechnet, die einer \\(t\\)-Verteilung folgt mit \\(df = 2\\)\n\n\\(t_{emp} = \\frac{b_0- \\beta_{00}}{\\hat{\\sigma}_{B_0}}\\)\n\\(t_{krit}: t_{(1-\\frac{\\alpha}{2};n-2)}\\)\n\nWenn \\(t_{emp} &gt; t_{krit}\\) kann die Nullhypothese abgelehnt werden.\n\n\n\n\n\n\nGeschätzte Populationsresidualvarianz \\(\\hat{\\sigma}^2_{\\varepsilon}\\) und Varianz von \\(B_0\\) \\(\\hat{\\sigma}^2_{B_0}\\)\n\n\n\n\n\nDie geschätzte Varianz (quadrierter Standardfehler) von \\(B_0\\), \\(\\hat{\\sigma}^2_{B_0}\\) kann berechnet werden mit:\n\\(\\hat{\\sigma}^2_{B_0} = \\hat{\\sigma}^2_{\\varepsilon} \\cdot (\\frac{1}{n} + \\frac{\\bar{x}^2}{n \\cdot s^2_x})\\)\nsomit:\n\\(\\hat{\\sigma}_{B_0} = \\hat{\\sigma}_{\\varepsilon} \\cdot \\sqrt{\\frac{1}{n} + \\frac{\\bar{x}^2}{n \\cdot s^2_x}}\\)\nwobei:\n\nDie Populationsresidualvarianz \\(\\sigma^2_{\\varepsilon}\\) meist nicht bekannt ist und geschätzt wird mit\n\n\\(\\hat{\\sigma}^2_{\\varepsilon} = \\frac{\\sum^n_{m=1} e^2_m}{n-2} = \\frac{\\sum^n_{m=1} (y_m - \\hat{y}_m)^2}{n-2}\\).\n\nDer geschätzte Standardschätzfehler (die geschätzte Standardabweichung der Residuen) entspricht somit\n\n\\(\\hat{\\sigma}_{\\varepsilon} = \\sqrt{\\frac{\\sum^n_{m=1} e^2_m}{n-2}} = \\sqrt{\\frac{\\sum^n_{m=1} (y_m - \\hat{y}_m)^2}{n-2}}\\).\n\n\n\nResidualwerte\n\n\n\n\n\nDas Konfidenzintervall entspricht\n[\\(b_0 - t_{(1-\\frac{\\alpha}{2} ; n-2)} \\cdot \\hat{\\sigma}_{B_0}\\) ; \\(b_0 + t_{(1-\\frac{\\alpha}{2};n-2)} \\cdot \\hat{\\sigma}_{B_0}\\)].\nWenn das Konfidenzintervall 0 nicht enthält, kann die Nullhypothese abgelehnt werden.\n\n\n\n14.3.3 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\nFür die einfache lineare Regressionsanalyse werden in der Regel der Regressionskoeffizient \\(b_1\\) und der dazugehörige \\(t\\)-Test für den Prädiktor berichtet sowie mit dem \\(R^2\\), wie viel der Varianz in der abhängigen Variable aufgeklärt wurde durch den Prädiktor.\nInferenzstatistische Kennwerte (z.B. \\(t\\)) werden mit zwei Dezimalen berichtet.6\n\nSimple linear regression analysis was used to test if hours of sleep predicted performance in a concentration test in young adults. The analysis showed that more hours of sleep significantly predict higher scores in the test (\\(\\beta\\) = 1.63, \\(p\\) = .002). The results of the regression indicated that hours of sleep explained 71% of the variance (\\(R^2\\) = .71, \\(F\\)(1,8) = 119.54, \\(p\\) = .002).",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Einfache lineare Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/einfachelineareregression.html#anwendungsbeispiel-in-r",
    "href": "datenanalyse/einfachelineareregression.html#anwendungsbeispiel-in-r",
    "title": "14  Einfache lineare Regression",
    "section": "14.4 Anwendungsbeispiel in R",
    "text": "14.4 Anwendungsbeispiel in R\n\n\n\n\n\n\nBeispiel: Schlaf und Konzentration\n\n\n\nStudienbeschrieb: In der (fiktiven) Studie wurde der Einfluss von Schlafdauer bei Jugendlichen auf Konzentrationsleistung in einem neuropsychologischen Test (mögliche Scores von 0 bis 20) untersucht.\nForschungsfrage: Hängt die nächtliche Schlafdauer mit der Konzentration am nächsten Tag zusammen?\n\nDie unabhängige Variable sleep enthält Daten über die Schlafdauer in der vorherigen Nacht.\nDie abhängige Variable concentration enthält Daten über die Leistung in einem neuropsychologischen Konzentrationstest. Die maximale Punktzahl beträgt 20.\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.4.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\n\\(H_0\\): Die Schlafdauer hat keinen Einfluss auf die Leistung im Konzentrationstest: \\(b_1 = 0\\)\n\\(H_1\\): Die Schlafdauer sagt die Leistung im Konzentrationstest vorher \\(b_1 \\neq 0\\)\nDas Alphaniveau wird auf \\(5 \\%\\) festgelegt. Da es sich um eine ungerichtete Hypothese handelt, wird zweiseitig getestet.\n\n\nDaten einlesen und vorverarbeiten\n\n\n\n\n\n\nHands-on: Beispieldatensatz Schlaf und Konzentration\n\n\n\n\n# Laden tidyverse\nlibrary(tidyverse)\n\n# Erstellen des Datensatzes\nd &lt;- tibble(sleep = c(5, 5, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12),\n            concentration = c(6, 10,  10, 12, 6, 12, 17, 12, 8, 16, 12, 16, 18, 8, 14, 10, 12, 18))\n\n\n\nFür die Regressionsanalyse sollten die Variablenwerte im Zahlenformat, also beispielsweise als integer oder double gespeichert sein.\n\n\nVoraussetzungen überprüfen\nMetrisch skalierte Variablen und Linearität\n\nglimpse(d)\n\nRows: 18\nColumns: 2\n$ sleep         &lt;dbl&gt; 5, 5, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 10, 10, 11, 11, 12, …\n$ concentration &lt;dbl&gt; 6, 10, 10, 12, 6, 12, 17, 12, 8, 16, 12, 16, 18, 8, 14, …\n\n\nLinearität\n\nd |&gt; ggplot(aes(x = sleep, y = concentration)) +\n  geom_point() +\n  ylim(0, 20+0.5) +\n  xlim(0, 12+0.5) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSobald das Regressionsmodell geschätzt wurde, können die weiteren Voraussetzungen überprüft werden.\n\n\n\n14.4.2 Analyse\n\nRegressionsmodell\nDie einfache lineare Regression kann mit der Funktion lm() aus dem schon in R installierten Package {stats} berechnet werden.\nAls Argumente benötigt die Funktion lm() die Modellgleichung (av ~ uv) und den Datensatz mit den Variablen (data = ...). Die Resultate der Regressionsanalyse können mit der Funktion summary() zusammengefasst werden.\n\n# Einfache lineare Regression berechnen\nm1 &lt;- lm(concentration ~ sleep,\n            data = d)\n\n# Output ausgeben\nsummary(m1)\n\n\nCall:\nlm(formula = concentration ~ sleep, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1874 -3.4042  0.1639  2.9614  5.9202 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   6.1623     3.3521   1.838   0.0847 .\nsleep         0.7025     0.3866   1.817   0.0880 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.591 on 16 degrees of freedom\nMultiple R-squared:  0.171, Adjusted R-squared:  0.1192 \nF-statistic: 3.301 on 1 and 16 DF,  p-value: 0.088\n\n\n\n\nKonfidenzintervalle\nKonfidenzintervalle können mit der Funktion confint() bestimmt werden.\n\n# 95%-Konfidenzintervall bestimmen\nconfint(m1, level = 0.95)\n\n                 2.5 %    97.5 %\n(Intercept) -0.9439279 13.268461\nsleep       -0.1171312  1.522154\n\n# 90%-Konfidenzintervall bestimmen\nconfint(m1, level = 0.90)\n\n                   5 %      95 %\n(Intercept) 0.30984057 12.014693\nsleep       0.02748094  1.377542\n\n\n\n\nModellannahmen überprüfen\nMit dem Package {performance} können die Modellannahmen einer einfachen linearen Regression überprüft werden.\n\nVor dem ersten Verwenden muss das Package {performance} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"performance\").\n\nDie Funktion check_model() gibt diagnostische Plots aus:\n\nperformance::check_model(m1)\n\n\n\nWeiterführend können auch die partiellen Residuen überprüft werden, wie hier beschrieben.\n\nWie die Plots gelesen werden sollten und was getan werden kann, wenn die Annahmen nicht erfüllt sind, wird auf der Website des Packages {performance} sehr gut beschrieben.\nLinearität\nOb die Linearität gegeben ist, kann in folgendem Plot visuell beurteilt werden. Die Referenzlinie (grün) sollte ungefähr gerade sein und horizontal liegen. Der graue Bereich sollte immer die gerade schwarze Linie beinhalten.\n\ndiagnostic_plots &lt;- plot(performance::check_model(m1, panel = FALSE))\n\n# check linearity\ndiagnostic_plots[[2]]\n\n\n\n\n\n\n\n\nHomoskedastizität\nDie Homoskedastizität kann ebenfalls im oberen Plot überprüft werden. Wenn die Streuung der Residuen um die Regressionsgerade unterschiedlich ist, dann ist die Annahme der Varianzhomogenität nicht erfüllt. Heteroskedastizität kann beispielsweise so aussehen, dass die Residuen bei tiefen Werten von \\(x\\) sehr wenig streuen und bei hohen Werten von \\(x\\) stärker streuen (wie ein Trichter).\nFolgender Plot zeigt die Wurzel der absoluten7 Residuen (standardisiert). Weil es so keine negativen Abweichungen mehr gibt, kann in die Abweichung der Residuen eine Linie hineingelegt werden, die möglichst parallel zu \\(0\\) sein sollte. Im Beispiel der obigen Trichterform würde dann eine ansteigende Linie zu sehen sein.\n\n# check homogeneity of variance\ndiagnostic_plots[[3]]\n\n\n\n\n\n\n\n\nDie Homoskedastizität kann weiter mit der Funktion check_heteroscedasticity() überprüft werden (Breusch-Pagan test).\n\nperformance::check_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.774).\n\n\nNormalverteilung der Fehlervariablen\nDie Normalverteilung der Residuen kann mit einem Q-Q-Plot überprüft werden.\n\n# check normality of residuals\ndiagnostic_plots[[5]]\n\n\n\n\n\n\n\n\nDie Normalverteilung der Fehlervariablen kann weiter mit der Funktion check_normality() überprüft werden (Shapiro-Wilk test).\n\nperformance::check_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.314).\n\n\nOutlier erkennen\n\n# detect outliers\ndiagnostic_plots[[4]]\n\n\n\n\n\n\n\n\n\n\nDeskriptivstatistik und Visualisierungen\nZur Visualisierung von Unterschieden eignen sich Punktdiagramme (Scatterplots) und das Einzeichnen der Regressionsgeraden.\nDie Regressionsgerade (schwarz) kann mit + geom_abline(intercept = ..., slope = ...) hinzugefügt werden. Weiter verfügt {ggplot2} auch über Funktionen, die die Regressionsgerade (blau) direkt berechnen, wie beispielsweise + geom_smooth().\n\nd |&gt; ggplot(aes(x = sleep, y = concentration)) +\n  geom_point() +\n  geom_abline(intercept = 6.1623, slope = 0.7025) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  ylim(0, 20+0.5) +\n  xlim(0, 12+0.5) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nDurch die Visualisierung der Rohwerte und der Regressionsgeraden, kann der “Fit”, also die Passung der Geraden zu den Daten gut visuell überprüft werden. Sichtbar wird auch, wenn die Daten nichtlineare Zusammenhänge aufweisen, die nicht mit einer linearen Regression analysiert werden können, wie beispielsweise kurvilineare Zusammenhänge.\n\n\n\n14.4.3 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\n\nSimple linear regression analysis was used to test if hours of sleep significantly predicted performance in a concentration test in young adults. Hours of sleep did not significantly predict performance in the concentration test (\\(\\beta\\) = 0.70, \\(p\\) = .088).\n\n\n\n\n14.4.4 Weiterführende Informationen\n\nInteraktive Visualisierung von Zusammenhängen von RPsychologist: https://rpsychologist.com/correlation/\nInformationen zu den Modellchecks mit {performance}: https://easystats.github.io/performance/index.html",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Einfache lineare Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/einfachelineareregression.html#footnotes",
    "href": "datenanalyse/einfachelineareregression.html#footnotes",
    "title": "14  Einfache lineare Regression",
    "section": "",
    "text": "Prädiktorvariablen, unabhängigen Variablen, Regressor↩︎\nKriteriumsvariablen, abhhängigen Variablen, Regressand↩︎\nhierbei muss beachtet werden, dass der Wert oft nicht extrem von dem vorhandenen Datenbereich abweichen darf, um eine gute Schätzung zu erzeugen↩︎\nEs kann auch ein anderer Wert als 0 für \\(\\beta_{10}\\) gewählt werden.↩︎\nHier kann darüber nachgedacht werden, ob zur Untersuchung eines Zusammenhangs der Achsenabschnitt geprüft werden soll, da er sich in den meisten Fällen sowieso von 0 unterscheidet. In R wird er standardmässig mitüberprüft. Bei standardisierten Variablen ist der Achsenabschnitt zwangsläufig 0.↩︎\nhttps://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf↩︎\ndas bedeutet, dass für ein Residuum von \\(-2\\) der Wert \\(2\\) vewendet würde↩︎",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Einfache lineare Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/multipleregression.html",
    "href": "datenanalyse/multipleregression.html",
    "title": "15  Multiple Regression",
    "section": "",
    "text": "15.1 Anwendungsbereich\nDie multiple Regression wird zur Vorhersage einer metrischen Variable durch mehrere metrische Variablen verwendet.\nDer Zusammenhang wird als Einfluss mehrerer erklärenden Variablen1 (predictor variables) auf eine zu erklärende Variable2 (outcome/response variable) quantifiziert. Dabei ist wichtig, dass mit Zusammenhang nicht zwingend ein Kausalzusammenhang gemeint ist. Kausalzusammenhänge müssen zusätzlich theoretisch begründet und methodisch implementiert (z.B. durch ein experimentelles Design) sein.\nDie multiple Regression modelliert den Zusammenhang von Variablen mit einer linearen Funktionen. Hierbei werden die Werte der zu erklärenden Variablen \\(y\\) als Funktion der erklärenden Variable \\(x\\) modelliert. Berechnet wird ein Achsenabschnitt (intercept) und ein Regressionskoeffizient für jeden Prädiktor.\nDiese Methode ermöglicht das Untersuchen von Fragestellungen, die mehrere Einflussfaktoren einbeziehen:\nTypische Fragestellungen:",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/multipleregression.html#anwendungsbereich",
    "href": "datenanalyse/multipleregression.html#anwendungsbereich",
    "title": "15  Multiple Regression",
    "section": "",
    "text": "Beschreiben von Merkmalsunterschieden/-zusammenhängen ohne Wirkrichtung bzw. ohne kausalen Zusammenhang\nBeschreiben/Feststellen von kausalen Zusammenhängen (bei theoretischer Begründung und methodischer Implementation/experimenteller Studie)\nPrognose bzw. Vorhersage/Prädiktion von Merkmalsausprägungen für neue Datenpunkte\nPrädiktion von neuen Werten\n\n\n\nWie wirkt sich Training in einer Aufgabe und Schlafdauer in der vorherigen Nacht auf die Reaktionszeit aus?\nBeeinflussen Berufserfahrung und Weiterbildungstage das Jahreseinkommen?\nSteigt das Risiko einer psychischen Erkrankung mit zunehmendem Alter und körperlichen Erkrankungen?\nWie gross ist das Risiko einer Erkrankung bei vorliegendem Testscore und Alter?",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/multipleregression.html#voraussetzungen",
    "href": "datenanalyse/multipleregression.html#voraussetzungen",
    "title": "15  Multiple Regression",
    "section": "15.2 Voraussetzungen",
    "text": "15.2 Voraussetzungen\n\nVoraussetzungen multiple Regression, Überprüfung und mögliche Alternativen bei Verletzung der Annahmen\n\n\n\n\n\n\n\nVoraussetzung\nBeschreibung\nVorgehen bei Verletzung\n\n\n\n\nAbhängige Variable\neine abhängige Variable mit metrischem Skalenniveau\nbei kategorialer Variable: logistische Regression.\n\n\nUnabhängige Variable\neine unabhängige Variable mit metrischem Skalenniveau\nVerwenden eines anderen statistischen Verfahrens (z.B. t-Test, ANOVA) oder Kodierung der UV durch Kodiervariablen (Dummy-Codierung)\n\n\nLinearität\nLinearer Zusammenhang zwischen den beiden Variablen. Die Linearitätsannahme kann durch die visuelle Inspektion des Punktediagramms (Scatterplot) überprüft werden.\nbei nichtlinearem Zusammenhang zwischen den Variablen: Variablen transformieren (z.B. Logarithmierung) oder Anwenden von Multipler Regressionsanalyse zur Analyse nichtlinearer Zusammenhänge\n\n\nVarianzhomogenität / Homoskedastizität\nDie Abweichung von \\(y\\) von der Regressionsgeraden sollte über verschiedene Werte der Prädiktorvariablen \\(x\\) ähnlich sein und nimmt nicht signifikant zu oder ab.\nTransformation von \\(y\\), alternative Schätzmethoden oder Bootstrapping\n\n\nNormalverteilung der Residuen\nOb die Residuen normalverteilt sind, kann mit einem Q-Q-Plot und dem Shapiro-Wilk-Test überprüft werden.\nTransformation von \\(y\\), alternative Schätzmethoden oder Bootstrapping\n\n\nUnabhängigkeit der Fehler\nDie Stichprobe muss so erhoben werden, dass die Merkmalsträger voneinander unabhängig sind.\nHierarchisch lineares Modell, dass die Abhängigkeit innerhalb der Datenstruktur berücksichtigt.\n\n\n\n\n\nAuf alternative statistische Verfahren bei Verletzung der Annahmen (z.B. Transformationen oder Multiple Regressionsanalyse für nichtlineare Zusammenhänge) wird in diesem Semester nicht eingegangen.\n\n\n\n\n\n\n\nMetrische Prädiktoren\n\n\n\nIn diesem Kapitel werden Modelle für zwei metrische Prädiktoren behandelt. Multiple Regressionen können aber auch mit mehr als zwei Prädiktoren berechnet werden.\nIm Kapitel Allgemeines lineares Modell wird darauf eingegangen, dass Regressionen auch mit kategorialen Prädiktoren verwendet berechnet werden können.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/multipleregression.html#grundkonzepte-und-vorgehen",
    "href": "datenanalyse/multipleregression.html#grundkonzepte-und-vorgehen",
    "title": "15  Multiple Regression",
    "section": "15.3 Grundkonzepte und Vorgehen",
    "text": "15.3 Grundkonzepte und Vorgehen\n\n\n\nAllgemeiner Workflow der Datenanalyse\n\n\n\n15.3.1 Vorverarbeitung\n\nDaten einlesen, vorverarbeiten und visualisieren\nZuerst müssen die Daten eingelesen und je nach Bedarf vorverarbeitet werden.\nDaten für eine einfache lineare Regression können mit einem Punktediagramm (scatterplot) diagnostisch visualisiert werden. Üblicherweise (aber nicht zwingend) wird die Prädiktorvariable (unabhängige Variable) auf der \\(x\\)-Achse und Kriteriumsvariable (abhängige Variable) auf der \\(y\\)-Achse abgetragen.\nScatterplots eignen sich besonders gut, um folgende Probleme zu identifizieren:\n\nSchlechte Datenqualität durch fehlende Werte\nVerzerrung der Resultate durch Extremwerte (Outlier)\nNichtlinearer Zusammenhang der beiden Variablen\n\n\n\nVoraussetzungen überprüfen\nVor dem Berechnen der Regressionsanalyse\n\nSkalenniveau der beiden Variablen: Beide Variablen sollten metrisch sein.3\nLinearitätsannahme: Durch ein Punktediagramm bzw. Scatterplot kann ein starker, nichtlinearer Zusammenhang der Variablen ausgeschlossen werden. Die meisten Zusammenhänge in der Psychologie und in den Verhaltenswissenschaften sind nur annähernd linear. Bei leichten Abweichungen kann trotzdem eine einfache lineare Regression ausgeführt werden.\n\n\n\n\nPunktediagramme für Datensätze mit gegebener und nicht gegebener Linearität\n\n\n\n\n\n15.3.2 Analyse\n\nRegressionsgleichungen\nDie Anzahl der Regressionskoeffizienten entspricht der Anzahl der Prädiktorvariablen (plus allfälliger Interaktionsterme).\nFolgende Regressionsgleichungen gelten für zwei Prädiktoren:\n\nPopulation: \\(y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\varepsilon\\)\nStichprobe: \\(y = b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + e\\)\n\nFolgende Regressionsgleichungen gelten für mehr als zwei Prädiktoren:\n\nPopulation: \\(y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + ... + \\beta_j \\cdot x_j + ... + \\beta_k \\cdot x_k + \\varepsilon\\)\nStichprobe: \\(y = b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + ... + b_j \\cdot x_j + ... + b_k \\cdot x_k + e\\)\n\nwobei \\(k\\) die Summe aller Prädiktorvariablen bezeichnet, und \\(j\\) eine Laufvariable ist, die bezeichnet, welche Variable gemeint ist.\n\nIn diesem Kapitel wird nur der “Spezial”-Fall einer Regressionsanalyse mit zwei Prädiktoren (\\(k = 2\\)) behandelt.\n\n\n\nRegressionsebene\nBei der multiplen Regression mit zwei Prädiktoren wird für jeden Prädiktor ein Regressionskoeffizient geschätzt. Die Regressionskoeffizienten werden wie bei der einfachen Regression mittels OLS (Ordinary Least Squares) geschätzt: Nach dem Kleinste-Quadrate-Kriterium wird die Summe der Abweichungsquadrate minimiert.\nMan kann sich die Schätzung zweier Regressionskoeffizienten vorstellen, wie 2 Geraden, die durch eine 3-dimensionale Punktewolke (Daten) gelegt werden. Die beiden Regressionsgeraden ergeben die Ränder der Regressionsebene.\n\n\n\nZwei Regressionsgeraden ergeben eine Regressionsebene\n\n\nDurch das Drehen des untenstehenden Plots kann erkannt werden, dass die Seite der Ebene für \\(x_1\\) und \\(x_2\\) eine Gerade bildet. Die interaktive Grafik zeigt, wie die beiden Regressionsgeraden zusammen eine Regressionsebene bilden. Der orange Punkt ist kein Datenpunkt, sondern markiert den Intercept \\(b_0\\).\n\n\n\n\n\n\n\n\nIm R-Skript regressionplane_3dmodel.R können Sie die Werte für \\(b_0\\), \\(x_1\\), \\(x_2\\) und \\(e\\) verändern, und sich die angepasste Regressionsebene anschauen. Im R-Skript regressionplane_3dmodel_tibble.R können Sie eigene Werte für \\(x_1\\), \\(x_2\\), und \\(y\\) definieren.\n\n\n\n\n\n\n\nWelche Werte haben \\(b_0\\), \\(b_1\\) und \\(b_2\\)?\n\n\n\n\n\n\n\\(b_0 = 10\\)\n\\(b_1 = 0.5\\)\n\\(b_2 = -0.5\\)\n\n\n\n\n\n\nBestimmung der Regressionskoeffizienten \\(b_1\\)\nDer Regressionskoeffizient bzw. die Steigung (slope) bei zwei Prädiktorvariablen wird mit folgender Gleichung bestimmt:\n\\(b_1 = b_{1s} \\cdot \\frac{s_y}{s_{x_1}}\\)\nwobei\n\\(b_{1s} = \\frac{r_{yx_1}-r_{yx_2} \\cdot r_{x_1x_2}}{1 - r^2_{x_1x_2}}\\)\nwobei\n\n\\(r_{yx_j}\\): Produkt-Moment-Korrelation von \\(y\\) und \\(x_j\\)\n\\(s_y\\): Standardabweichung von \\(y\\)\n\\(s_{x_j}\\): Standardabweichung von \\(x_j\\)\n\nDies bedeutet, dass die Korrelation der Variablen \\(x_1\\) und \\(x_2\\) stark Einfluss auf den Regressionskoeffizienten nimmt.\nWenn \\(x_1\\) und \\(x_2\\) nicht korrelieren, \\(r_{x_1x_2} = 0\\), dann verändert sich der Regressionskoeffizient der Variablen \\(x_1\\) nicht zwischen einer einfachen Regression (mit nur Prädiktor \\(x_1\\)) und einer multiplen Regression (mit Prädiktoren \\(x_1\\) und \\(x_2\\)).\nWenn hingegen die Korrelation zwischen \\(x_1\\) und \\(x_2\\) nicht null ist, \\(r_{x_1x_2} \\neq 0\\), dann entspricht ein Regressionskoeffizient (bei zwei Prädiktoren) der Steigung der Regressionsgeraden, wenn die Ausprägungen auf der zweiten Prädiktorvariablen konstant gehalten wird. Mit der multiplen Regressionsanalyse wird der Einfluss einer Prädiktorvariablen auf die abhängige Variable bei Konstanthaltung aller anderer Prädiktorvariablen untersucht.\n\n\nBestimmung der Achsenabschnitts \\(b_0\\)\nDer Achsenabschnitt \\(b_0\\) entspricht dem Wert von \\(y\\), wenn \\(x_1\\) und \\(x_2\\) beide 0 sind.\nBerechnet wird er wie folgt:\n\\(b_0 = \\bar{y} - b_1 \\cdot \\bar{x}_1 - b_2 \\cdot \\bar{x}_2\\)\n\n\n\nAchsenabschnitt: Der orange Punkt entspricht dem Achsenabschnitt. Er liegt dort, wo \\(x_1 = 0\\) und \\(x_2 = 0\\).\n\n\n\n\nDeterminations- und Indeterminationskoeffizient\nDer multiple Determinationskoeffizient \\(R^2\\) entspricht der Wurzel aus der multiplen Korrelation (\\(R\\)). Er kann einen Wert zwischen 0 und 1 annehmen. Für Werte zwischen 0 und 1 gilt, dass \\(c \\cdot 100%\\) der Varianz in \\(y\\) durch Variation in den Prädiktorvariablen erklärt wird, also zurückgeführt werden kann. Ein Determinationskoeffizient von \\(0.45\\) bedeutet also, dass 45% der Varianz in \\(y\\) durch Variation in den Prädiktorvariablen erklärt werden kann.\nDeterminationskoeffizient: \\(R^2 = \\frac{s^2_\\hat{y}}{s^2_y}\\)\nIndeterminationskoeffizient: \\(1- R^2 = \\frac{s^2_e}{s^2_y}\\)\n\n\nTeststatistik berechnen\nFür die statistische Absicherung der multiplen Regression gegen \\(0\\) können folgende Teststatistiken berechnet werden:\nGesamtmodell\n\\(H_0: \\beta_1 = ... = \\beta_j = ... = \\beta_k = 0\\)\n\\(H_1:\\) mindestens ein \\(\\beta_j \\neq 0\\)\nUm zu überprüfen, ob die Prädiktorvariablen insgesamt einen Beitrag zur Erklärung in Unterschieden der abhängigen Variablen erklären, kann die ein \\(F\\)-Test durchgeführt werden.\nPrüfgrösse ist \\(F\\) mit \\(df_1 = k\\) und \\(df_2 = n-k-1\\) Freiheitsgraden. Vereinfacht kann gesagt werden:\n\\(F = \\frac{MQSR}{MQSE}\\)\nRegressionskoeffizienten\n\\(H_0: \\beta_j = \\beta_{0j}\\) wobei \\(\\beta_{0j}\\) das Regressionsgewicht unter der Nullhypothese ist\n\\(H_1: \\beta_j \\neq \\beta_{0j}\\)\nGegen \\(0\\) (häufigster Fall) wäre das\n\\(H_0: \\beta_j = 0\\) \\(H_1: \\beta_j \\neq 0\\)\nEs können wie bei vorherigen Tests auch gerichtete Hypothesen formuliert werden.\nDie Signifikanz einzelner Regressionskoeffizienten, kann mit einer \\(t\\)-Statistik berechnet werden.\nPrüfgrösse ist \\(t\\) mit \\(df = n-k-1\\).\n\\(t = \\frac{b_j - \\beta_{0j}}{\\hat{\\sigma}_{B_j}}\\)\nEin Konfidenzintervall kann konstruiert werden mit\n\\([(b_j - t_{(1 - \\frac{\\alpha}{2}; df)} \\cdot \\hat{\\sigma}_{B_j}) ; (b_j + t_{(1 - \\frac{\\alpha}{2}; df)} \\cdot \\hat{\\sigma}_{B_j}) ]\\)\n\n\n\n15.3.3 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\n\nMultiple regression analysis was used to test if personality traits significantly predicted participants’ ratings of aggression. The results of the regression analysis show that the two predictors explained 35.8% of the variance (\\(R^2\\) = .38, \\(F\\)(2,55) = 5.56, \\(p\\) &lt; .01). It was found that extraversion significantly predicted aggressive tendencies (\\(\\beta\\) = .56, \\(p\\) &lt; .001), as did agreeableness (\\(\\beta\\) = -.36, \\(p\\) &lt; .01).",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/multipleregression.html#anwendungsbeispiel-in-r",
    "href": "datenanalyse/multipleregression.html#anwendungsbeispiel-in-r",
    "title": "15  Multiple Regression",
    "section": "15.4 Anwendungsbeispiel in R",
    "text": "15.4 Anwendungsbeispiel in R\n\n\n\n\n\n\nBeispiel: Schlaf und Konzentration\n\n\n\nStudienbeschrieb: In der (fiktiven) Studie wurde bei Jugendlichen der Einfluss von Schlafdauer und Sport-Training auf die Konzentrationsleistung mit einem neuropsychologischen Test (concentration: mögliche Scores von 0 bis 20) untersucht.\nForschungsfrage: Hängt die Dauer des Sportrainings und die nächtliche Schlafdauer mit der Konzentration am nächsten Tag zusammen?\n\nDie unabhängige Variable sleep enthält Daten über die Schlafdauer (in Stunden) in der vorherigen Nacht.\nDie unabhängige Variable sport enthält Daten über die Traingsdauer (in Stunden) am vorherigen Tag.\nDie abhängige Variable concentration enthält Daten über die Leistung in einem neuropsychologischen Konzentrationstest. Die minimale Punktzahl beträgt 0, die maximale Punktzahl beträgt 20.\n\n\n\nWenn man zwei einzelne Regressionen für die beiden Prädiktorvariablen rechnen würde ergäbe dies zwei Variablenpaare: concentration ~ sleep (blaue Datenpunkte) und concentration ~ sport (rote Datenpunkte).\n\n\n\n\n\n\n\n\n\nBei der multiplen Regression werden beide Prädiktorvariablen gleichzeitig in ein Modell einbezogen.\n\n15.4.1 Planung\n\nStatistische Hypothesen und Signifikanzniveau festlegen\nDas Alphaniveau wird auf \\(5 \\%\\) festgelegt. Da es sich um eine ungerichtete Hypothese handelt, wird zweiseitig getestet.\nHypothesen für den Gesamttest:\n\\(H_0\\): Die Schlafdauer und die Sportdauer haben keinen Einfluss auf die Leistung im Konzentrationstest. \\(\\beta_{sleep} = \\beta_{sport} = 0\\)\n\\(H_1\\): Die Schlafdauer und/oder die Sportdauer sagen die Leistung im Konzentrationstest vorher. \\(\\beta_{sleep}\\) und/oder \\(\\beta_{sport} \\neq 0\\)\nHypothese für einen Regressionskoeffizienten:\n\\(H_0\\): Die Sportdauer hat keinen Einfluss auf die Leistung im Konzentrationstest. \\(\\beta_{sport} = 0\\)\n\\(H_1\\): Die Sportdauer sagt die Leistung im Konzentrationstest vorher. \\(\\beta_{sport} \\neq 0\\)\n\n\nDaten einlesen und vorverarbeiten\n\n\n\n\n\n\nHands-on: Beispieldatensatz Schlaf, Sport und Konzentration\n\n\n\nDer Datensatz kann selber generiert werden mit folgendem Code:\n\n# Laden tidyverse\nlibrary(tidyverse)\n\n# Erstellen des Datensatzes\nd_sport &lt;- tibble(sleep = c(5, 5, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12),\n            sport = c(0.5, 5.4, 2.3, 2.3, 0.2, 0.4, 3.4, 1.2, 1.9, 3.1, 2.0, 5.2, 0.5, 0.6, 1.1, 2.1, 1.1, 1.9),\n            concentration = c(6, 10, 10, 12, 6, 12, 17, 12, 8, 16, 12, 16, 18, 8, 14, 10, 12, 18))\n\nTipp: Sie können dies auch in einer WebR-Konsole tun.\n\n\nFür die Regressionsanalyse mit metrischen Variablen sollten die Variablenwerte im Zahlenformat, also beispielsweise als integer oder double gespeichert sein.\n\n\nVoraussetzungen überprüfen\nMetrisch skalierte Variablen und Linearität\n\nglimpse(d_sport)\n\nRows: 18\nColumns: 3\n$ sleep         &lt;dbl&gt; 5, 5, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 10, 10, 11, 11, 12, …\n$ sport         &lt;dbl&gt; 0.5, 5.4, 2.3, 2.3, 0.2, 0.4, 3.4, 1.2, 1.9, 3.1, 2.0, 5…\n$ concentration &lt;dbl&gt; 6, 10, 10, 12, 6, 12, 17, 12, 8, 16, 12, 16, 18, 8, 14, …\n\n\nLinearität\nIm obigen Plot sind keine auffälligen nonlinearen Beziehungen zwischen der concentration und sleep bzw. concentration sichtbar.\nSobald das Regressionsmodell geschätzt wurde, können die weiteren Voraussetzungen überprüft werden.\n\n\n\n15.4.2 Analyse\n\nRegressionsmodell\nDie multiple Regression kann, sofern die Daten nicht hierarchisch geordnet sind, mit der Funktion lm() aus dem schon in R installierten Package {stats} berechnet werden.\nAls Argumente benötigt die Funktion lm() die Modellgleichung (av ~ uv1 + uv2) und den Datensatz mit den Variablen (data = ...). Die Resultate der Regressionsanalyse können mit der Funktion summary() zusammengefasst werden.\n\n# Multiple Regression berechnen\nm1 &lt;- lm(concentration ~ sleep + sport,\n            data = d_sport)\n\n# Output ausgeben\nsummary(m1)\n\n\nCall:\nlm(formula = concentration ~ sleep + sport, data = d_sport)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.4910 -2.6881 -0.2208  2.5439  6.1126 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   2.6177     3.5404   0.739   0.4711  \nsleep         0.8729     0.3643   2.396   0.0300 *\nsport         1.0817     0.5372   2.013   0.0624 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.291 on 15 degrees of freedom\nMultiple R-squared:  0.3474,    Adjusted R-squared:  0.2604 \nF-statistic: 3.993 on 2 and 15 DF,  p-value: 0.04072\n\n\n\n\nKonfidenzintervalle\nKonfidenzintervalle können mit der Funktion confint() bestimmt werden.\n\n# 95%-Konfidenzintervall bestimmen\nconfint(m1, level = 0.95)\n\n                  2.5 %    97.5 %\n(Intercept) -4.92863568 10.163942\nsleep        0.09647021  1.649299\nsport       -0.06337326  2.226821\n\n\nDie 95%-Konfidenzintervalle beinhalten 0 sowohl für den Achsenabschnitt (intercept), wie auch für die Variable sport. Für sleep beinhaltet das 95%-Konfidenzintervall 0 nicht.\nEs können auch 90%-Konfidenzintervalle (oder jede andere Prozentzahl) bestimmt werden:\n\n# 90%-Konfidenzintervall bestimmen\nconfint(m1, level = 0.90)\n\n                   5 %     95 %\n(Intercept) -3.5889325 8.824239\nsleep        0.2343081 1.511461\nsport        0.1399174 2.023530\n\n\n\n\nModellannahmen überprüfen\nMit dem Package {performance} können die Modellannahmen einer multiplen Regression überprüft werden.\n\nVor dem ersten Verwenden muss das Package {performance} heruntergeladen/installiert werden, z.B. in der Konsole mit install.packages(\"performance\").\n\nDie Funktion check_model() gibt diagnostische Plots aus:\n\nperformance::check_model(m1)\n\n\nWie die Plots gelesen werden sollten und was getan werden kann, wenn die Annahmen nicht erfüllt sind, wird auf der Website des Packages {performance} sehr gut beschrieben.\nLinearität\nOb die Linearität gegeben ist, kann in folgendem Plot visuell beurteilt werden. Die Referenzlinie (grün) sollte ungefähr gerade sein und horizontal liegen. Der graue Bereich sollte immer die gerade schwarze Linie beinhalten.\n\ndiagnostic_plots &lt;- plot(performance::check_model(m1, panel = FALSE))\n\n# check linearity\ndiagnostic_plots[[2]]\n\n\n\n\n\n\n\n\nHomoskedastizität\nDie Homoskedastizität kann ebenfalls im oberen Plot überprüft werden. Wenn die Streuung der Residuen um die Regressionsgerade unterschiedlich ist, dann ist die Annahme der Varianzhomogenität nicht erfüllt. Heteroskedastizität kann beispielsweise so aussehen, dass die Residuen bei tiefen Werten von \\(x\\) sehr wenig streuen und bei hohen Werten von \\(x\\) stärker streuen (wie ein Trichter).\nFolgender Plot zeigt die Wurzel der absoluten4 Residuen (standardisiert). Weil es so keine negativen Abweichungen mehr gibt, kann in die Abweichung der Residuen eine Linie hineingelegt werden, die möglichst parallel zu \\(0\\) sein sollte. Im Beispiel der obigen Trichterform würde dann eine ansteigende Linie zu sehen sein.\n\n# check homogeneity of variance\ndiagnostic_plots[[3]]\n\n\n\n\n\n\n\n\nDie Homoskedastizität kann weiter mit der Funktion check_heteroscedasticity() überprüft werden (Breusch-Pagan test).\n\nperformance::check_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.809).\n\n\nNormalverteilung der Fehlervariablen\nDie Normalverteilung der Residuen kann mit einem Q-Q-Plot überprüft werden.\n\n# check normality of residuals\ndiagnostic_plots[[6]]\n\n\n\n\n\n\n\n\nDie Normalverteilung der Fehlervariablen kann weiter mit der Funktion check_normality() überprüft werden (Shapiro-Wilk test).\n\nperformance::check_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.549).\n\n\nOutlier erkennen\n\n# detect outliers\ndiagnostic_plots[[4]]\n\n\n\n\n\n\n\n\nMultikollinearität\nWenn die Prädiktor miteinander sehr stark korrelieren wird dies Multikollinearität genannt. Dies kann zu ungenauen Parameterschätzungen führen (durch einen erhöhten Standardfehler des Regressionskoeffizienten). Die Werte im grünen Bereich sind hier ok.\n\n# detect collinearity\ndiagnostic_plots[[5]]\n\n\n\n\n\n\n\n\n\n\nVisualisierungen\nZur Visualisierung von Unterschieden eignen sich Punktdiagramme (Scatterplots) und das Einzeichnen der Regressionsgeraden (z.B. mit geom_abline() oder geom_smooth() für jedes Variablenpaar.\nMöchte man den Einfluss beider Prädiktorvariablen gleichzeitig visualisieren, kann man für eine Variable eine Farbkodierung nutzen. Dies ist auch interaktiv möglich5, z.B. so:\n\nggiraphExtra::ggPredict(m1,interactive=TRUE)\n\n\n\n\n\n\n{ggiraph}-Package\n\nIn diesem Modell sind keine Interaktionen zugelassen, deshalb sind alle Linien parallel.\n\n\n\n\n\n\nFür Interessierte: Modell mit Interaktion\n\n\n\n\n\nSoll die Interaktion von Schlaf und Sport in das Modell einbezogen werden, kann dies mit einem * in der Modellgleichung implementiert werden:\n\nm1_interaction &lt;- lm(concentration ~ sleep * sport, \n                     data = d_sport)\n\nSo wird ein zusätzlicher Regressionskoeffizient für die Interaktion geschätzt:\n\nsummary(m1_interaction)\n\n\nCall:\nlm(formula = concentration ~ sleep * sport, data = d_sport)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6149 -2.2305 -0.4475  2.4947  6.3219 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  3.58457    5.25390   0.682    0.506\nsleep        0.74555    0.62321   1.196    0.251\nsport        0.56273    2.09982   0.268    0.793\nsleep:sport  0.07132    0.27831   0.256    0.801\n\nResidual standard error: 3.399 on 14 degrees of freedom\nMultiple R-squared:  0.3505,    Adjusted R-squared:  0.2113 \nF-statistic: 2.518 on 3 and 14 DF,  p-value: 0.1004\n\n\nVisualisiert sieht das wie folgt aus:\n\nggiraphExtra::ggPredict(m1_interaction,interactive=TRUE)\n\n\n\n\n\nDeskriptiv hat Schlaf immer einen positiven Einfluss auf die Konzentration. Dieser Einfluss nimmt jedoch ab, je höher die Werte für Sport sind (je mehr Trainingsstunden absolviert wurden). Dies wird sichtbar daran, dass der Regressionskoeffizient bei den tieferen Sportwerten (dunkleres Blau) kleiner ist, als bei den höheren Sportwerten (helleres Blau).6 Inferenzstatistisch sind die Effekte von Schlaf, Sport wie auch der Interaktion nicht signifkant.\n\n\n\nDurch die Visualisierung der Rohwerte und der Regressionsgeraden, kann der “Fit”, also die Passung der Geraden zu den Daten gut visuell überprüft werden. Sichtbar wird auch, wenn die Daten nichtlineare Zusammenhänge aufweisen, die nicht mit einer linearen Regression analysiert werden können, wie beispielsweise kurvilineare Zusammenhänge.\n\n\n\n15.4.3 Schlussfolgerungen\n\nErgebnisse interpretieren und berichten\n\nMultiple regression analysis was used to test if duration of sport training and sleep significantly predicted performance in a concentration test in young adults. The results of the regression analysis show that the two predictors explained 35% of the variance (\\(R^2\\) = .35, \\(F\\)(2,15) = 3.99, \\(p\\) = .041). It was found that sleep duration significantly predicted concentration (\\(\\beta_{sleep}\\) = .87, \\(p\\) = .030), whereas sport duration did not show a significant effect on concentration (\\(\\beta_{sport}\\) = 1.08, \\(p\\) = .062).",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/multipleregression.html#weiterführende-informationen",
    "href": "datenanalyse/multipleregression.html#weiterführende-informationen",
    "title": "15  Multiple Regression",
    "section": "15.5 Weiterführende Informationen",
    "text": "15.5 Weiterführende Informationen\n\nInteraktive Visualisierung von Zusammenhängen von RPsychologist\nInteraktive Visualisierung von Konfidenzintervallen von RPsychologist\n{performance}-Package für Modelltests mit check_model()\n{ggiraph}-Package für interaktive Visualisierungen von Modellen",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/multipleregression.html#footnotes",
    "href": "datenanalyse/multipleregression.html#footnotes",
    "title": "15  Multiple Regression",
    "section": "",
    "text": "Prädiktorvariablen, unabhängigen Variablen, Regressoren↩︎\nKriteriumsvariablen, abhhängigen Variablen, Regressand↩︎\nDie multiple Regression kann auch mit kategorialen Variablen berechnet werden. Dies wird in diesem Kapitel nicht behandelt, siehe Allgemeines lineares Modell für mehr Informationen.↩︎\nDas bedeutet, dass für ein Residuum von \\(-2\\) der Wert \\(2\\) verwendet würde.↩︎\nVerwirrenderweise ist der Regressionskoeffizient hier der erste Wert, der Achsenabschnitt kommt am Schluss.↩︎\nVerwirrenderweise ist der Regressionskoeffizient hier der erste Wert, der Achsenabschnitt kommt am Schluss.↩︎",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "datenanalyse/alm.html",
    "href": "datenanalyse/alm.html",
    "title": "16  Allgemeines lineares Modell",
    "section": "",
    "text": "16.1 Definition\nIm allgemeinen linearen Modell können Prädiktoren sowohl metrisch, wie auch kategorial sein (z.B. dichotom mit 2 Ausprägungen). Für die Berechnung der Regression werden die kategorialen Prädiktorvariablen kodiert (Dummy-Codierung). \\(t\\)-Tests und ANOVAs sind somit eine Form der Regressionsanalyse mit einem kategorialen Prädiktor. Von Vorteil ist vor allem, dass kategoriale und metrische Prädiktoren gleichzeitig ins Modell einbezogen werden können. Dies ist in der Psychologie und den Verhaltenswissenschaften oft von Nutzen.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Allgemeines lineares Modell</span>"
    ]
  },
  {
    "objectID": "datenanalyse/alm.html#definition",
    "href": "datenanalyse/alm.html#definition",
    "title": "16  Allgemeines lineares Modell",
    "section": "",
    "text": "“Das ALM ist eine verallgemeinerte Annahme über Datenzusammenhänge, die es gestattet, die Ausprägungen der Kriteriumsvariablen (…) als gewichtete Summe (Linearkombination) von Prädiktorvariablen (…) und einer Fehlerkomponente (Residuum) darzustellen.” https://dorsch.hogrefe.com/stichwort/allgemeines-lineares-modell",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Allgemeines lineares Modell</span>"
    ]
  },
  {
    "objectID": "datenanalyse/alm.html#einteilung-linearer-modelle",
    "href": "datenanalyse/alm.html#einteilung-linearer-modelle",
    "title": "16  Allgemeines lineares Modell",
    "section": "16.2 Einteilung linearer Modelle",
    "text": "16.2 Einteilung linearer Modelle\nLineare Modelle werden je nach Skalenniveau der Prädiktorvariablebn und Anzahl Modelparameter anders genannt.\nSkalenniveau der Prädiktorvariablen:\n\nModelle mit metrischen1 (kontinuierlichen oder mindestens intervallskalierten) Prädiktorvariablen werden Regressionsanalysen genannt.\nModelle mit kategorialen (ordinal- oder nominalskalierten)2 Variablen werden Varianzanalysen genannt.\n\nAnzahl Prädiktoren:\n\nModelle mit einer Prädiktorvariable (AV und UV) entsprechen einer einfachen Regressionsanalyse bzw. eine \\(t\\)-Test.\nModelle mit mehr als einer Prädiktorvariablen entsprechen einer multiple Regressionsanalyse bzw. einer ANOVA.\n\n\n\n\nTabelle Lineare Modelle mit einem und mehreren Prädiktoren\n\n\n\n\n16.2.1 Beispiel: \\(t\\)-Test als einfache lineare Regression\nAngenommen die Gruppenzugehörigkeit (Gruppe \\(A\\) oder \\(B\\)) ist in der Variablen \\(x\\) enthalten und soll \\(y\\) vorhersagen. Die Variable \\(x\\) ist also eine kategoriale Prädiktorvariable. Für die Berechnung der der Regression wird die kategoriale Prädiktorvariable kodiert (Dummy-Codierung). In der Variablen \\(x\\) (Gruppe) wird der Gruppe \\(A\\) beispielsweise der Wert 0 (\\(x_A = 0\\)) und Gruppe \\(B\\) der Wert 1 (\\(x_B = 1\\)) zugeordnet. Die Gruppe \\(A\\) entspricht somit dem Achsenabschnitt \\(b_0\\) (da der Wert \\(x_A = 0\\) das Regressionsgewicht aufhebt). Wenn \\(x\\) also eine Einheit ansteigt zu \\(x_B\\) (von 0 zu 1), dann entspricht der Wert des Regressionskoeffizienten dem Unterschied in \\(y\\) zwischen der Gruppe \\(A\\) und \\(B\\).\nDas bedeutet, dass in R ein \\(t\\)-Test sowie eine ANOVA mittels der Funktion lm() berechnet werden können. Entscheidend ist, dass die Modell-Formel korrekt spezifiziert wird.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Allgemeines lineares Modell</span>"
    ]
  },
  {
    "objectID": "datenanalyse/alm.html#footnotes",
    "href": "datenanalyse/alm.html#footnotes",
    "title": "16  Allgemeines lineares Modell",
    "section": "",
    "text": "quantitativ abgestuften↩︎\nqualitativ abgestuften↩︎",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Allgemeines lineares Modell</span>"
    ]
  },
  {
    "objectID": "uebungen/uebungen.html",
    "href": "uebungen/uebungen.html",
    "title": "Informationen",
    "section": "",
    "text": "Dieses Kapitel enthält die Übungsmaterialien begleitend zur Vorlesung.\nTutoriat in den Übungsgruppen\nDie Aufgaben werden in den Übungsgruppen mit Tutoriat gemeinsam bearbeitet.\nArbeiten mit RProjekten \nErstellen Sie immer zuerst ein RProjekt für die Übung bevor Sie mit den Aufgaben beginnen und benennen Sie dieses Projekt z.B. nach der Übung: Uebung_7).\nTeilweise erhalten Sie für eine oder mehrere Übungen einen vorgefertigten Projekt-Ordner. Achtung: Ordner müssen vor dem Bearbeiten entzippt werden.\nDatensätze\nDie für die Übungen verwendeten Datensätze können am Anfang der Übungen per Link heruntergeladen werden.",
    "crumbs": [
      "Übungen",
      "Informationen"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html",
    "href": "uebungen/uebung-01.html",
    "title": "Übung 1",
    "section": "",
    "text": "Aufgabe 1.1. Installation von R und RStudio\nInstallieren Sie R und RStudio, wie in 1  Installation beschrieben.",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html#aufgabe-1.2-packages-installieren",
    "href": "uebungen/uebung-01.html#aufgabe-1.2-packages-installieren",
    "title": "Übung 1",
    "section": "Aufgabe 1.2 Packages installieren",
    "text": "Aufgabe 1.2 Packages installieren\nInstallieren Sie das Package {tidyverse} entweder über die Konsole oder über Tools.",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html#aufgabe-1.3-rproject-und-rskript-erstellen",
    "href": "uebungen/uebung-01.html#aufgabe-1.3-rproject-und-rskript-erstellen",
    "title": "Übung 1",
    "section": "Aufgabe 1.3: RProject und RSkript erstellen",
    "text": "Aufgabe 1.3: RProject und RSkript erstellen\n\nErstellen Sie (an einem für Sie geeigneten Ort auf Ihrem Rechner) einen Ordner für alle Übungen in Statistik 2 mit dem Namen Statistik2. \nÖffnen Sie RStudio und erstellen Sie in diesem Ordner ein RProject mit dem Namen introduction_to_r.\nErstellen Sie in RStudio ein RSkript (Endung .R).\nSpeichern Sie dieses Skript im RProjekt-Ordner mit dem Namen introskript ab.\nErstellen Sie im aktuellen RProjekt-Ordner einen Unterordner namens data. Laden Sie dann die Datensätze herunter und speichern Sie diese im data-Ordner.\n\nDatensatz 1\nDatensatz 2",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html#aufgabe-1.4-operatoren-und-funktionen-verwenden",
    "href": "uebungen/uebung-01.html#aufgabe-1.4-operatoren-und-funktionen-verwenden",
    "title": "Übung 1",
    "section": "Aufgabe 1.4: Operatoren und Funktionen verwenden",
    "text": "Aufgabe 1.4: Operatoren und Funktionen verwenden\n\nSchreiben Sie in das Skript untenstehenden Code und führen Sie diesen aus.\n\n\nlibrary(tidyverse)\nnumbers &lt;- c(43, 65, 23, 78, 34, 73, 69, 14, 37, 84)\n\nWie können Sie nun nachschauen, welche Werte in der Variable vorhanden sind?\n\nBerechnen Sie folgende Werte:\n\nMittelwert der Variable numbers.\nStandardabweichung der Variable numbers.\nSumme der Variable numbers\nWas passiert, wenn Sie die Variable numbers mit sich selber addieren (numbers + numbers) oder multiplizieren?\nWas passiert, wenn Sie die Wurzel nehmen?\n\nErstellen Sie eine Variable words mit den Wörtern yellow, green und red darin.\n\nWas passiert, wenn Sie den Mittelwert der Variable words berechnen?\nWelcher Wert wird ausgegeben?\nGibt es eine Warnung oder eine Fehlermeldung?\n\nWas passiert, wenn Sie die Variable words mit sich selber addieren?\n\nWelcher Wert wird ausgegeben?\nGibt es eine Warnung oder eine Fehlermeldung?\n\nDiskutieren Sie kurz zusammen: Wie unterscheiden sich Warnungen von Fehlermeldungen?",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html#aufgabe-1.5-rnotebook-erstellen-und-packages-laden",
    "href": "uebungen/uebung-01.html#aufgabe-1.5-rnotebook-erstellen-und-packages-laden",
    "title": "Übung 1",
    "section": "Aufgabe 1.5: RNotebook erstellen und Packages laden",
    "text": "Aufgabe 1.5: RNotebook erstellen und Packages laden\n\nErstellen Sie ein RNotebook und speichern Sie es unter dem Namen intronotebook ab.\nIdentifizieren Sie die 3 Bausteine eines Notebooks: Header, Textfeld und Codefeld mit folgenden Fragen:\n\nWoran erkennt man den Baustein?\nFür was eignet sich der Baustein besonders und für was nicht?\n\nGeben Sie dem Notebook einen Titel.\nLaden Sie in einem Codefeld das Package {tidyverse} mit\n\n\nlibrary(tidyverse)\n\n\nBeschreiben Sie im Textfeld über dem Codefeld was der Code machen sollte.",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html#aufgabe-1.6-daten-einlesen",
    "href": "uebungen/uebung-01.html#aufgabe-1.6-daten-einlesen",
    "title": "Übung 1",
    "section": "Aufgabe 1.6: Daten einlesen",
    "text": "Aufgabe 1.6: Daten einlesen\nIn dieser Aufgabe arbeiten wir weiter mit dem RNotebook von oben.\n\nErstellen Sie ein neues Codefeld.\nLesen Sie den Datensatz stroop_data_sub-001.csv aus dem data-Ordner ein. Gehen Sie dabei schrittweise vor:\n\nWelche Endungen hat die Datei?\nImportieren Sie die Daten mit dem GUI.\nLöschen Sie die Variable aus dem Environment.\nImportieren Sie den Datensatz mit Code. Verwenden Sie dafür den Variablennamen d1 für den Datensatz (bzw. d2 für den zweiten Datensatz).\n\n\n\nd1 &lt;- ...(\"data/...\")\n\nFühren Sie dieselben Schritte für stroop_data_sub-001.xlsx aus. Denken Sie daran, dass die Einlesefunktion für .xlsx-Dateien aus dem Package {readxl} stammt und sie dieses zuerst laden müssen.\n\nd2 &lt;- ...\n\n\nDiskutieren Sie kurz zusammen:\n\nWas war schwierig? Was fällt Ihnen auf?\nWas sind Separators?\nWelcher Weg fällt Ihnen leichter?",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html#aufgabe-1.7-datensätze-anschauen",
    "href": "uebungen/uebung-01.html#aufgabe-1.7-datensätze-anschauen",
    "title": "Übung 1",
    "section": "Aufgabe 1.7: Datensätze anschauen",
    "text": "Aufgabe 1.7: Datensätze anschauen\nSchauen Sie sich die beiden Datensätze auf vier Arten an:\n\nindem Sie im Environment mit dem Pfeil den Datensatz aufklappen.\nindem Sie im Environment auf den Namen doppelklicken.\nindem Sie den Namen der Variable eingeben (in der Konsole oder im RNotebook).\nindem Sie untenstehenden Code eingeben (... muss mit einer Variable ersetzt werden):\n\n\nglimpse(...)",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-01.html#aufgabe-1.8-visualisieren-der-datensätze",
    "href": "uebungen/uebung-01.html#aufgabe-1.8-visualisieren-der-datensätze",
    "title": "Übung 1",
    "section": "Aufgabe 1.8: Visualisieren der Datensätze",
    "text": "Aufgabe 1.8: Visualisieren der Datensätze\n\nInstallieren Sie das Package {esquisse}. Verwenden Sie hierzu entweder den Reiter Tools&gt; Install Packages... oder ergänzen Sie den untenstehenden Code.\n\n\n# Ergänzen Sie diesen Code und schreiben Sie ihn in die Konsole und NICHT ins RNotebook.\n__(\"esquisse\")\n\nWieso sollte das Package nicht im RNotebook installiert werden?\n\nGeben Sie in der Konsole folgenden Code ein:\n\n\nesquisse::esquisser()\n\n\n\n\n\n\n\nFigure 1: Auswahl des Datensatzes in Equisser\n\n\n\n\nSchauen Sie sich nacheinander die beiden Datensätze an.\n\nWelche Variablen gibt es und welches Skalenniveau haben diese?\nIst die Variable rt normalverteilt?\nWelche Darstellungsform eignet sich am besten?\nLassen Sie sich für die beste Darstellung des Datensatzes einen Code ausgeben.\nSpeichern Sie Ihr RNotebook ab. Speichern Sie alle Änderungen in Ihrem RNotebook. Der Titel sollte nicht mehr in rot geschrieben sein und keinen Stern nach dem Namen haben.\n\n\n\n\n\n\n\n\nFigure 2: Beispiel Equisser\n\n\n\n\nSchliessen Sie Ihr RProject und öffnen Sie es erneut.\nFalls nötig: Öffnen Sie ihr intronotebook.Rmd-File wieder. Dies können Sie unter File &gt; Open File tun oder im rechten unteren Quadranten unter Files.\nFühren Sie Ihren Code mit Run all aus. Jetzt sollten Sie zum Schluss eine Grafik angezeigt erhalten.\nZeigen Sie einander die Grafiken und diskutieren Vor- und Nachteile der Darstellungsformen.\n\n\n\n\n\n\n\nBei Problemen…\n\n\n\nDer Einstieg ins Programmieren mit R ist nicht einfach. Falls Sie Fragen zu den Übungen haben, dürfen Sie diese zusätzlich in der R Sprechstunde nächste Woche stellen. Kommen Sie einfach mit Ihrem Computer vorbei und wir schauen es an.",
    "crumbs": [
      "Übungen",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html",
    "href": "uebungen/uebung-02.html",
    "title": "Übung 2",
    "section": "",
    "text": "Aufgabe 2.1: Help\nFinden Sie heraus, was diese Funktionen tun, welche Argumente sie benötigen und welchen Output sie generieren. Wählen Sie verschiedene Wege die Aufgabe zu lösen (z.B. Suchmaschine, Help in R, ?function, Autocomplete mit Tab).",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html#aufgabe-2.1-help",
    "href": "uebungen/uebung-02.html#aufgabe-2.1-help",
    "title": "Übung 2",
    "section": "",
    "text": "glimpse()\nunique()\nwrite.csv()\nvar()\nsum()",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html#aufgabe-2.2-datensatz-formate-und-data-dictionaries",
    "href": "uebungen/uebung-02.html#aufgabe-2.2-datensatz-formate-und-data-dictionaries",
    "title": "Übung 2",
    "section": "Aufgabe 2.2: Datensatz-Formate und Data Dictionaries",
    "text": "Aufgabe 2.2: Datensatz-Formate und Data Dictionaries\na. Laden Sie das Package {tidyverse}.\nb. Lesen Sie die 3 Datensätze ein:\n\nreadingskills_clean.csv\nexperiment1.csv\nexperiment2.csv\n\nc. Bestimmen Sie für jeden Datensatz, welches Format der Datensatz hat Long oder Wide. Mehr Infos zu den Formaten finden Sie hier.\nd. Schreiben Sie für jeden der Datensätze ein Data Dictionary mit den unten vorgegebenen Spalten.\nTipps:\n\nSie können das Data Dictionary auf Papier, in einem Textprogramm, oder auch im RNotebook erstellen. Tabellen mit Markdown können z.B. auf dieser Website erstellt und dann ins RNotebook kopiert werden.\nDen Variablentyp sehen Sie z.B. im Environment, wenn Sie den Datensatz aufklappen, oder wenn Sie die Funktion glimpse() nutzen.\nFinden Sie den kleinsten und grössten Wert bequem mit min() und max() heraus. Hierzu müssen Sie als Argument für die Funktion datensatznamen$variable verwenden.\n\n\nBeispiel Data-Dictionary\n\n\n\n\n\n\n\nVariablennamen\nVariablentyp\nRange (kleinster Wert, grösster Wert)\n\n\n\n\nz.B. id\ncharacter\nsub-01 bis sub-55\n\n\n…\n…\n…\n\n\n…\n…\n…\n\n\n\ne. Löschen Sie zum Ende dieser Aufgabe alle Variablen (gespeicherten Datensätze) aus dem Environment im oberen rechten Quadranten, indem Sie auf das Besen-Icon klicken.",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html#aufgabe-2.3-data-cleaning",
    "href": "uebungen/uebung-02.html#aufgabe-2.3-data-cleaning",
    "title": "Übung 2",
    "section": "Aufgabe 2.3: Data cleaning",
    "text": "Aufgabe 2.3: Data cleaning\na. Lesen Sie die Beschreibung zum Datensatz milgram.csv und beantworten Sie folgende Frage:\nWelche Hypothese haben Sie: In welcher Gruppe (1, 2, 3) haben die Personen das Experiment am stärksten als “unethisch” empfunden (also im Rating von 1 (überhaupt nicht ethisch) bis 9 (völlig ethisch) die tiefsten Werte angegeben)? Stellen Sie hier einfach eine Vermutung auf ohne die Daten anzuschauen.\n\n\n\n\n\n\nDatensatz milgram.csv\n\n\n\n\n\nIn dieser Aufgabe wird mit dem Datensatz milgram.csv gearbeitet.\nDer Datensatz stammt aus dem Package {Stat2Data}. Sie müssen dieses Package nicht installieren, sondern können einen angepassten Datensatz zu Beginn dieser Übung herunterladen.\nDer Datensatz stammt nicht direkt vom Milgram Experiment, sondern von einer Folgestudie.1\nBeschreibung:\n\nEine der berühmtesten und verstörendsten psychologischen Studien des 20. Jahrhunderts fand im Labor von Stanley Milgram an der Yale University statt. Milgrams Probanden wurden gebeten, die Antworten eines „Lernenden“ zu überwachen und einen Knopf zu drücken, um Schocks auszulösen, wenn der Lernende eine falsche Antwort gab. Je mehr falsche Antworten, desto stärker der Schock. Sogar Milgram selbst war von den Ergebnissen überrascht: Jeder seiner Probanden versetzte einem langsamen „Lernenden“ als Strafe für wiederholte falsche Antworten einen seiner Meinung nach gefährlichen 300-Volt-Schock. Auch wenn die „Schocks“ nicht real waren und der „Lernende“ in das Geheimnis eingeweiht war, lösten die Ergebnisse eine hitzige Debatte über Ethik und Experimente mit Menschen aus. Um die Einstellungen zu diesem Thema zu untersuchen, führte die Harvard-Doktorandin Maryann de Mateo ein randomisiertes Vergleichsexperiment durch. Ihre Probanden waren 37 High-School-Lehrer, die nichts von der Milgram-Studie wussten. Per Zufall ordnete Maryann jeden Lehrer einer von drei Behandlungsgruppen zu:\n\n\n\nGruppe 1 (Tatsächliche Ergebnisse der echten Milgramstudie): Jeder High-School-Lehrer in dieser Gruppe las eine Beschreibung von Milgrams Studie, einschliesslich der tatsächlichen Ergebnisse, dass jeder Proband einen sehr starken „Schock“ lieferte.\n\n\n\n\nGruppe 2 (Viele kamen der Bitte nach): Jeder High-School-Lehrer las die gleiche Beschreibung wie die High-School-Lehrer in Gruppe 1, mit der Ausnahme, dass die tatsächlichen Ergebnisse durch gefälschte Ergebnisse ersetzt wurden und viele, aber nicht alle Probanden sich daran hielten einen sehr starken “Schock” zu geben.\n\n\n\n\nGruppe 3 (Die meisten lehnten ab): Für die High-School-Lehrer dieser Gruppe hiess es in den gefälschten Ergebnissen, dass sich die meisten Probanden weigerten, einen sehr starken “Schock” abzugeben.\n\n\n\nNach der Lektüre der Beschreibung wurde jeder High-School-Lehrer gebeten, die Studie danach zu bewerten, wie ethisch er sie fand, von 1 (überhaupt nicht ethisch) bis 9 (völlig ethisch).\n\n\n\n\nb. Lesen Sie den Datensatz milgram.csv ein und speichern Sie ihn in die Variable d_milgram.\nc. Schauen Sie den Datensatz mit glimpse() oder head() an.\nd. Erstellen Sie ein Data Dictionary, wie in Aufgabe 2.2.\n\nNutzen Sie die Funktionen min() und max() für numerische Variablen.\nNutzen Sie die Funktion unique() für nicht-numerische Variablen.\n\n\nDie Funktionen min() und max() funktionieren nicht gut, wenn Sie NAs im Datensatz haben. Falls dies der Fall ist wird Ihnen einfach NA angezeigt, statt einer Zahl. Sie können z.B. stattdessen summary() verwenden und wissen nun, dass Sie im Datensatz die NAs noch anschauen müssen beim Vorverarbeiten.\n\ne. Schauen Sie sich den Datensatz nochmals an, indem Sie im Environment darauf doppelklicken. Nutzen Sie zusätzlich die Funktion describe() aus dem {Hmisc}-Package. Laden Sie das Package nicht dafür, sondern nutzen Sie die Syntax packagename::functionname().\nBeantworten Sie dann folgende Fragen zum Datensatz:\n\nWelche Gruppennummer entspricht welcher Bedingung (condition)?\nIn welcher Variable finden sich die Ethik-Ratings?\nWas fällt Ihnen zu den Datenpunkten auf? Was müsste getan werden bevor mit der Analyse begonnen wird?\n\nf. Bereinigen Sie den Datensatz und speichern Sie ihn in der Variable d_milgram_clean. Es müssen zum Schluss folgende Kriterien erfüllt sein:\n\nDie Versuchspersonenidentifikationsvariable heisst id.\nAlle Messungen (Zeilen) mit NA-Werten wurden gelöscht.\nKeine Versuchspersonennummer kommt doppelt vor.\nDie Variable score heisst ethic_rating.\n\nZur Überprüfung:\n\nDer bereinigte Datensatz heisst d_milgram_clean und ist im Long-Format.\nEr enthält 3 Variablen: id, condition, ethic_rating.\nEr enthält 37 Messungen (obs steht für observations, also Messungen)\n\ng. Nutzen Sie nochmals die Funktion describe(): Wo gibt es einen Unterschied? Schauen Sie, ob Sie min() und max() nun nutzen können.\nh. Speichern Sie den neuen Datensatz mit der folgenden Zeile ab:\n\nwrite.csv(d_milgram_clean, \"data/milgram_clean.csv\", row.names = FALSE)",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html#aufgabe-2.4-deskriptivstatistik",
    "href": "uebungen/uebung-02.html#aufgabe-2.4-deskriptivstatistik",
    "title": "Übung 2",
    "section": "Aufgabe 2.4: Deskriptivstatistik",
    "text": "Aufgabe 2.4: Deskriptivstatistik\nJetzt können wir die Gruppen in den verschiedenenen Bedingungen vergleichen.\na. Berechnen Sie für jede Gruppe den Mittelwert und die Standardabweichung der Ethik-Ratings.\nGehen Sie hierzu wie folgt vor:\n\nNehmen Sie den bereinigten Datensatz\nGruppieren Sie den Datensatz nach Bedingungen (Experimentalgruppen).\nBerechnen Sie den Mittelwert und die Standardabweichung für alle drei Bedingungen.\nErstellen mit den obigen Schritten einen neue Variable namens d_milgram_summary.\n\nb. Lassen Sie sich die Resultate anzeigen indem Sie die Variable aufrufen. Welche Gruppe hat das Milgram-Experiment am höchsten eingeschätzt bezüglich der Ethik? Überrascht Sie das Resultat?\n\nd_milgram_summary",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html#aufgabe-2.5-visualisierung",
    "href": "uebungen/uebung-02.html#aufgabe-2.5-visualisierung",
    "title": "Übung 2",
    "section": "Aufgabe 2.5: Visualisierung",
    "text": "Aufgabe 2.5: Visualisierung\nErstellen Sie eine Abbildung, welche die Ratings in den drei Gruppen aufzeigt. Zeigen Sie einander Ihre Grafiken.\n\nWas funktioniert gut?\nWelche Formen eignen sich weniger?\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nSie können mehrere Formen übereinanderlegen. Informative Grafiken haben oft ein zusammenfassende Form (z.B. Boxplot) und Formen, die die Datenpunkte aufzeigen.\n\n\n\n\nesquisse::esquisser()",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html#aufgabe-2.6-zusatzaufgabe",
    "href": "uebungen/uebung-02.html#aufgabe-2.6-zusatzaufgabe",
    "title": "Übung 2",
    "section": "Aufgabe 2.6: Zusatzaufgabe",
    "text": "Aufgabe 2.6: Zusatzaufgabe\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nDies ist eine Zusatzaufgabe für Fortgeschrittene. Sie muss nicht gelöst werden.\n\n\nSchauen Sie sich den Datensatz readingskills_clean.csv an:\n\nVergleichen Sie die Gruppenmittelwerte, in dem Sie den Datensatz gruppieren und zusammenfassen. Unterscheiden sich die Kinder mit und ohne Dyslexie in der Leseleistung? Und im IQ?\nBerechnen Sie die Korrelation von Leseleistung und IQ. Hängen die beiden Werte zusammen?\nBerechnen Sie die Korrelation von Leseleistung und IQ separat für Kinder mit und ohne Dyslexie. Was fällt Ihnen auf?\nVisualisieren Sie die Daten.\nKopieren Sie den Code von esquisser und versuchen Sie diesen in Ihrem RNotebook zu modifizieren.\n\nForschungsfragen:\n\nUnterscheiden sich Kinder mit und ohne Dyslexie in Leseleistung und IQ?\nWie hängen Leseleistung und IQ in diesem Datensatz zusammen?\nUnterscheidet sich der Zusammenhang von IQ und Leseleistung zwischen den Gruppen in seiner Stärke?",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-02.html#footnotes",
    "href": "uebungen/uebung-02.html#footnotes",
    "title": "Übung 2",
    "section": "",
    "text": "DiMatteo, Mary Ann (1972): “An experimental study of attitudes toward deception” by Mary Ann DiMatteo. Unpublished manuscript, Department of Psychology and Social Relations, Harvard University. ↩︎",
    "crumbs": [
      "Übungen",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebungen/uebung-04.html",
    "href": "uebungen/uebung-04.html",
    "title": "Übung 4",
    "section": "",
    "text": "Aufgabe 4.1: Projektumgebung\nFalls obige Anforderungen noch nicht erfüllt:",
    "crumbs": [
      "Übungen",
      "Übung 4"
    ]
  },
  {
    "objectID": "uebungen/uebung-04.html#aufgabe-4.1-projektumgebung",
    "href": "uebungen/uebung-04.html#aufgabe-4.1-projektumgebung",
    "title": "Übung 4",
    "section": "",
    "text": "Laden Sie den Projektordner herunter und entzippen Sie den Ordner.\nÖffnen Sie das RProjekt ttests.\nInstallieren Sie die benötigten Packages (falls noch nicht geschehen:\n\ndas Package {pwr} in der Konsole mit install.packages(\"pwr\") oder mit Tools &gt; Install Packages...\ndas Package {car} in der Konsole mit install.packages(\"car\") oder mit Tools &gt; Install Packages...\ndas Package {effsize} in der Konsole mit install.packages(\"effsize\") oder mit Tools &gt; Install Packages...\n\nErstellen ein RNotebook names uebung-04.",
    "crumbs": [
      "Übungen",
      "Übung 4"
    ]
  },
  {
    "objectID": "uebungen/uebung-04.html#aufgabe-4.2-t-test-ausführen",
    "href": "uebungen/uebung-04.html#aufgabe-4.2-t-test-ausführen",
    "title": "Übung 4",
    "section": "Aufgabe 4.2: T-Test ausführen",
    "text": "Aufgabe 4.2: T-Test ausführen\nStudienbeschrieb\nSie wollen untersuchen, ob sich die Beziehungsqualität von Paaren durch ein Kommunikationstraining beeinflussen lässt. Sie untersuchen daher zwei Gruppen mit insgesamt 60 Paaren. Eine Gruppe (30 Paare) erhält während zwei Monaten ein Kommunikationstraining (KT). Die andere Gruppe (30 Paare) erhält in diesen zwei Monaten ein Rechtschreibetraining (RS) mit gleicher Intensität. Nach zwei Monaten werden alle Paare zu zweit zu ihrer Beziehungsqualität befragt. Diese Befragung ergibt einen Wert für Beziehungsqualität pro Paar, also 30 Werte in der KT-Gruppe und 30 Werte in der RS-Gruppe. Das Signifikanzniveau wird auf \\(\\alpha=0.05\\) festgelegt.\nForschungsfrage: Besteht nach dem Training ein Unterschied in der Einschätzung der Beziehungsqualität zwischen den beiden Gruppen?\n\nBearbeiten Sie nun Schritt für Schritt folgende Aufgaben:\na. Muss gerichtet oder ungerichtet getestet werden? Wie lautet die \\(H_0\\) und die \\(H_1\\)?\nb. Welches Signifikanzniveau wurde festgelegt? Was bedeutet das?\nc. Laden Sie das Package {tidyverse}. Lesen Sie den Datensatz couples_quality.csv aus dem Ordner data ein und speichern Sie ihn in die Variable d_quality.\n\n___(tidyverse)\n\n___ &lt;- read.csv(\"___/___\")\nglimpse(___)\n\nd. Konvertieren Sie id zu einem Faktor, da Versuchspersonenidentifikationen ja keine numerischen Werte haben, sondern nominalskaliert sind (z.B. ist Versuchsperson 10 ja nicht doppelt so viel wie Versuchsperson 5). Der Datensatz sollte danach immer noch d_quality heissen.\n\nd_quality &lt;- d_quality |&gt;\n  mutate(id = ___(id))\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\nBeginnen Sie mit d_quality &lt;- d_quality |&gt;\nNutzen Sie die Funktion mutate() und as.factor().\nLesen Sie hier nach.\n\n\n\n\ne. Schauen Sie sich die Variablen und die Deskriptivstatistik an. Wie lauten die Mittelwerte und die Standardabweichungen der beiden Gruppen? Was fällt Ihnen auf?\nVorgehen:\n\nGruppieren Sie den Datensatz nach Bedingungen.\nBerechnen Sie den Mittelwert und die Standardabweichung\nErstellen Sie mit den obigen Schritten einen neue Variable namens d_quality_summary.\nSchauen Sie sich die Werte in d_quality_summary an.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\nBeginnen Sie mit d_quality_summary &lt;- ___. Fügen Sie den Namen des Datensatzes ein.\nFahren Sie dann mit der Pipe |&gt; weiter.\nVerwenden Sie group_by() zum Gruppieren. Als Argument muss hier die Gruppierungsvariable (UV) eingegeben werden.\nBerechnen Sie den Mittelwert und die Standardabweichung mit mean() und sd().\n\nFür eine Anleitung sehen Sie hier nach\n\n\n\n\n___ &lt;- ___ |&gt;\n  group_by(___) |&gt;\n  summarise(mean_quality = mean(___),\n            sd_quality = sd(___))\nd_quality_summary\n\nf. Welchen statistischen Test führen Sie durch?\ng. Überprüfen Sie die Voraussetzung der Varianzhomogenität für diesen Test. Was bedeutet das Ergebnis des Levene-Tests?\nDie Varianzhomogenität wird mit dem Levene-Test überprüft. Dafür kann das Package {car} verwendet werden.\n\ncar::___(___ ~ ___, # av ~ uv\n         data = ___) # dataset\n\nh. Führen Sie einen t-Test mit der Funktion t.test() durch. Wie lautet Ihre Testentscheidung?\n\n# t-Test für unabhängige Stichproben durchführen\nt.test(formula = ___ ~ ___, # av ~ uv\n       alternative = \"___\", # one.sided or two.sided\n       var.equal = TRUE,\n       data = ___) # dataset\n\ni. Berechnen Sie die Effektgrösse mit der Funktion cohen.d() aus dem Package {effsize}. Wie gross ist der Effekt nach Cohen (1998)?\n\n# Effektgrösse berechnen\n___::___(formula = ___ ~ ___, # av ~ uv\n         data = ___) # dataset\n\nj. Interpretation und Berichten\nSchreiben Sie 1-2 Sätze zu den Ergebnissen für einen wissenschaftlichen Artikel.\nHier finden Sie ein Beispiel.\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\n\n\nWeitere Möglichkeiten, um mit diesem Datensatz zu arbeiten:\n\nBerechnen Sie eine A-priori Poweranalyse. Hierfür darf der Datensatz nicht verwendet werden, da diese VOR der Datenerhebung durchgeführt werden muss.\nErstellen Sie einen Boxplot aus den Daten und überprüfen Sie visuell, ob sich die Gruppen und die Varianzen unterscheiden. Was fällt Ihnen auf?",
    "crumbs": [
      "Übungen",
      "Übung 4"
    ]
  },
  {
    "objectID": "uebungen/uebung-04.html#aufgabe-4.3-t-test-ausführen",
    "href": "uebungen/uebung-04.html#aufgabe-4.3-t-test-ausführen",
    "title": "Übung 4",
    "section": "Aufgabe 4.3: T-Test ausführen",
    "text": "Aufgabe 4.3: T-Test ausführen\nStudienbeschrieb\nSie fragen sich, ob das Sprichwort “Gegensätze ziehen sich an” bei romantischen Paaren zutrifft. Sie untersuchen daher, ob sich die Persönlichkeitsmerkmale von Partnern unterscheiden und haben dazu bei 250 Paaren das Persönlichkeitsmerkmals Extraversion erhoben. Die abhängige Variable Extraversion wurde jeweils bei beiden Partner mit dem gleichen Messinstrument erhoben. Das Signifikanzniveau wird auf \\(\\alpha=0.05\\) festgelegt.\n\nArtikel zum Studienbeispiel: Claxton et al. (2012)\n\nForschungsfrage: Unterscheiden sich das Persönlichkeitsmerkmal Extraversion signifikant zwischen Partnern?\nBearbeiten Sie nun Schritt für Schritt folgende Aufgaben:\na. Muss gerichtet oder ungerichtet getestet werden? Wie lautet die \\(H_0\\) und die \\(H_1\\)?\nb. Welches Signifikanzniveau wurde festgelegt? Was bedeutet das?\nc. Lesen Sie den Datensatz couples_extraversion.csv aus dem data Ordner ein und speichern Sie ihn in die Variable d_extraversion.\n\n___ &lt;- read.csv(\"___/___\")\nglimpse(___)\n\nd. Schauen Sie sich die Variablen und die Deskriptivstatistik an.\n\nIn welchem Format ist der Datensatz? Inwiefern unterscheidet er sich zu Aufgabe 4.2.?\nWie lauten die Mittelwerte und die Standardabweichungen der Variablen? Was fällt Ihnen auf?\n\n\nd_extraversion_summary &lt;- ___ |&gt;\n  summarise(mean_extra1 = mean(___), \n            sd_extra1 = sd(___),\n            mean_extra2 = ___(___), \n            sd_extra2 = ___(___))\nd_extraversion_summary\n\ne. Welchen statistischen Test führen Sie durch?\nf. Welche Voraussetzungen müssen für den Test erfüllt sein? Welche überprüfen wir?\ng. Führen Sie einen t-Test mit der Funktion t.test() durch. Wie lautet Ihre Testentscheidung?\n\n# t-Test für abhängige Stichproben durchführen\nt.test(d_extraversion$___, d_extraversion$___, #av1, av2\n       alternative = \"two.sided\",\n       paired = ___, # TRUE: abhängig, FALSE: unabhängig\n       data = ___) # Datensatz\n\nh. Berechnen Sie die Effektgrösse mit der Funktion cohen.d() aus dem Package {effsize}. Wie gross ist der Effekt nach Cohen (1998)?\n\n# Effektgrösse berechnen\n___::cohen.d(___$___, # av 1\n                 ___$___, # av 2\n                 paired = ___) #TRUE: abhängig, FALSE: unabhängig\n\ni. Interpretation und Berichten\nSchreiben Sie 1-2 Sätze zu den Ergebnissen für einen wissenschaftlichen Artikel.\nHier finden Sie ein Beispiel.\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\n\n\nWeitere Möglichkeiten, um mit diesem Datensatz zu arbeiten:\n\nBerechnen Sie eine A-priori Poweranalyse. Hierfür darf der Datensatz nicht verwendet werden, da diese VOR der Datenerhebung durchgeführt werden muss.\nErstellen Sie einen Boxplot aus den Daten und überprüfen Sie visuell, ob sich die Gruppen und die Varianzen unterscheiden. Nutzen Sie hierfür esquisse::esquisser() Was fällt Ihnen auf?",
    "crumbs": [
      "Übungen",
      "Übung 4"
    ]
  },
  {
    "objectID": "uebungen/uebung-04.html#aufgabe-4.4-zusatzaufgabe",
    "href": "uebungen/uebung-04.html#aufgabe-4.4-zusatzaufgabe",
    "title": "Übung 4",
    "section": "Aufgabe 4.4: Zusatzaufgabe",
    "text": "Aufgabe 4.4: Zusatzaufgabe\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\nDiskutieren Sie folgende Fragen:\n\nWie könnte das Design des Experiments der Aufgabe 4.2 verbessert werden?\n\nWelche Probleme könnten bei dem bestehenden Design auftreten? (z.B. das fälschlicherweise ein Effekt angenommen wird, obwohl keiner existiert?)\nWelche zusätzlichen Messzeitpunkte könnten aufschlussreiche Daten liefern?\nKönnten die Daten dieses verbesserten Designs mit einem unabhängigen oder abhängigen t-Tests analysiert werden?",
    "crumbs": [
      "Übungen",
      "Übung 4"
    ]
  },
  {
    "objectID": "uebungen/uebung-05.html",
    "href": "uebungen/uebung-05.html",
    "title": "Übung 5",
    "section": "",
    "text": "Aufgabe 5.0: Projektumgebung erstellen\nFalls obige Anforderungen noch nicht erfüllt:\na. Öffnen Sie das RProjekt anova.\nb. Erstellen Sie ein RNotebook namens uebung-05.",
    "crumbs": [
      "Übungen",
      "Übung 5"
    ]
  },
  {
    "objectID": "uebungen/uebung-05.html#aufgabe-5.0-projektumgebung-erstellen",
    "href": "uebungen/uebung-05.html#aufgabe-5.0-projektumgebung-erstellen",
    "title": "Übung 5",
    "section": "",
    "text": "Laden Sie den Projektordner herunter und entzippen Sie den Ordner.1\nInstallieren Sie die benötigten Packages (falls noch nicht geschehen) unter Tools &gt; Install Packages... oder in der Konsole mit\ninstall.packages(\"afex\")\ninstall.packages(\"emmeans\")\ninstall.packages(\"beeswarm\")\ninstall.packages(\"effectsize\")",
    "crumbs": [
      "Übungen",
      "Übung 5"
    ]
  },
  {
    "objectID": "uebungen/uebung-05.html#aufgabe-5.1-einstieg",
    "href": "uebungen/uebung-05.html#aufgabe-5.1-einstieg",
    "title": "Übung 5",
    "section": "Aufgabe 5.1: Einstieg",
    "text": "Aufgabe 5.1: Einstieg\n\nWelche \\(H_0\\) wird mit einer einfaktoriellen Varianzanalyse mit vier Bedingungen überprüft? Wie lautet die entsprechende \\(H_1\\) dazu?\nFormulieren Sie zwei Forschungsfragen, die mit einer einfaktoriellen Varianzanalyse ohne Messwiederholung untersucht werden können.",
    "crumbs": [
      "Übungen",
      "Übung 5"
    ]
  },
  {
    "objectID": "uebungen/uebung-05.html#aufgabe-5.2-einfaktorielle-varianzanalyse-ohne-messwiederholung",
    "href": "uebungen/uebung-05.html#aufgabe-5.2-einfaktorielle-varianzanalyse-ohne-messwiederholung",
    "title": "Übung 5",
    "section": "Aufgabe 5.2: Einfaktorielle Varianzanalyse ohne Messwiederholung",
    "text": "Aufgabe 5.2: Einfaktorielle Varianzanalyse ohne Messwiederholung\nBeschreibung der Studie\nIn diesem Musik-Experiment2 wurde die Hypothese untersucht, dass die Konzentrationsleistung von Personen unter dem Einfluss klassischer Instrumentalmusik (Bedingung 1) höher ist als unter dem Einfluss von Rockmusik (Bedingung 2), von Opernmusik (Bedingung 3) oder von Schlagermusik (Bedingung 4). Die Versuchspersonen wurden randomisiert einer der vier experimentellen Bedingungen zugeteilt und sollten sich entsprechende Musikstücke für ca. 15 Minuten anhören. Gleichzeitig sollten sie einen Konzentrationstest bearbeiten. Das Alphaniveau wurde auf \\(5 \\%\\) festgelegt.\nForschungsfrage: Besteht ein Unterschied in der Konzentrationsleistung zwischen mindestens zwei Gruppen?\nUnabhängige Variable: Art der Musik in vier Bedingungen (condition: Instrumental, Rock, Oper, Schlager)\nAbhängige Variable: Erreichte Punktzahl in einem Konzentrationstest (testscore) als Indikator für Konzentrationsleistung auf einer Skala von 0 - 35 möglichen Punkten.\n\nBearbeiten Sie nun Schritt für Schritt folgenden Aufgaben:\na. Wird eine gerichtete oder eine ungerichtete Hypothese überprüft? Wie lautet die \\(H_0\\) und die \\(H_1\\)?\nb. Welches Signifikanzniveau wurde festgelegt? Was bedeutet das?\nc. Laden Sie das {tidyverse}. Lesen Sie den Datensatz anova_music.csv aus dem Ordner data ein und speichern Sie ihn in die Variable d_music. Konvertieren Sie die Variablen id und condition zu einem Faktor.\n\n# tidyverse laden\n___(___)\n\n# Datensatz einlesen\n___ &lt;- ___(\"___/___.csv\")\n\n# Faktoren konvertieren\nd_music &lt;- ___ |&gt;\n  ___(id = ___(___)) |&gt;\n  ___(condition = ___(___))\n\nd. Schauen Sie sich den Datensatz genauer an, z.B. mit glimpse() und Hmisc::describe().\n\n# Daten anschauen mit glimpse()\n___(___)\n\n# Daten anschauen mit describe() aus Hmisc\n___::___(___)\n\n\nWie heissen die vier Bedingungen im Datensatz?\nWie viele Personen sind in welcher Bedingung?\nGibt es fehlende Werte (missings)?\nWie lauten die Mittelwerte und Standardabweichungen der Testscores in den vier Bedingungen? Fassen Sie hierzu die Daten mit group_by() und summarise() zusammen (eine Anleitung dazu finden Sie hier).\n\n\n# Gruppieren und zusammenfassen\nd_summary &lt;- ___ |&gt;\n  ___(___) |&gt;\n  ___(mean_testscore = ___(___),\n      sd_testscore = ___(___))\nd_summary\n\n\nWas wissen Sie nun bereits über die Daten?\n\ne. Welchen statistischen Test führen Sie durch und weshalb?\nf. Überprüfen Sie, ob die Voraussetzungen für die Anwendung eines F-Tests erfüllt sind.\nDie Varianzhomogenität wird mit dem Levene-Test überprüft. Dafür kann die Funktion leveneTest() aus dem Package {car} verwendet werden. Wir wählen das Signifikanzniveau von 5%. Wie fällt das Ergebnis des Levene-Tests aus?\n\n# Levene Test\n___::___(___ ~ ___, # av ~ uv\n         data = ___)\n\ng. Führen Sie nun eine einfaktorielle Varianzanalyse mit der Funktion aov_4() durch. Sie benötigen dazu das Package {afex}.\n\nBerechnen Sie eine einfaktorielle Varianzanalyse und speichern Sie das Modell als Objekt namens m_anova1.\nLassen Sie sich eine summary() und eine vollständige Anova-Tabelle mit ___$Anova ausgeben.\nWelche Werte in der Tabelle sind relevant? Suchen Sie die wichtigen Kennwerte heraus.\nWie lautet Ihre Testentscheidung?\n\n\n# afex laden\nlibrary(afex)\n\n# Einfaktorielle Anova \nm_anova1 &lt;- aov_4(___ ~ ___ + (1 | ___), # av ~ uv + (1 | Identifikationsvariable)\n                data = ___) # dataset\n\n# Resultate ausgeben\nsummary(___) \n___$Anova\n\nh. Visualisierung\nVerwendet Sie den folgenden Code, um die Mittelwerte und Standardfehler zu plotten. Stellen Sie Vermutungen an, welche Gruppen sich signifikant unterscheiden und welche nicht.\n\n# Plot\nplot_anova &lt;- afex_plot(object = ___, # Objekt mit Anovamodell\n          x = \"___\",  # uv (Faktor)\n          error_ci = FALSE) + # Anzeigen von Standardfehler der Mittelwerte\n    theme_minimal()\nplot_anova\n\ni. Effektstärke berechnen\nDie Effektgrösse \\(\\eta^2\\) lässt sich anhand des Quotienten aus der Zwischen-Quadratsumme und der Gesamtquadratsumme berechnen. In R kann dieses Mass direkt mit der Funktion eta_squared() aus dem Package {effectsize} ausgegeben werden. Als Argument für die Funktion muss das Anova-Modell (Objekt), also hier m_anova1, eingegeben werden.\n\n# Effektgrösse berechnen\n___::___(___)",
    "crumbs": [
      "Übungen",
      "Übung 5"
    ]
  },
  {
    "objectID": "uebungen/uebung-05.html#aufgabe-5.3-zusatzaufgabe",
    "href": "uebungen/uebung-05.html#aufgabe-5.3-zusatzaufgabe",
    "title": "Übung 5",
    "section": "Aufgabe 5.3: Zusatzaufgabe",
    "text": "Aufgabe 5.3: Zusatzaufgabe\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\n\nBerechnen Sie den F-Wert und den \\(\\eta^2\\)-Wert mithilfe der Quadratsummen aus dem Output selbst.\nErstellen Sie mit esquisse::esquisser() eine andere Grafik (z.B. Boxplot), welche die Testscores der vier Bedingungen in einer Grafik abbildet.",
    "crumbs": [
      "Übungen",
      "Übung 5"
    ]
  },
  {
    "objectID": "uebungen/uebung-05.html#footnotes",
    "href": "uebungen/uebung-05.html#footnotes",
    "title": "Übung 5",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden.↩︎\nEid, M., Gollwitzer, M., & Schmitt, M. (2017). Statistik und Forschungsmethoden: Mit Online-Materialien (5., korrigierte Auflage). Beltz. S. 459↩︎",
    "crumbs": [
      "Übungen",
      "Übung 5"
    ]
  },
  {
    "objectID": "uebungen/uebung-06.html",
    "href": "uebungen/uebung-06.html",
    "title": "Übung 6",
    "section": "",
    "text": "Aufgabe 6.0: Projektumgebung erstellen\nFalls obige Anforderungen noch nicht erfüllt:\na. Öffnen Sie das RProjekt anova.\nb. Erstellen Sie ein RNotebook namens uebung-06 oder arbeiten Sie bei uebung-05 weiter.",
    "crumbs": [
      "Übungen",
      "Übung 6"
    ]
  },
  {
    "objectID": "uebungen/uebung-06.html#aufgabe-6.0-projektumgebung-erstellen",
    "href": "uebungen/uebung-06.html#aufgabe-6.0-projektumgebung-erstellen",
    "title": "Übung 6",
    "section": "",
    "text": "Laden Sie den Projektordner herunter und entzippen Sie den Ordner.1\nInstallieren Sie die benötigten Packages (falls noch nicht geschehen) unter Tools &gt; Install Packages... oder in der Konsole mit\ninstall.packages(\"afex\")\ninstall.packages(\"emmeans\")\ninstall.packages(\"beeswarm\")\ninstall.packages(\"effectsize\")",
    "crumbs": [
      "Übungen",
      "Übung 6"
    ]
  },
  {
    "objectID": "uebungen/uebung-06.html#aufgabe-6.1-einstieg",
    "href": "uebungen/uebung-06.html#aufgabe-6.1-einstieg",
    "title": "Übung 6",
    "section": "Aufgabe 6.1: Einstieg",
    "text": "Aufgabe 6.1: Einstieg\na. Welche Vermutungen haben Sie bei Aufgabe 5.2.h? Welche Mittelwerte unterscheiden sich Ihrer Einschätzung nach bedeutsam?\nb. Wie viele paarweise Mittelwertsvergleiche durch t-Tests sind im Musikexperiment grundsätzlich möglich?\nc. Worin besteht das Problem des multiplen Testens?\n\n\n\n\n\n\nTipp\n\n\n\n\n\nBei einem Faktor mit vier Faktorstufen und einer Irrtumswahrscheinlichkeit von \\(\\alpha=0.05\\) pro Test ergibt sich folgende Berechnung für den \\(\\alpha\\)-Fehler aller \\(s\\) Paarvergleiche:\n\\(\\alpha_{fam} = 1 - (1 - \\alpha_r)^6 = 1 - 0.95^6 = 1 - 0.735 = 0.265\\)",
    "crumbs": [
      "Übungen",
      "Übung 6"
    ]
  },
  {
    "objectID": "uebungen/uebung-06.html#aufgabe-6.2-post-hoc-vergleiche",
    "href": "uebungen/uebung-06.html#aufgabe-6.2-post-hoc-vergleiche",
    "title": "Übung 6",
    "section": "Aufgabe 6.2: Post-hoc Vergleiche",
    "text": "Aufgabe 6.2: Post-hoc Vergleiche\na. Anova-Modell berechnen\n\nLesen Sie den Datensatz anova_music.csv ein und konvertieren Sie die Variable id und condition zu einem Faktor (siehe Übung 5). Schauen Sie sich den Datensatz kurz mit glimpse() an.\nBerechnen Sie das Anova-Modell m_anova1 (siehe Übung 5).\n\n\n# afex laden\nlibrary(afex)\n\nWarning: package 'afex' was built under R version 4.4.3\n\n# Einfaktorielle Anova \nm_anova1 &lt;- aov_4(testscore ~ condition + (1 | id), \n                data = d_music) \n\n# Resultate ausgeben\nsummary(m_anova1) \n\nAnova Table (Type 3 tests)\n\nResponse: testscore\n          num Df den Df    MSE      F     ges    Pr(&gt;F)    \ncondition      3     76 18.343 36.406 0.58967 1.083e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm_anova1$Anova\n\nAnova Table (Type III tests)\n\nResponse: dv\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 19406.5  1 1057.951 &lt; 2.2e-16 ***\ncondition    2003.4  3   36.406 1.083e-14 ***\nResiduals    1394.1 76                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nErstellen Sie mit der Funktion emmeans() aus dem Package {emmeans} ein Objekt, z.B. m_anova1_results. Darin werden die “Estimated Marginal Means” gespeichert.\n\n\n# Package emmeans laden\nlibrary(emmeans)\n\n# Resultate (estimated marginal means) speichern\nm_anova1_result &lt;- emmeans(object = ____, specs = ~ ____) # object = anova modell, ~ uv\nm_anova1_result\n\n\nLassen Sie sich mit der Funktion pairs(x = model, adjust = \"none\") zuerst alle Paarvergleiche ausgeben, ohne dass eine Korrektur vorgenommen wird. Zu Übungszwecken können Sie so die korrigierten Resultate mit den unkorrigierten vergleichen.\n\n\n# Post-hoc-Test ohne Adjustierung\npairs(x = m_anova1_result, adjust = \"none\") \n\nb. Überprüfen Sie mit dem Tukey-Test einen vollständigen Paarvergleich aller Bedingungen.\n\nWelche Voraussetzungen erfordert der Tukey-Test?\nWelchen Vorteil hat der Tukey-Test gegenüber der Bonferroni-Korrektur?\nWelche Prüfgrösse gibt der Tukey-Test in R aus?\nFühren Sie den Post-hoc-Vergleich für alle möglichen Mittelwertspaare mit adjust = \"tukey\" durch. Wie lautet Ihre Testentscheidung?\n\nc. Als eine weitere Möglichkeit wollen Sie a-priori (also vorher) festgelegte Hypothesen prüfen. Prüfen Sie mit der Bonferroni-Holm-Methode, welche Bedingungsmittelwerte sich signifikant unterscheiden.\n\nWie funktioniert die Bonferroni-Holm-Methode?\nWelchen Vorteil hat sie gegenüber der Bonferroni-Methode?\nFühren Sie den Post-hoc-Vergleich mit adjust = \"holm\" durch. Wie lautet Ihre Testentscheidung? Vergleichen Sie die \\(p\\)-Werte mit den unkorrigierten Werten.\nFalls ein unbalanciertes Design vorliegt, kann die Bonferroni-Holm-Methode nicht verwendet werden. Überprüfen Sie die Paarvergleiche daher zu Übungszwecken auch mit dem Scheffé-Test mit adjust = \"scheffe\". Was fällt Ihnen auf?",
    "crumbs": [
      "Übungen",
      "Übung 6"
    ]
  },
  {
    "objectID": "uebungen/uebung-06.html#aufgabe-6.3-kontrastanalysen",
    "href": "uebungen/uebung-06.html#aufgabe-6.3-kontrastanalysen",
    "title": "Übung 6",
    "section": "Aufgabe 6.3: Kontrastanalysen",
    "text": "Aufgabe 6.3: Kontrastanalysen\nSchauen Sie mit der Funktion levels() im Datensatz nach, in welcher Reihenfolge die Stufen des Faktors condition geordnet sind:\n\nlevels(d_music$condition)\n\nDies ist wichtig, um nun die Kontrasthypothesen richtig zu spezifizieren.\na. Für Kontrastanalysen muss zuerst spezifiziert werden, welcher Kontrast/welche Kontraste von Interesse sind. Definieren Sie die Kontraste für folgende Alternativhypothesen und benennen Sie den Kontrast. Wichtig: Ein Kontrast in dieser Aufgabe besteht aus einer Reihe von 4 Werten, die in der Summe 0 ergeben. Beachten Sie die obige Reihenfolge der Faktorstufen.\n\n“Die kognitive Leistung unter Opernmusik ist höher als die durchschnittliche kognitive Leistung in den drei anderen Bedingungen.”\n“Die kognitive Leistung unter Schlagermusik ist besser als unter Rockmusik.”\n“Die kognitive Leistung unter Schlagermusik ist schlechter als unter Rockmusik.”\n\nb. Sie wollen nun die Hypothese überprüfen, dass die Konzentrationsleistung von Personen unter dem Einfluss klassischer Instrumentalmusik (Bedingung 1) höher ist als unter dem Einfluss von Opernmusik (Bedingung 2), von Rockmusik (Bedingung 3) oder von Schlagermusik (Bedingung 4).\nÜberprüfen Sie mit Hilfe eines Kontrasts zuerst die (ungerichtete) Hypothese, dass sich die kognitive Leistung in der Instrumentalbedingung vom Durchschnitt der kognitiven Leistung in den drei anderen Musikbedingungen unterscheidet. Da wir jedoch die gerichtete Hypothese testen wollen, müssen wir im Anschluss noch den \\(p\\)-Wert halbieren.\n\n# Kontrastanalyse\n## H: Instrumental unterscheidet sich von anderen Bedingungen\nm_anova1_contrast1 &lt;- list(\"____ vs. ____\" = c(__, __, __, __)) # Kontrast definieren (Summe 0!)\ncontrast(object = _____, method = m_anova1_contrast1) # Anovamodell (emmeans)\n\nc. Überprüfen Sie nun eine weitere Hypothese, die besagt, dass sich moderne Pop- und Rocksongs von anderen Musikarten wie Instrumentalmusik und Oper in ihrem Effekt auf die kognitive Leistung unterscheiden (d.h. Instrumental & Oper versus Schlager & Rock).\nd. Was passiert, wenn man mehrere Kontraste mit den gleichen Daten berechnet?\n\n\n\n\n\n\nZusatz\n\n\n\n\n\nFolgendermassen können die sechs Paarvergleiche auch als einzelne Kontraste definiert und getestet werden.\n\n# Kontraste definieren\ncontrast_list &lt;- list(\"instrumental vs. oper\" = c(1, -1, 0, 0),\n                           \"instrumental vs. rock\" = c(1, 0, -1, 0),\n                           \"instrumental vs. schlager\" = c(1, 0, 0, -1),\n                           \"oper vs. rock\" = c(0, 1, -1, 0),\n                           \"oper vs. schlager\" = c(0, 1, 0, -1),\n                           \"rock vs. schlager\" = c(0, 0, 1, -1)) \n\n# Emmeans-Objekt mit definierten Kontrasten\nm_anova1_contrastlist &lt;- emmeans(m_anova1, ~ condition, contr = contrast_list)\n\n# Ergebnisse mit Korrekturmethoden ausgeben\nsummary(m_anova1_contrastlist$contrasts, adjust = \"holm\")        \n\n contrast                  estimate   SE df t.ratio p.value\n instrumental vs. oper         9.05 1.35 76   6.682  &lt;.0001\n instrumental vs. rock         7.70 1.35 76   5.685  &lt;.0001\n instrumental vs. schlager    13.95 1.35 76  10.300  &lt;.0001\n oper vs. rock                -1.35 1.35 76  -0.997  0.3220\n oper vs. schlager             4.90 1.35 76   3.618  0.0011\n rock vs. schlager             6.25 1.35 76   4.615  &lt;.0001\n\nP value adjustment: holm method for 6 tests",
    "crumbs": [
      "Übungen",
      "Übung 6"
    ]
  },
  {
    "objectID": "uebungen/uebung-06.html#zusatzaufgabe",
    "href": "uebungen/uebung-06.html#zusatzaufgabe",
    "title": "Übung 6",
    "section": "Zusatzaufgabe",
    "text": "Zusatzaufgabe\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\na. Verfassen Sie für einen wissenschaftlichen Artikel einen Text zu den Resultaten der Aufgabe 6.3.b.\nb. Erstellen Sie eine Grafik des Datensatzes d_music, der die durchschnittliche Leistung in allen vier Bedingungen miteinander vergleicht, mit condition und testscore auf den beiden Achsen. Hierfür eignet sich beispielsweise ein Boxplot oder ein Violinplot.",
    "crumbs": [
      "Übungen",
      "Übung 6"
    ]
  },
  {
    "objectID": "uebungen/uebung-06.html#footnotes",
    "href": "uebungen/uebung-06.html#footnotes",
    "title": "Übung 6",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden.↩︎",
    "crumbs": [
      "Übungen",
      "Übung 6"
    ]
  },
  {
    "objectID": "uebungen/uebung-07.html",
    "href": "uebungen/uebung-07.html",
    "title": "Übung 7",
    "section": "",
    "text": "Aufgabe 7.0: Projektumgebung erstellen\nFalls obige Anforderungen noch nicht erfüllt:\na. Öffnen Sie das RProjekt anova.\nb. Erstellen Sie ein RNotebook namens uebung-07.",
    "crumbs": [
      "Übungen",
      "Übung 7"
    ]
  },
  {
    "objectID": "uebungen/uebung-07.html#aufgabe-7.0-projektumgebung-erstellen",
    "href": "uebungen/uebung-07.html#aufgabe-7.0-projektumgebung-erstellen",
    "title": "Übung 7",
    "section": "",
    "text": "Laden Sie den Datensatz anova_confidence.csv herunter und speichern Sie ihn im RProjekt anova im Ordner data ab.\nInstallieren Sie die benötigten Packages (falls noch nicht geschehen) unter Tools &gt; Install Packages... oder in der Konsole mit\ninstall.packages(\"afex\")\ninstall.packages(\"emmeans\")\ninstall.packages(\"effectsize\")",
    "crumbs": [
      "Übungen",
      "Übung 7"
    ]
  },
  {
    "objectID": "uebungen/uebung-07.html#aufgabe-7.1-einstieg",
    "href": "uebungen/uebung-07.html#aufgabe-7.1-einstieg",
    "title": "Übung 7",
    "section": "Aufgabe 7.1: Einstieg",
    "text": "Aufgabe 7.1: Einstieg\na. Wie unterscheidet sich eine einfaktorielle von einer zweifaktoriellen Varianzanalyse ohne Messwiederholung?\nb. In welche vier Komponenten lässt sich ein Zellmittelwert \\(\\overline{x}_{jk}\\) bei einer zweifaktoriellen Varianzanalyse zerlegen?\nc. Welche unterschiedlichen Kombinationen aus Haupt- und Interaktionseffekten gibt es in einem einfachen 2×2-Design?",
    "crumbs": [
      "Übungen",
      "Übung 7"
    ]
  },
  {
    "objectID": "uebungen/uebung-07.html#aufgabe-7.2-zweifaktorielle-varianzanalyse",
    "href": "uebungen/uebung-07.html#aufgabe-7.2-zweifaktorielle-varianzanalyse",
    "title": "Übung 7",
    "section": "Aufgabe 7.2: Zweifaktorielle Varianzanalyse",
    "text": "Aufgabe 7.2: Zweifaktorielle Varianzanalyse\n\n\n\n\n\n\nDatensatz anova_confidence.csv\n\n\n\n\n\nBeschreibung der Studie\nIn der (fiktiven) Studie wurde der Einfluss eines evidenzbasierten Trainings (treatment) und der Belohnung des Verhaltens (reward) auf das Selbstvertrauen (confidence) untersucht. Die Personen wurden ins Verhaltenslabor eingeladen, erhielten entweder das Training oder “warteten”. Zusätzlich wurden die Hälfte der Personen bei gewissem Verhalten (z.B. Blickkontakt) belohnt mit einem mündlichen Lob und die andere Hälfte nicht.\nDie Personen wurden den Bedingungskombinationen zufällig (randomisiert) zugewiesen, um systematische Störeinflüsse zu minimieren.\nUnabhängige Variable A: Art des Trainings (treatment): evidenzbasiertes Training (training) oder Wartekontrollgruppe (control)\nUnabhängige Variable B: Art der Belohnung (reward): Belohnung (yes) oder keine Belohnung (no)\nAbhängige Variable: Höhe des Selbstvertrauens (confidence) auf einer Skala von 0 - 100 möglichen Punkten (Fragebogen)\nForschungsfragen:\n\nHängt das Selbstvertrauen davon ab, ob die Versuchspersonen das Training absolviert haben?\nHängt das Selbstvertrauen davon ab, ob während des Laboraufenthalts (z.B. Blickkontakt) belohnt wurde oder nicht?\nIst der Unterschied zwischen Training oder Kontrollbedingung im Selbstvertrauen grösser, je nach dem ob das Verhalten belohnt wurde oder nicht?\n\nDie Effekte sollen auf einem Signifikanzniveau von \\(\\alpha = 0.05\\) geprüft werden.\n\n\n\n\na. Lesen Sie den Datensatz anova_confidence.csv aus dem data-Ordner ein und konvertieren Sie die Variablen id, treatment und reward zu Faktoren. Schauen Sie sich den Datensatz mit glimpse() an.\n\n# tidyverse laden\n\n# Datensatz einlesen\n\n# Faktoren konvertieren\n\n# Datensatz anschauen\n\nb. Schauen Sie sich den Datensatz genauer an.\n\nWie viele Stufen hat Faktor A (treatment)? Wie viele Stufen hat Faktor B (reward)?\nWie viele Personen wurden pro Gruppe untersucht?\nWie lauten die Mittelwerte und Standardabweichungen der abhängigen Variable confidence in den Gruppen? Tipp: Verwenden Sie die Funktionen group_by() und summarise(). Bei group_by() müssen beide Faktoren angegeben werden.\n\n\n# Mittelwerte und Standardabweichungen berechnen\n\nc. Laden die das Package {afex} und berechnen Sie das Anova-Modell m_anova2 mit zwei Faktoren.\n\nGibt es einen signifikanten Haupteffekt A für treatment und was bedeutet das?\nGibt es einen signifikanten Haupteffekt B für reward und was bedeutet das?\nGibt es einen signifikanten Interaktionseffekt AxB für treatment * reward und was bedeutet das?\n\n\n# afex laden\n\n# Zweifaktorielle Anova ohne Messwiederholung\nm_anova2 &lt;- aov_4(___ ~ ___ * ___ + (1 | id), # av ~ uv1 * uv2 + (1 | id)\n                  data = ___) # Datensatz\n\n# Resultate ausgeben\n___\n___\n\nd. Berechnen Sie den Gesamteffekt mit der Funktion summary(lm(av ~ uv1 * uv2, data = my_data)).\n\nIst der Gesamteffekt signifikant? Was bedeutet das?\n\n\n# Gesamteffekt\nsummary(lm(___ ~ ___ * ___, # av ~ uv1 * uv2\n           data = ___)) # Datensatz\n\ne. Laden Sie das Package {emmeans}. Berechnen Sie die bedingten Haupteffekte für Faktor B (reward) für die beiden Faktorstufen des Faktors A (treatment) mit der Funktion joint_tests() aus dem Package {emmeans}. Wie können diese interpretiert werden?\n\n# emmeans laden\n___\n\n# Bedingte Haupteffekte Faktor B\n___(___, # Funktion, Modell\n            by = \"___\") # für Faktorstufen a1/a2\n\nf. Laden Sie das Package {effectsize}. Berechnen Sie die Effektstärken \\(\\eta^2_p\\) für alle Effekte.\n\n# effectsize laden\n___\n\n# Effektstärke partielles Etaquadrat berechnen\n___(___, # Funktion, Modell\n    partial = TRUE)",
    "crumbs": [
      "Übungen",
      "Übung 7"
    ]
  },
  {
    "objectID": "uebungen/uebung-07.html#aufgabe-7.3-interaktionen",
    "href": "uebungen/uebung-07.html#aufgabe-7.3-interaktionen",
    "title": "Übung 7",
    "section": "Aufgabe 7.3: Interaktionen",
    "text": "Aufgabe 7.3: Interaktionen\na. Zeichnen Sie den Interaktionseffekt mit den Mittelwerten der vier Bedingungen aus Aufgabe 7.2 von Hand auf.\n\nWie sieht die Interaktion aus und um welche Form könnte es sich handeln?\n\nb. Stellen Sie die Ergebnisse auch in R mit Hilfe von afex_plot() dar.\n\nWie interpretieren Sie die Kombination des Haupteffekts und des Interaktionseffekts?\n\n\nafex_plot(object = m_anova2,\n          x = \"___\", # uv1\n          trace = \"___\", # uv2\n          mapping = c(\"color\", \"shape\"),\n          error_ci = FALSE,\n          legend_title = \"___\") + # Legende für uv2 \n  theme_minimal()",
    "crumbs": [
      "Übungen",
      "Übung 7"
    ]
  },
  {
    "objectID": "uebungen/uebung-07.html#zusatzaufgabe",
    "href": "uebungen/uebung-07.html#zusatzaufgabe",
    "title": "Übung 7",
    "section": "Zusatzaufgabe",
    "text": "Zusatzaufgabe\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\na. Verfassen Sie für einen wissenschaftlichen Artikel einen Text zu den Ergebnissen der Aufgabe 7.2.\nb. Welche Forschungsfrage würden Sie gerne mit einer zweifaktoriellen Varianzanalyse beantworten? Diskutieren Sie anhand dieser Frage: Was sind Vor- und Nachteile dieser Analysemethode?",
    "crumbs": [
      "Übungen",
      "Übung 7"
    ]
  },
  {
    "objectID": "uebungen/uebung-08.html",
    "href": "uebungen/uebung-08.html",
    "title": "Übung 8",
    "section": "",
    "text": "Aufgabe 8.0: Projektumgebung erstellen\nFalls obige Anforderungen noch nicht erfüllt:\na. Öffnen Sie das RProjekt anova.\nb. Erstellen Sie ein RNotebook namens uebung-08.",
    "crumbs": [
      "Übungen",
      "Übung 8"
    ]
  },
  {
    "objectID": "uebungen/uebung-08.html#aufgabe-8.0-projektumgebung-erstellen",
    "href": "uebungen/uebung-08.html#aufgabe-8.0-projektumgebung-erstellen",
    "title": "Übung 8",
    "section": "",
    "text": "Laden Sie den Datensatz anova_confidence2.csv herunter und speichern Sie ihn im RProjekt anova im Ordner data ab.\nInstallieren Sie die benötigten Packages (falls noch nicht geschehen) unter Tools &gt; Install Packages... oder in der Konsole mit\ninstall.packages(\"afex\")\ninstall.packages(\"emmeans\")\ninstall.packages(\"effectsize\")",
    "crumbs": [
      "Übungen",
      "Übung 8"
    ]
  },
  {
    "objectID": "uebungen/uebung-08.html#aufgabe-8.1-einstieg",
    "href": "uebungen/uebung-08.html#aufgabe-8.1-einstieg",
    "title": "Übung 8",
    "section": "Aufgabe 8.1: Einstieg",
    "text": "Aufgabe 8.1: Einstieg\na. Wie unterscheidet sich eine einfaktorielle Varianzanalyse mit und ohne Messwiederholung bezüglich der Quadratsummenzerlegung?\nb. Formulieren Sie die Null- und Alternativhypothese einer einfaktoriellen Varianzanalyse bei \\(J = 3\\) Faktorstufen mit Messwiederholung.\nc. Was besagt die Sphärizitätsannahme?\nd. Was versteht man unter der Intraklassen-Korrelation bei der einfaktoriellen Varianzanalyse mit Messwiederholung? In welchem Bereich können die Werte liegen?",
    "crumbs": [
      "Übungen",
      "Übung 8"
    ]
  },
  {
    "objectID": "uebungen/uebung-08.html#aufgabe-8.2-einfaktorielle-varianzanalyse-mit-messwiederholung",
    "href": "uebungen/uebung-08.html#aufgabe-8.2-einfaktorielle-varianzanalyse-mit-messwiederholung",
    "title": "Übung 8",
    "section": "Aufgabe 8.2: Einfaktorielle Varianzanalyse mit Messwiederholung",
    "text": "Aufgabe 8.2: Einfaktorielle Varianzanalyse mit Messwiederholung\n\n\n\n\n\n\nDatensatz anova_confidence2.csv\n\n\n\n\n\nBeschreibung der Studie\nIn der (fiktiven) Studie wurde der Einfluss von Feedback während eines evidenzbasierten Trainings auf das Selbstvertrauen (confidence) bei Jugendlichen untersucht. Die Versuchspersonen absolvierten dabei drei verschiedene Durchgänge (condition). Sie erhielten zuerst ein positives Feedback, dann ein negatives Feedback und beim dritten Durchgang ein neutrales Feedback. Es wurden fünf Jugendliche untersucht. Nach jedem Durchgang wurde die Höhe des Selbstvertrauens mit einem Fragebogen gemessen.\nUnabhängige Variable: Aufeinanderfolgende Bedingungen mit unterschiedlichem Feedback (condition: positive, negative, neutral)\nAbhängige Variable: Höhe des Selbstvertrauens (confidence) auf einer Skala von 0 - 100 möglichen Punkten (Fragebogen)\nForschungsfrage: Beeinflusst die Art des Feedbacks während des Trainings das Selbstvertrauen?\nDie Hypothese soll auf einem Signifikanzniveau von \\(\\alpha = 0.05\\) geprüft werden.\n\n\n\n\na. Lesen Sie den Datensatz anova_confidence2.csv aus dem data-Ordner ein und konvertieren Sie die Variablen idund condition zu Faktoren. Schauen Sie sich den Datensatz mit glimpse() an.\n\n# tidyverse laden\n\n# Datensatz einlesen\nd_anova1rm &lt;- ___\n\n# Faktoren konvertieren\n\n# Datensatz anschauen\n\nb. Schauen Sie sich den Datensatz zum Beispiel mit print() genauer an.\n\nWie viele Stufen hat der Faktor (condition) und wie heissen die Faktorstufen?\nWie viele Messwerte gibt es insgesamt?\nWie lauten die Mittelwerte und Standardabweichungen der abhängigen Variable confidence in den einzelnen Bedingungen?\n\n\n# Mittelwerte und Standardabweichungen berechnen\n\nc. Laden die das Package {afex} und berechnen Sie das Anova-Modell m_anova1rm mit Messwiederholung auf dem Faktor condition.\n\nPrüfen Sie die Voraussetzung der Sphärizität. Welche Nullhypothese wird mit dem Mauchly-Test geprüft? Muss die Nullhypothese abgelehnt werden?\nMuss eine Korrektur vorgenommen werden oder nicht? Welche?\nInterpretieren Sie das entsprechende Anova-Modell. Gibt es einen Effekt für condition und was bedeutet das?\n\n\n\n\n\n\n\nTipp \\(\\varepsilon_{GG}\\)\n\n\n\n\n\nBeachten Sie, dass das \\(\\varepsilon_{GG}\\) ein Mass dafür ist, inwiefern die Sphärizität verletzt ist. Ein Wert von 1 bedeutet keine Abweichung von der Sphärizität (alle Varianzen der Bedingungsunterschiede sind gleich). Ein Verstoss gegen die Sphärizität führt zu einem \\(\\varepsilon_{GG}\\) unter 1. Je weiter Epsilon von 1 entfernt ist, desto schlimmer ist der Verstoss.\nDer Mauchly-Test sollte nicht signifikant sein, wenn wir annehmen, dass die Annahme der Sphärizität erfüllt ist.\n\n\n\n\n# afex laden\n___\n\n# Zweifaktorielle Anova ohne Messwiederholung\nm_anova1rm &lt;- aov_4(___ ~ 1 + (___ | id), # av ~ 1 + (uv | id)\n                      data = ___) # Datensatz\n\n# Resultate ausgeben\nsummary(___)\n\nd. Bei nur 5 Versuchspersonen hat der Mauchly-Test mit einem Signifikanzniveau von \\(\\alpha=0.05\\) eine sehr geringe Power und ist daher zu streng. Das bedeutet, dass die Wahrscheinlichkeit die Nullhypothese selbst bei grossen Abweichungen von der sphärischen Matrix abzulehnen, sehr gering ist. Wenn wir ein weniger strenges \\(\\alpha\\)-Niveau festlegen, ist die Teststärke grösser. Überprüfen Sie daher die Sphärizität für dieses Beispiel auf dem weniger strengen \\(\\alpha=0.1\\)-Niveau.\n\nMuss eine Korrektur vorgenommen werden oder nicht? Welche?\nInterpretieren Sie das entsprechende Anova-Modell. Gibt es einen Effekt für condition und was bedeutet das?\n\ne. Berechnen Sie einen vollständigen Paarvergleich mit dem entsprechenden Post-hoc Test.\n\nWelchen Test (bzw. welche Korrektur) wählen Sie und warum?\nWelche Mittelwertsvergleiche sind auf dem (adjustierten) \\(\\alpha=0.05\\)-Niveau signifikant?\n\n\n# Emmeans laden\nlibrary(___)\n\n# Resultate in Objekt speichern\nresult_anova1_rm &lt;- ___\nresult_anova1_rm\n\n# Post-hoc Test\npairs(x = ___, adjust = \"___\")",
    "crumbs": [
      "Übungen",
      "Übung 8"
    ]
  },
  {
    "objectID": "uebungen/uebung-08.html#aufgabe-8.3-ergebnisse-darstellen",
    "href": "uebungen/uebung-08.html#aufgabe-8.3-ergebnisse-darstellen",
    "title": "Übung 8",
    "section": "Aufgabe 8.3: Ergebnisse darstellen",
    "text": "Aufgabe 8.3: Ergebnisse darstellen\na. Nutzen Sie den untenstehenden Code, um die Ergebnisse in R mit Hilfe von afex_plot() grafisch darzustellen. Ersetzen Sie dazu die vier Platzhalter ___.\n\n# Plot mit afex_plot\nplot_anova &lt;- afex_plot(object = ___, # Anova-Modell\n                        x = \"___\", error = \"within\") +\n  geom_line(aes(group = \"id\"), alpha = 0.3) +  \n  geom_point(aes(group = \"id\"), size = 2) +  \n  theme_minimal() +\n  labs(title = \"Unterschiede Selbstvertrauen über Bedingungen\", \n       y = \"___\", # y-Achse mit AV anschreiben\n       x = \"___\" # x-Achse mit UV anschreiben\n  )\n\nplot_anova\n\n\nb. Erstellen Sie anhand des Outputs aus 8.2.c. eine Anova-Tabelle.\n\n\n\n\n\n\n\n\n\n\n\n\nQuelle der Variation\nQS\ndf\nMQS\nF\np\n\\(\\eta^2_p\\)\n\n\n\n\nFaktor A\n\n\n\n\n\n\n\n\nPerson\n\n\n\n\n\n\n\n\nResiduum\n\n\n\n\n\n\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\n\nc. Ergänzen Sie den folgenden Ergebnisbericht für einen Artikel mit Ihren Resultaten.\n\nDie einfaktorielle Varianzanalyse mit Messwiederholung zeigte, dass es einen signifikantennicht signifikanten Effekt von SelbstvertrauenFeedbackBedingungen auf SelbstvertrauenFeedbackBedingungen gab, F(2, 12)F(4)F(2, 8) = 24.13, p &lt; .001= .006= .067, \\(\\eta^2\\) =, 0.860.64.\nDer Mauchly-Test war signifikantnicht signifikant, \\(W\\) = .16, p &lt; .001= .006= .067, womit Sphärizität angenommen werden kann.\nPost-hoc-Tests mit Tukey-Korrektur ergaben, dass das Selbstvertrauen in der Bedingung negatives Feedbackpositives Feedbackneutrales Feedback (M = 58.00, SD = 11.36) signifikant niedrigergleichhöher war, als in der Bedingung negatives Feedbackpositives Feedbackneutrales Feedback (M = 24.00, SD = 12.00), p &lt; .001), und in der Bedingung negatives Feedbackpositives Feedbackneutrales Feedback (M = 38.00, SD = 11.40), p = .0495.\nDie Ergebnisse deuten darauf hin, dass positives Feedback im Vergleich zu negativem und neutralem Feedback keineneinen positiveneinen negativen Effekt auf das Selbstvertrauen von Jugendlichen hat.",
    "crumbs": [
      "Übungen",
      "Übung 8"
    ]
  },
  {
    "objectID": "uebungen/uebung-08.html#zusatzaufgabe",
    "href": "uebungen/uebung-08.html#zusatzaufgabe",
    "title": "Übung 8",
    "section": "Zusatzaufgabe",
    "text": "Zusatzaufgabe\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\na. Erklären Sie die Varianzanalyse in eigenen Worten einer Person, die nicht Psychologie studiert.\nb. Suchen Sie über eine Datenbank nach einem Paper, welches eine Anova als Analysemethode verwendet. Welche Faktoren und Faktorstufen wurden verwendet? Was war die AV? Wie werden die Resultate berichtet und dargestellt?",
    "crumbs": [
      "Übungen",
      "Übung 8"
    ]
  },
  {
    "objectID": "uebungen/uebung-09.html",
    "href": "uebungen/uebung-09.html",
    "title": "Übung 9",
    "section": "",
    "text": "Aufgabe 9.1: Outputs interpretieren 1\nBeantworten Sie die Fragen zum folgenden R-Output.\ncar::leveneTest(speed ~ condition, \n                data = dataset_speed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)  \ngroup  2  6.4558 0.01249 *\n      12                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nm_anova_speed &lt;- aov_4(speed ~ condition + (1 | id), \n                data = dataset_speed) \n\nsummary(m_anova_speed) \n\nAnova Table (Type 3 tests)\n\nResponse: speed\n          num Df den Df    MSE      F      ges Pr(&gt;F)\ncondition      2     12 7.5673 0.1798 0.029096 0.8376",
    "crumbs": [
      "Übungen",
      "Übung 9"
    ]
  },
  {
    "objectID": "uebungen/uebung-09.html#aufgabe-9.1-outputs-interpretieren-1",
    "href": "uebungen/uebung-09.html#aufgabe-9.1-outputs-interpretieren-1",
    "title": "Übung 9",
    "section": "",
    "text": "Welche Analyse wurde hier durchgeführt?\nFalls Voraussetzungen überprüft werden (müssen), sind die Annahmen verletzt?\nWelche Variablen bzw. Faktoren wurden analysiert? Wieviel Faktorstufen gibt es pro Faktor?\nWelche Hypothese(n) kann/können mit dieser Analyse überprüft werden?\nWelche Effekte sind auf dem \\(\\alpha = 0.1\\) Niveau signifikant?\nWie werden die Resultate interpretiert (empirische Prüfgrösse, p-Wert, Testentscheidung)?",
    "crumbs": [
      "Übungen",
      "Übung 9"
    ]
  },
  {
    "objectID": "uebungen/uebung-09.html#aufgabe-9.2-outputs-interpretieren-2",
    "href": "uebungen/uebung-09.html#aufgabe-9.2-outputs-interpretieren-2",
    "title": "Übung 9",
    "section": "Aufgabe 9.2: Outputs interpretieren 2",
    "text": "Aufgabe 9.2: Outputs interpretieren 2\na. Schauen Sie sich die folgenden Datensätze dataset_learn und dataset_learn_new an.\n\nWelches Skalenniveau haben die jeweiligen Variablen?\nWie unterscheiden sich die Datensätze in ihrem Format?\nWelchen der beiden Datensätze können Sie für eine Varianzanalyse mit der Funktion aov_4() verwenden?\nInwiefern ist das Format des Datensatzes wichtig für die Berechnung von Mittelwert und Standardabweichung in R?\n\n\nprint(dataset_learn)\n\n# A tibble: 8 × 5\n  id      t1_beginn t2_threemonths t3_sixmonths t4_ninemonths\n  &lt;fct&gt;       &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1 sub-001        18             15           15            12\n2 sub-002        15             16           14            11\n3 sub-003        17             16           17            10\n4 sub-004        16             14           15            15\n5 sub-005        16             19           17            18\n6 sub-006        19             14           15            10\n7 sub-007        15             12           13            12\n8 sub-008        14             15           13             1\n\nprint(dataset_learn_new)\n\n# A tibble: 32 × 3\n   id      condition      examscore\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;\n 1 sub-001 t1_beginn             18\n 2 sub-002 t1_beginn             15\n 3 sub-003 t1_beginn             17\n 4 sub-004 t1_beginn             16\n 5 sub-005 t1_beginn             16\n 6 sub-006 t1_beginn             19\n 7 sub-007 t1_beginn             15\n 8 sub-008 t1_beginn             14\n 9 sub-001 t2_threemonths        15\n10 sub-002 t2_threemonths        16\n# ℹ 22 more rows\n\n\n\nb. Beantworten Sie die Fragen zum folgenden R-Output.\n\nWelche Analyse wurde hier durchgeführt?\nFalls Voraussetzungen überprüft werden (müssen), ist die Annahme verletzt?\nWelche Variablen bzw. Faktoren wurden analysiert? Wieviel Faktorstufen gibt es pro Faktor?\nWelche Hypothese(n) kann/können mit dieser Analyse überprüft werden?\nWelche Effekte sind auf dem \\(\\alpha = 0.05\\) Niveau signifikant?\nWie werden die Resultate interpretiert (empirische Prüfgrösse, p-Wert, Testentscheidung, Interaktion)?\n\n\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n            Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept) 6583.8      1   104.47      7 441.1508 1.395e-07 ***\ncondition    119.1      3   129.66     21   6.4297  0.002926 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n          Test statistic  p-value\ncondition       0.077568 0.013356\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n           GG eps Pr(&gt;F[GG])  \ncondition 0.50243    0.01985 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n             HF eps Pr(&gt;F[HF])\ncondition 0.6104115 0.01300484",
    "crumbs": [
      "Übungen",
      "Übung 9"
    ]
  },
  {
    "objectID": "uebungen/uebung-09.html#aufgabe-9.3-outputs-interpretieren-3",
    "href": "uebungen/uebung-09.html#aufgabe-9.3-outputs-interpretieren-3",
    "title": "Übung 9",
    "section": "Aufgabe 9.3: Outputs interpretieren 3",
    "text": "Aufgabe 9.3: Outputs interpretieren 3\na. Beantworten Sie die Fragen zum folgenden R-Output.\n\nWelche Analyse wurde hier durchgeführt?\nWelche Variablen bzw. Faktoren wurden analysiert? Wieviel Faktorstufen gibt es pro Faktor?\nWelche Hypothese(n) kann/können mit dieser Analyse überprüft werden?\nWelche Effekte sind auf dem \\(\\alpha = 0.05\\) Niveau signifikant?\nWie werden die Resultate interpretiert (empirische Prüfgrösse, p-Wert, Testentscheidung, Interaktion)?\n\n\n\n# A tibble: 4 × 4\n# Groups:   team [2]\n  team  payment mean_motivation sd_motivation\n  &lt;fct&gt; &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n1 team1 high                 80          10  \n2 team1 low                  40          10  \n3 team2 high                 36          19.7\n4 team2 low                  30          11  \n\n\nAnova Table (Type 3 tests)\n\nResponse: motivation\n             num Df den Df    MSE       F     ges   Pr(&gt;F)   \nteam              1      8 177.25 12.3385 0.60666 0.007931 **\npayment           1      8 177.25  8.9535 0.52812 0.017275 * \nteam:payment      1      8 177.25  4.8914 0.37943 0.057932 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nb. Gibt es einen bedingten Haupteffekt für Faktor A (team)? Wie wird er interpretiert?\n\n\npayment = high:\n model term df1 df2 F.ratio p.value\n team         1   8  16.384  0.0037\n\npayment = low:\n model term df1 df2 F.ratio p.value\n team         1   8   0.846  0.3845\n\n\n\nc. Effektgrössen\n\nWie gross ist das \\(\\eta^2_p\\) für den signifikanten Haupteffekte des Faktors team?\n\n\n\n# Effect Size for ANOVA (Type III)\n\nParameter    | Eta2 (partial) |       95% CI\n--------------------------------------------\nteam         |           0.61 | [0.17, 1.00]\npayment      |           0.53 | [0.09, 1.00]\nteam:payment |           0.38 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\nWelche weitere Möglichkeit gibt es, um das Package {effectsize} zu verwenden, ohne es mit der Funktion library() zu laden?",
    "crumbs": [
      "Übungen",
      "Übung 9"
    ]
  },
  {
    "objectID": "uebungen/uebung-09.html#aufgabe-9.4-kontraste",
    "href": "uebungen/uebung-09.html#aufgabe-9.4-kontraste",
    "title": "Übung 9",
    "section": "Aufgabe 9.4: Kontraste",
    "text": "Aufgabe 9.4: Kontraste\na. Für den Datensatz dataset_learn_new wurde eine Kontrastanalyse gerechnet, um zu überprüfen, ob sich der Messzeitpunkt 1 vom Mittel der anderen Messzeitpunkten unterscheidet.\n\nWie lautet die Testentscheidung?\n\n\n\n contrast    estimate   SE df t.ratio p.value\n t1 vs. rest     7.62 2.56  7   2.975  0.0207\n\n\n\nb. Im unteren Beispiel wurde der geplante Kontrast falsch spezifiziert. Wie müsste er korrekt spezifiziert sein?\n\nm_learn_contrast &lt;- list(\"t1 vs. rest\" = c(1, -1, -1, -1)) \ncontrast(object = m_learn_results, method = m_learn_contrast)\n\n contrast    estimate   SE df t.ratio p.value\n t1 vs. rest    -24.9 2.37  7 -10.490  &lt;.0001\n\n\n\nc. Im Datensatz dataset_learn_new wurden Daten von Personen zu vier Messzeitpunkte erhoben. Eine Forscherin interessiert sich jedoch nur für den ersten und zweiten Messzeitpunkt der Studie und analysiert die Unterschiede der beiden Messzeitpunkte mit einem t-Test für abhängige Stichproben. Ein anderer Forscher verwendet die selben Daten und untersucht Messzeitpunkt 1 und 4 - ebenfalls mit einem t-Test für abhängige Stichproben.\n\nWelches Problem entsteht dadurch bzw. weshalb ist dies nicht zulässig?\nWie würden Sie die Hypothese testen, dass sich zwei Messzeitpunkte unterscheiden?\n\n\nd. Nun möchte die Forscherin wissen, ob die Versuchspersonen zum letzten Messzeitpunkt signifikant höhere Testwerte hatten als zum ersten Messzeitpunkt und überprüft die gerichtete Alternativhypothese \\(\\mu_1 &lt; \\mu_4\\) (entspricht auch \\(\\mu_4 - \\mu_1 &gt; 0\\)).\n\nWie lautet die Testentscheidung?\n\n\nd_summary_learn\n\n# A tibble: 4 × 3\n  condition      mean_examscore sd_examscore\n  &lt;fct&gt;                   &lt;dbl&gt;        &lt;dbl&gt;\n1 t1_beginn                16.2         1.67\n2 t2_threemonths           15.1         2.03\n3 t3_sixmonths             14.9         1.55\n4 t4_ninemonths            11.1         4.91\n\nm_learn_contrast &lt;- list(\"t1 &lt; t4\" = c(-1, 0, 0, 1)) \ncontrast(object = m_learn_results, method = m_learn_contrast)\n\n contrast estimate   SE df t.ratio p.value\n t1 &lt; t4     -5.12 1.66  7  -3.082  0.0178",
    "crumbs": [
      "Übungen",
      "Übung 9"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html",
    "href": "uebungen/uebung-10.html",
    "title": "Übung 10",
    "section": "",
    "text": "Aufgabe 10.1: Voraussetzungen und deren Überprüfung\na. Welche Voraussetzungen müssen für die einfache lineare Regression gegeben sein?\nb. Schauen Sie sich untenstehende Punktdiagramme (scatterplots) an. Bei welchen Daten würden Sie eine lineare Regression berechnen, bei welchen eher nicht? (Hinweis: Nicht alle Beispiele sind eindeutig.)",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html#aufgabe-10.1-voraussetzungen-und-deren-überprüfung",
    "href": "uebungen/uebung-10.html#aufgabe-10.1-voraussetzungen-und-deren-überprüfung",
    "title": "Übung 10",
    "section": "",
    "text": "Scatterplots verschiedener Datensets",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html#aufgabe-10.2-komponenten-der-regressionsgleichung",
    "href": "uebungen/uebung-10.html#aufgabe-10.2-komponenten-der-regressionsgleichung",
    "title": "Übung 10",
    "section": "Aufgabe 10.2: Komponenten der Regressionsgleichung",
    "text": "Aufgabe 10.2: Komponenten der Regressionsgleichung\na. Wie lautet die Bestimmungsgleichung der Regressionsgeraden in der einfachen linearen Regressionsanalyse? Schreiben Sie die Gleichung auf und ordnen Sie die untenstehenden Begriffe den Termen in der Gleichung zu:\n\nAchsenabschnitt (intercept)\nRegressionsgewicht bzw. die Steigung (slope) der Regressionsgeraden\nVorhersagefehler\nAV\n\nb. Wie lautet die Bestimmungsgleichung für \\(b_0\\) für unstandardisierte Variablen?\nc. Wie lautet die Bestimmungsgleichung für \\(b_1\\) für unstandardisierte Variablen?\nd. Welchen konstanten Wert hat \\(b_0\\) bei standardisierten Variablen?\ne. Welchem Wert entspricht \\(b_1\\) bei standardisierten Variablen?\nf. In welcher Einheit wird das unstandardisierte Regressionsgewicht angegeben?",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html#aufgabe-10.3-anwendungsbereich",
    "href": "uebungen/uebung-10.html#aufgabe-10.3-anwendungsbereich",
    "title": "Übung 10",
    "section": "Aufgabe 10.3: Anwendungsbereich",
    "text": "Aufgabe 10.3: Anwendungsbereich\nEigene Fragestellung bearbeiten.\na. Nehmen Sie an, Sie könnten sich einen Datensatz wünschen. Welche für Sie spannende Forschungsfrage könnte mit einer einfachen linearen Regression analysiert werden?\nb. Zeichnen Sie die Daten für Ihre Forschungsfrage auf.\n\nWas ist die AV und was die UV?\nZeichnen Sie die Achsen inkl. Achsenbeschriftungen (möglicher Wertebereich) auf. Wählen Sie wenn möglich Messungen/Achsen mit positiven, ganzzahligen Werten (integers). Wählen Sie für \\(x\\) (UV) eine Achse die \\(0\\) enthält.\nWelche Daten würden Sie erwarten? Zeichnen Sie ein Punktdiagramm (Scatterplot) mit 10-20 Datenpunkten zu Ihrer Forschungsfrage.\n\nc. Welcher Zusammenhang besteht zwischen den beiden Variablen?\n\nLegen Sie eine möglichst passende (lineare) Regressionsgerade durch die Punktewolke.\nMarkieren Sie den ungefähren Achsenabschnitt (intercept) \\(b_0\\). Welcher Wert hat \\(b_0\\)?\nZeichnen Sie den ungefähren Vorhersagefehler \\(e\\) für jeden Datenpunkt ein.\nWelche Steigung (slope) \\(b_1\\) hat die Gerade ungefähr? (Tipp: Zeichnen Sie auf der Gerade 2 Punkte ein und berechnen Sie die Differenz der \\(x\\) und \\(y\\)-Werten dieser zwei Punkte. Teilen Sie dann \\(dy/dx\\).)\n\nd. Nutzen Sie Ihre Analyse zur Prädiktion.\n\nWählen Sie einen neuen \\(x\\)-Wert.\nBerechnen Sie den neuen \\(y\\)-Wert mit der Regressionsgleichung (siehe Aufgabe 10.2a). Lassen Sie den Fehlerterm weg.\nZeichnen Sie den neuen Datenpunkt ein. Was stellen Sie fest?\n\ne. Welche Schlussfolgerungen würden Sie aus der Analyse ziehen? Welche Aussagen können Sie mit den berechneten Werten machen?\n\ne. Welche Schlussfolgerungen würden Sie aus der Analyse ziehen? Welche Aussagen können Sie mit den berechneten Werten machen?\nGemeinsam eine Fragestellung bearbeiten\nTauschen Sie in Kleingruppen/im Plenum die Forschungsfragen aus und wählen Sie als Gruppe eine davon aus. Sammeln Sie dieses Mal gemeinsam Daten: Jede Person zeichnet mind. einen (fiktiven) Datenpunkt ein. Gehen Sie danach obige Schritte anhand diesen Beispiels durch.\n\nWelche Schlussfolgerungen würden Sie aus der Analyse ziehen? Welche Aussagen können Sie mit den berechneten Werten machen?\n\nDiskutieren Sie zusätzlich:\n\nWelche weiteren Datenpunkte würden für sehr hohe/tiefe Werte der UV vorhergesagt werden?\nWas könnte zu Fehlschätzungen führen?\nWas würde passieren, wenn Sie die Achsen umdrehen? Bleiben die Werte für \\(b_0\\) und \\(b_1\\) gleich oder verändern diese sich?",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html#aufgabe-10.4-kleinste-quadrate-kriterium",
    "href": "uebungen/uebung-10.html#aufgabe-10.4-kleinste-quadrate-kriterium",
    "title": "Übung 10",
    "section": "Aufgabe 10.4: Kleinste Quadrate-Kriterium",
    "text": "Aufgabe 10.4: Kleinste Quadrate-Kriterium\na. Ergänzen Sie den folgenden Text zum Grundgedanken des Kleinste-Quadrate Kriteriums:\n\n“Optimale Reduktion des KriteriumsVorhersageBestimmung der Regressionsgeraden ist gegeben, wenn die Varianzdas Minimumdie Summe der quadrierten Differenzen zwischen den aus der unabhängigen Variablen beobachtetenvorhergesagten Werten der abhängigen Variablen und den beobachtetenvorhergesagten Werten der abhängigen Variablen maximalminimal ist.” (Eid et al. 2017)\n\nb. Diskutieren Sie diesen Gedanken kurz: Gibt es Unklarheiten? Fassen Sie den obigen Satz für Laienpersonen verständlich in 1-2 Sätzen zusammen.",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html#aufgabe-10.5-berechnen-der-regressionsgeraden",
    "href": "uebungen/uebung-10.html#aufgabe-10.5-berechnen-der-regressionsgeraden",
    "title": "Übung 10",
    "section": "Aufgabe 10.5: Berechnen der Regressionsgeraden",
    "text": "Aufgabe 10.5: Berechnen der Regressionsgeraden\n\n\n\n\n\n\nSchlafstudie\n\n\n\n\n\nBeschreibung der Studie\nIn der (fiktiven) Studie wurde der Einfluss von Schlafdauer bei Jugendlichen auf Konzentrationsleistung in einem neuropsychologischen Test (mögliche Scores zwischen 0 und 20) untersucht.\nForschungsfrage: Hängt die nächtliche Schlafdauer mit der Konzentration am nächsten Tag zusammen?\nDaten: Die Grafik zeigt Messungen von 10 Jugendlichen.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen Sie den Regressionskoeffizienten \\(b_1\\) und den Achsenabschnitt \\(b_0\\) dieser Daten.\na. Schreiben Sie alle Werte in eine Tabelle mit je einer Spalte für jede Variable oder geben Sie diese in R ein. Benennen Sie die UV \\(x\\) und die AV \\(y\\).\n\n# Packages laden\nlibrary(tidyverse)\n\n# Erstellen des Datensatzes\nd &lt;- tibble(x = ___,\n            y = ___)\n\nb. Berechnen Sie \\(r_{XY}\\) (die Korrelation der beiden Variablen) und die Standardabweichungen von Hand oder mit den Funktionen cor() und sd() in R.\n\n# Korrelation berechnen\nr_xy &lt;- ___\n\n# Standardabweichungen berechnen\nsd_x &lt;- ___\nsd_y &lt;- ___\n\nc. Berechnen Sie den Regressionskoeffizienten \\(b_1\\) von Hand oder in R.\nTipp: Multiplizieren Sie \\(r_{XY}\\) mit den Quotienten der Standardabweichungen von \\(Y\\) und \\(X\\), um das Regressionsgewicht \\(b_1\\) zu erhalten.\n\n# Regressionskoeffizient berechnen\nb_1 &lt;- ___\n\nd. Berechnen Sie den Achsenabschnitt \\(b_0\\). Hierfür brauchen Sie die Durchschnittswerte für \\(x\\) und \\(y\\).\n\n# Achsenabschnitt berechnen\nmean_x &lt;- ___\nmean_y &lt;- ___\nb_0 &lt;- ___\n\ne. Sagen Sie einen neuen Wert \\(y\\) für eine gegebenen Wert \\(x\\) vorher.\n\n# Prädiktion\ny_hat &lt;- ___\n\nf. Fügen Sie in den Plot die Werte für die Regressionsgerade ein. (Nur möglich, wenn Sie die Daten in R eingegeben haben.)\n\nd |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  xlim(0, 13) +\n  ylim(-5, 20) +\n  geom_abline(intercept = ___, slope = ___) +\n  theme_minimal()\n\ng. Welche Schlussfolgerungen würden Sie aus der Analyse ziehen? Welche Aussagen können Sie mit den berechneten Werten machen?",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html#aufgabe-10.6-berechnen-der-regressionsgeraden-für-eigenes-beispiel",
    "href": "uebungen/uebung-10.html#aufgabe-10.6-berechnen-der-regressionsgeraden-für-eigenes-beispiel",
    "title": "Übung 10",
    "section": "Aufgabe 10.6: Berechnen der Regressionsgeraden für eigenes Beispiel",
    "text": "Aufgabe 10.6: Berechnen der Regressionsgeraden für eigenes Beispiel\nBerechnen Sie, wie in der vorherigen Aufgabe, den Regressionskoeffizienten \\(b_1\\) und den Achsenabschnitt \\(b_0\\) für das in Aufgabe 10.3a-c selber erarbeitete Beispiel.\na. Schreiben Sie die Werte in eine Tabelle mit je einer Spalte für jede Variable oder geben Sie diese in R ein.\n\n# Packages laden\nlibrary(tidyverse)\n\n# Erstellen des Datensatzes\n___\n\nb. Berechnen Sie \\(b_1\\) und \\(b_0\\). Tipp: Verwenden Sie hierfür die Funktionen mean(), sd(), cor() in R.\nc. Zeichnen Sie die Regressionslinie in Ihr zu Beginn erstelltes Punktediagramm ein und vergleichen Sie diese mit der zuvor von Ihnen geschätzten Regressionsgerade. Oder plotten Sie die Daten alternativ mit {ggplot2}, siehe Aufgabe 10.5f.\nd. Welche Schlussfolgerungen würden Sie aus der Analyse ziehen? Welche Aussagen können Sie mit den berechneten Werten machen?",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-10.html#zusatzaufgaben",
    "href": "uebungen/uebung-10.html#zusatzaufgaben",
    "title": "Übung 10",
    "section": "Zusatzaufgaben",
    "text": "Zusatzaufgaben\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\na. Berechnen Sie die Varianzen: von \\(y\\), \\(\\hat{y}\\) und der Residuen \\(e\\), und berechnen Sie den Determinationskoeffizienten \\(R^2\\) und Indeterminationskoeffizienten. Was sagen diese aus?\n\n\n\n\n\n\nTipp\n\n\n\n\n\nErstellen Sie hierfür eine Tabelle wie in den Vorlesungsfolien und berechnen Sie die Zwischenschritte mit den Funktionen mean(), sd(), cor(), var() (siehe Deskriptive Statistik)\n\n\n\n\n\\(m\\)\n\\(x_m\\)\n\\(y_m\\)\n\\(\\hat{y}\\)\n\\(e_m = y_m - \\hat{y}_m\\)\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n5\n\n\n\n\n\n\nSumme\n\n\n\n\n\n\nM\n\n\n\n\n\n\nSD\n\n\n\n\n\n\nVarianz\n\n\\(s_{y}^2 =\\)\n\\(s_{\\hat{y}}^2 =\\)\n\\(s_e^2 =\\)\n\n\n\n\n\n\nb. Osterspecial: Lesen Sie in diesem Artikel was lineare Regression mit Jesus zu tun hat.",
    "crumbs": [
      "Übungen",
      "Übung 10"
    ]
  },
  {
    "objectID": "uebungen/uebung-11.html",
    "href": "uebungen/uebung-11.html",
    "title": "Übung 11",
    "section": "",
    "text": "Aufgabe 11.1: Einstieg\na. Welches sind die wichtigen Kennwerte, welche die Regressionsanalyse liefert?\nb. Suchen Sie mit dem Suchbegriff “we used a simple linear regression” oder “a simple linear regression model was used” sowie einem Begriff für ein Thema in der Psychologie, dass Sie interessiert in einer Datenbank nach Artikeln.\nSchauen Sie sich dann an, was diese Studien untersucht haben und lesen Sie die Results-Section. Finden Sie die Kennwerte der Regressionsanalyse? Was verstehen Sie bezüglich der Analyse, welche gemacht wurde und welche Resultate sie lieferten? Was bleibt unklar?\nDiskutieren Sie kurz miteinander, was Sie gefunden haben.",
    "crumbs": [
      "Übungen",
      "Übung 11"
    ]
  },
  {
    "objectID": "uebungen/uebung-11.html#aufgabe-11.2-regression-berechnen-i",
    "href": "uebungen/uebung-11.html#aufgabe-11.2-regression-berechnen-i",
    "title": "Übung 11",
    "section": "Aufgabe 11.2: Regression berechnen I",
    "text": "Aufgabe 11.2: Regression berechnen I\nBearbeiten Sie diese Aufgabe im RNotebook uebung-11.\nIn dieser Aufgabe berechnen wir die Regression für das Datenbeispiel der Aufgabe 10.5 von Übung 10 mit der Funktion lm() statt Schritt für Schritt.\n\n\n\n\n\n\nSchlafstudie\n\n\n\n\n\nBeschreibung der Studie\nIn der (fiktiven) Studie wurde der Einfluss von Schlafdauer bei Jugendlichen (sleep) auf Konzentrationsleistung in einem neuropsychologischen Test (mögliche Scores zwischen 0 und 20) (concentration) untersucht.\nForschungsfrage: Beeinflusst die nächtliche Schlafdauer mit die Konzentration am nächsten Tag?\nDaten: Die Grafik zeigt Messungen von 10 Jugendlichen.\n\nDaten der Schlafstudie\n\n\n\\(x\\)\n\\(y\\)\n\n\n\n\n5\n6\n\n\n6\n10\n\n\n7\n6\n\n\n7\n12\n\n\n8\n12\n\n\n9\n12\n\n\n9\n16\n\n\n10\n18\n\n\n11\n14\n\n\n12\n12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na. Geben Sie die Daten in R ein.\n\n# Package(s) laden\n___\n\n# Daten eingeben\nd_sleep &lt;- ___(sleep = ___,\n               concentration = ___)\n\nb. Berechnen Sie eine einfache lineare Regression mit Schlaf als Prädiktorvariablen (unabhängiger Variablen) und Konzentration als Kriteriumsvariablen (abhängiger Variablen).\n\n# Modell für einfache lineare Regression\nm1_sleep &lt;- lm(___ ~ ___, \n                        data = ___)\n\nsummary(___)\n\nc. Interpretieren Sie den Output: Wie gross waren folgende Kennwerte und was bedeutet das?\n\nAchsenabschnitt \\(b_0\\)\nRegressionskoeffizient \\(b_1\\)\n\\(p\\)\n\\(R^2\\)\n\nWas bedeuten die restlichen Werte des Outputs?",
    "crumbs": [
      "Übungen",
      "Übung 11"
    ]
  },
  {
    "objectID": "uebungen/uebung-11.html#aufgabe-11.3-regression-berechnen-ii",
    "href": "uebungen/uebung-11.html#aufgabe-11.3-regression-berechnen-ii",
    "title": "Übung 11",
    "section": "Aufgabe 11.3: Regression berechnen II",
    "text": "Aufgabe 11.3: Regression berechnen II\nBearbeiten Sie diese Aufgabe im RNotebook uebung-11.\n\n\n\n\n\n\nBeschreibung des Datensatzes\n\n\n\nDer Datensatz wurde simuliert mit Werten angelehnt an die Informationen3 einer nicht-klinischen Stichprobe aus dem Originalartikel zu den Depression Anxiety Stress Scales (DASS) (Lovibond & Lovibond, 1995). Die Subskalen reichen von 0-42, wobei höhere Werte eine höhere Ausprägung (von Angst bzw. Stress) bedeuten.\n\n\nBearbeiten Sie nun Schritt für Schritt folgenden Aufgaben:\na. Formulieren Sie eine Fragestellung und halten Sie diese in Ihrem RNotebook uebung-11 fest.\n\nWas ist die Prädiktorvariable (unabhängige Variable)?\nWas die Kriteriumsvariable (abhängige Variable)?\nWelcher Anwendung (Beschreiben, Erklären, Prognose) entspricht Ihre Forschungsfrage?\n\nb. Lesen Sie aus dem data-Ordner des RProjekts regression den Datensatz stressanxiety.csv ein und schauen Sie ihn an.\n\n# Datensatz einlesen\n___\n\n# Datensatz anschauen\n___\n\nc. Welche Voraussetzungen müssen für die einfache lineare Regression erfüllt sein? Überprüfen Sie diese sofern möglich.\n\n# Datensatz plotten\n\nd. Berechnen Sie eine einfache lineare Regression für die beiden Variablen.\n\n# Regressionsmodell\nm1_stressanxiety &lt;- ___\n\n# Output\n___\n\ne. Überprüfen Sie die Modellannahmen für das berechnete Modell mit den Funktionen\n\ncheck_model()\ncheck_heteroscedasticity()\ncheck_normality()\n\naus dem Package {performance}.\n\nHier finden Sie weiterführende, hilfreiche Informationen zum Package {performance}.\n\n\n# Check Modelannahmen\n___\n\nf. Lassen Sie sich den Modelloutput ausgeben mit der Funktion summary(): Wie gross waren folgende Kennwerte und was bedeutet das?\n\n# Output\n___\n\n\nAchsenabschnitt \\(b_0\\) und entsprechender \\(p\\)-Wert\nRegressionskoeffizient \\(b_1\\) und entsprechender \\(p\\)-Wert\n\\(df\\)\n\\(R^2\\)\n\nWas bedeuten die restlichen Werte des Outputs?\ng. Berechnen Sie das andere mögliche Modell in dem Sie stress und anxiety tauschen.\n\n# Regressionsmodell\nm1_stressanxiety2 &lt;- ___\n\n# Output\n___\n\n\nWas können Sie jetzt für eine Aussage machen?\nStimmen die beiden Regressionskoeffizienten überein? Was denken Sie sagt die Höhe des Regressionskoeffizienten über die Stärke des Zusammenhangs aus?\n\ng. Berechnen Sie den standardisierten Regressionskoeffizienten in dem Sie scale() nutzen (\\(z\\)-transformiert die Variablen)\n\nlm(scale(___) ~ scale(___), \n   data = ___)\n\n\nWas passiert, wenn Sie die beiden Variablen wie oben austauschen?\nWas bedeutet der Regressionskoeffizient nun?",
    "crumbs": [
      "Übungen",
      "Übung 11"
    ]
  },
  {
    "objectID": "uebungen/uebung-11.html#aufgabe-11.4-resultate-berichten",
    "href": "uebungen/uebung-11.html#aufgabe-11.4-resultate-berichten",
    "title": "Übung 11",
    "section": "Aufgabe 11.4: Resultate berichten",
    "text": "Aufgabe 11.4: Resultate berichten\na. Erstellen Sie nun einen Bericht über die in Aufgabe 11.3 berechneten Ergebnisse der Regressionsanalyse. Achten Sie darauf, dass alle wichtigen Kennwerte enthalten sind. Informationen hierfür finden Sie hier.\nb. Erstellen Sie einen Bericht über die in Aufgabe 11.2 berechneten Ergebnisse der Regressionsanalyse.",
    "crumbs": [
      "Übungen",
      "Übung 11"
    ]
  },
  {
    "objectID": "uebungen/uebung-11.html#zusatzaufgabe",
    "href": "uebungen/uebung-11.html#zusatzaufgabe",
    "title": "Übung 11",
    "section": "Zusatzaufgabe",
    "text": "Zusatzaufgabe\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\na. Schauen Sie für _Aufgabe 11.3__ mit der Funktion check_model() aus dem Package {performance}, ob die Voraussetzungen für die Regressionsanalyse gegeben sind.\nb. Vergleichen Sie den berechneten standardisierten Regressionskoeffizienten aus Aufgabe 11.3 mit der Korrelationsmatrix der Variablen Angst und Stress aus dem Originalpaper von Lovibond & Lovibond, 1995.\n\nIst er vergleichbar?\nHätten Sie den Zusammenhang der Variablen der berichteten Stärke angenommen?",
    "crumbs": [
      "Übungen",
      "Übung 11"
    ]
  },
  {
    "objectID": "uebungen/uebung-11.html#footnotes",
    "href": "uebungen/uebung-11.html#footnotes",
    "title": "Übung 11",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden.↩︎\nEs werden beim Herunterladen zusätzliche Packages installiert, geben Sie dafür bei Aufforderung in der Konsole y ein.↩︎\nMittelwerte, Standardabweichungen, Korrelation↩︎",
    "crumbs": [
      "Übungen",
      "Übung 11"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html",
    "href": "uebungen/uebung-12.html",
    "title": "Übung 12",
    "section": "",
    "text": "Aufgabe 12.0: Projektumgebung erstellen\nDateien und Packages für die Übung vorbereiten:",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#aufgabe-12.0-projektumgebung-erstellen",
    "href": "uebungen/uebung-12.html#aufgabe-12.0-projektumgebung-erstellen",
    "title": "Übung 12",
    "section": "",
    "text": "Laden Sie den Datensatz sat_act.csv herunter und speichern Sie den Datensatz im data-Ordner des RProjekts regression.\n\n\n\n\n\n\n\nFalls Übung 11 nicht durchgeführt\n\n\n\n\n\n\nLaden Sie den Projektordner regression herunter und entzippen Sie den Ordner.1 Der Projektordner enthält:\n\nRProjekt regression.RProj\nDatensatz stressanxiety.csv für Übung 11\nDatensatz sat_act.csv für Übung 12\n\nInstallieren Sie (falls noch nicht vorhanden) die benötigten Packages unter Tools &gt; Install Packages... oder in der Konsole mit\n\ninstall.packages(\"performance\")2\n\n\n\n\n\n\nÖffnen Sie das RProjekt regression.\nErstellen Sie ein RNotebook namens uebung-12.",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#aufgabe-12.1-positive-und-negative-regressionsgewichte",
    "href": "uebungen/uebung-12.html#aufgabe-12.1-positive-und-negative-regressionsgewichte",
    "title": "Übung 12",
    "section": "Aufgabe 12.1: Positive und negative Regressionsgewichte",
    "text": "Aufgabe 12.1: Positive und negative Regressionsgewichte\nWas bedeuten folgende (fiktive) Resultate?\n\nA. Eine Studie hat den Einfluss von Musikstunden pro Woche auf das Abschneiden in einem Intelligenztest bei 15-jährigen untersucht. Die Studie hat ein \\(b_0\\) = 98.72 und ein \\(b_1\\) = 0.25 gefunden.\n\n\nB. Eine Studie hat den Zusammenhang von Musikstunden pro Woche und dem dem Abschneiden in einem Sportleistungstest bei 15-jährigen untersucht. Die Studie hat ein \\(b_0\\) = 34.3 und ein \\(b_1\\) = -1.21 gefunden.\n\n\nC. Eine Studie hat untersucht, wie sich die Lebenszufriedenheit verändert wenn Personen mehr oder weniger Unterstützung durch die Spitex erhalten. Die Studie hat ein \\(b_0\\) = 5.7 und ein \\(b_1\\) = -0.002 gefunden.\n\nWie würden Sie das Resultat einer Person erklären, die die Regressionsanalyse nicht kennt? Formulieren Sie in einem Satz aus, was die Ergebnisse bedeuten.\nEvtl. helfen folgende Unterfragen dabei:\n\nWas ist die AV, was ist die UV?\nWie verändert sich die AV in Abhängigkeit von der UV?\nIn welchen Beispielen finden Sie standardisierte und in welchen unstandardisierte Variablen sinnvoller?",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#aufgabe-12.2-einstieg-in-multiple-regression",
    "href": "uebungen/uebung-12.html#aufgabe-12.2-einstieg-in-multiple-regression",
    "title": "Übung 12",
    "section": "Aufgabe 12.2: Einstieg in multiple Regression",
    "text": "Aufgabe 12.2: Einstieg in multiple Regression\na. Was unterscheidet die einfach von der multiplen Regression? Was ist der Mehrwert?\nb. Was sind die Voraussetzungen für die multiple Regression?\nc. Welche Fragestellung würden Sie untersuchen wollen, bei der eine multiple Regression zur Anwendung kommen könnte?\nd. Suchen Sie mit dem Suchbegriff “we used a multiple regression” oder “a multiple linear regression model was used” sowie einem Begriff für ein Thema in der Psychologie, dass Sie interessiert in einer Datenbank nach Artikeln.\nSchauen Sie sich dann an, was diese Studien untersucht haben und lesen Sie die Results-Section. Finden Sie die Kennwerte der Regressionsanalyse? Was verstehen Sie bezüglich der Analyse, welche gemacht wurde und welche Resultate sie lieferten? Was bleibt unklar?\nDiskutieren Sie kurz miteinander, was Sie gefunden haben.",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#aufgabe-12.3-regressionsgleichung-der-multiplen-regression",
    "href": "uebungen/uebung-12.html#aufgabe-12.3-regressionsgleichung-der-multiplen-regression",
    "title": "Übung 12",
    "section": "Aufgabe 12.3: Regressionsgleichung der multiplen Regression",
    "text": "Aufgabe 12.3: Regressionsgleichung der multiplen Regression\na. Wie lautet die Bestimmungsgleichung der Regressionsgeraden in der multiplen Regressionsanalyse? Schreiben Sie die Gleichung für zwei Prädiktorvariablen auf.\nb. Was bedeutet der Wert \\(b_1\\) in der multiplen Regression?\nc. Ergänzen Sie den folgenden Text zur Additivität der Regressionskomponenten:\n\nEin beobachteter yxe-Wert lässt sich additiv zerlegen in die Kriteriumsvariableden Achsenabschnittden Regressionskoeffizienten \\(b_0\\), den mit \\(b_1\\) korreliertenquadriertengewichteten Wert von \\(x_{m1}\\) (Kriteriumsvariableerste Prädiktorvariablezweite Prädiktorvariable), den mit \\(b_2\\) korreliertenquadriertengewichteten Wert von \\(x_{m2}\\) (Kriteriumsvariableerste Prädiktorvariablezweite Prädiktorvariable), und den ResidualwertVarianzen der Residuendie kleinste Quadratsumme \\(e_m\\).\n\nFassen Sie in einfachen Worten zusammen, was Additivität der Regressionskomponenten bedeutet und tauschen Sie Ihre Definitionen aus.",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#aufgabe-12.4-multiple-regression-berechnen-i",
    "href": "uebungen/uebung-12.html#aufgabe-12.4-multiple-regression-berechnen-i",
    "title": "Übung 12",
    "section": "Aufgabe 12.4: Multiple Regression berechnen I",
    "text": "Aufgabe 12.4: Multiple Regression berechnen I\nBearbeiten Sie diese Aufgabe im RNotebook uebung-12.\nIn dieser Aufgabe berechnen wir die Regression für das Datenbeispiel sat_act.csv.\n\n\n\n\n\n\nPrüfungsscores\n\n\n\n\n\nBeschreibung der Daten\nDiese Daten wurden im Rahmen des SAPA-Projekts3 erhoben, um Online-Messungen von Testleistungen zu entwickeln (Revelle, Wilt und Rosenthal, 2009).\nDer Datensatz (n = 700) beinhaltet die Variablen:\n\nage: Alter in Jahren\ngender4: m (1), f (2)\neducation: Selbstberichteter Bildungsgrad (1 = high school … 5 = graduate work)\nACT: Testscore ACT (American College Testing)\nSATV: Testscore SAT (Scholastic Assessment Test) Verbal\nSATQ: Testscore SAT (Scholastic Assessment Test) Quantitativ\n\nQuelle: Revelle, William, Wilt, Joshua, und Rosenthal, Allen (2009) Personality and Cognition: The Personality-Cognition Link. In Gruszka, Alexandra, Matthews, Gerald und Szymura, Blazej (Hrsg.) Handbook of Individual Differences in Cognition: Attention, Memory and Executive Control, Springer.5\n\n\n\na. Fragestellung\nWelche Fragestellung möchten Sie bearbeiten mit den oben gegebenen Variablen? Überprüfen Sie die Voraussetzungen für die Regression (metrische Variablen und Linearität).\n\nWählen Sie dafür drei Variablen aus (eine AV und zwei UVn).\nFormulieren Sie die Fragestellung und schreiben Sie sie in Ihr RNotebook.\nSchreiben Sie sich auf: Welche Variable ist \\(y\\)? Welche \\(x_1\\) und welche \\(x_2\\)?\nDenken Sie, dass \\(x_1\\) und \\(x_2\\) zusammenhängen?\n\nb. “Präregistrierung”\nVerfassen Sie ein Resultatetext ohne zu wissen welche Resultate die Analyse ergeben wird. Lassen Sie die Werte deshalb noch weg. Schreiben Sie einen Text für das für Sie wahrscheinlichste Ergebnis.\nc. Datensatz vorbereiten\n\nLesen Sie den Datensatz sat_act.csv aus dem data-Ordner Ihres regression-Projekts ein und speichern Sie ihn unter d_sat_act.\nTransformieren Sie die Variable gender in eine kategoriale Variable.\nIn den SATQ-Scores gibt es einige fehlende Werte (missings). Filtern Sie diese heraus wie hier beschrieben.\n\nFühren Sie diese Schritte idealerweise mit der Pipe (|&gt;) aus, damit sie die Objekte nicht überschreiben/neu benennen müssen. Bei korrekter Ausführung bleiben 687 Datenpunkte (obs.) in 6 Variablen..\nd. Variablen bestimmen und Voraussetzungen prüfen\n\nSchauen Sie für beide Variablenpaare \\(y ~ x_1\\) und \\(y ~x_2\\) den Zusammenhang mit je einem Plot an. Ist die Annahme der (Quasi-)Linearität ok?\n\ne. Regressionsmodelle berechnen und vergleichen\n\nBerechnen Sie das einfache lineare Regressionsmodell mit \\(x_1\\) als Prädiktorvariable.\n\n\n# Modell mit x1 als Prädiktor\nm_x1 &lt;- ___\n\n\nBerechnen Sie das einfache lineare Regressionsmodell mit \\(x_2\\) als Prädiktorvariable.\n\n\n# Modell mit x2 als Prädiktor\nm_x2 &lt;- ___\n\n\nBerechnen Sie die multiple Regression mit \\(x_1\\) und \\(x_2\\) als Prädiktorvariablen.\n\n\n# Modell mit x1 und x2 als Prädiktoren\nm_x1x2 &lt;- ___\n\nVergleichen Sie den Achsenabschnitt und die Regressionskoeffizienten zwischen den Modellen. Was sehen Sie?\nf. Voraussetzungen überprüfen\nSchauen Sie sich mit den Model-Check Funktionen aus dem {performance}-Package an, ob die Voraussetzungen für die multiple Regression gegeben sind. Falls die Annahmen verletzt sind: Sehen Sie in den Plots, weshalb?\n\nTipp: Ganz schnell können diagnostische Plots auch mit der Funktion plot() erstellt werden, als Argumentnamen wird nur das Modell-Objekt z.B. m_x1 benötigt. Welche Form der Plots mögen Sie mehr?",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#aufgabe-12.5-varianzaufklärung-und-determinationskoeffizienten",
    "href": "uebungen/uebung-12.html#aufgabe-12.5-varianzaufklärung-und-determinationskoeffizienten",
    "title": "Übung 12",
    "section": "Aufgabe 12.5: Varianzaufklärung und Determinationskoeffizienten",
    "text": "Aufgabe 12.5: Varianzaufklärung und Determinationskoeffizienten\n\nWas sagt ein Determinationskoeffizient aus? Wann ist er 0? Wann ist er 1?\nErstellen Sie eine Tabelle mit den Spalten Modell, Prädiktor(en), \\(R^2\\), \\(\\triangle R^2\\). Fügen Sie aus den obigen Modellen die Prädiktoren, das \\(R^2\\) sowie die in dem Modell zusätzlich erklärte Varianz (\\(\\triangle R^2\\)), also die Differenz von \\(R^2\\) zum vorherigen \\(R^2\\), ein.\n\n\nDeterminationskoeffizienten\n\n\nModell\nPrädiktor(en)\n\\(R^2\\)\n\\(\\triangle R^2\\)\n\n\n\n\n\\(m_{x1}\\)\n\n\n\n\n\n\\(m_{x2}\\)\n\n\n\n\n\n\\(m_{x1x2}\\)\n\n\n\n\n\n\\(m_{x2x1}\\)\n\n\n\n\n\n\n\nWas passiert mit \\(R^2\\), wenn Sie die Reihenfolge der Prädiktorvariablen umdrehen?\n\n\n# Modell mit x2 und x1 als Prädiktoren\nm_x2x1 &lt;- ___\n\n\nVergleichen und diskutieren Sie kurz mit jemandem, der andere Modelle gerechnet hat. Was fällt Ihnen auf?\nWieso heisst der Determinationskoeffizient \\(R^2\\)? (Tipp: Auf https://rpsychologist.com/correlation/ können Sie Daten/Korrelationen simulieren und die Korrelation und den \\(R^2\\)-Wert vergleichen)\nZeichnen Sie auf, wie viel Varianz Ihre gewählten Variablen in der Varianz von \\(y\\) aufklären. Zeichnen Sie dies mittels 3 Kreisen auf.\n\n\n\n\nErklärte Varianz zwischen Kriteriumsvariable und Prädiktoren (Venn Diagramme)",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#aufgabe-12.6-resultate-berichten",
    "href": "uebungen/uebung-12.html#aufgabe-12.6-resultate-berichten",
    "title": "Übung 12",
    "section": "Aufgabe 12.6: Resultate berichten",
    "text": "Aufgabe 12.6: Resultate berichten\nLassen Sie sich mit summary() den Output des Modells \\(m_x1x2\\) ausgeben. Um nur die Regressionskoeffizienten anzuschauen, können auch model$coefficients oder summary(model)$cofficients verwenden.\n\n___(___)\n___$coefficients\nsummary(____)$coefficients\n\n\nFüllen Sie nun die Werte in den Resultate-Text, den Sie in Aufgabe 12.4b vorbereitet haben.\nFügen Sie noch einen Satz zu den Modellannahmen ein (erfüllt, nicht erfüllt?).\nHätten Sie dieses Resultat erwartet? Diskutieren Sie zusammen, ob Ihre Intuition und die Resultate übereingestimmt haben.",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#zusatzaufgaben",
    "href": "uebungen/uebung-12.html#zusatzaufgaben",
    "title": "Übung 12",
    "section": "Zusatzaufgaben",
    "text": "Zusatzaufgaben\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\na. Interaktiver Plot: Regressionsebene\nMit dem R-Skript können Sie Datenpunkte simulieren und diese dann mit der gefitteten Regressionsebene in R plotten. Das Skript erstellt einen interaktiven 3D-Plot im Plots-Fenster (rechter unterer Quadrant). Der 3D-Plot visualisert, wie bei zwei Prädiktoren eine zwei Regressionsgeraden eine Ebene ergeben.\nVorgehen:\n\nInstallieren Sie das Package {plotly} mit install.packages(\"plotly\") in der Konsole.\nLaden Sie das R-Skript regressionplane_3dmodel.R herunter, um neue Daten zu simulieren oder das R-Skript regressionplane_3dmodel_tibble.R, um die Werte der Variablen einzuheben.\nPlotten Sie die Grafik. Finden Sie ungefähr die Werte von \\(b_0\\), \\(b_1\\) und \\(b_2\\)?\nVerändern Sie die Werte und plotten Sie die Grafik erneut.\n\n\nb. Regressionskoeffizienten vergleichen (für Interessierte)\nVergleichen Sie die Regressionskoeffizienten \\(b_1\\) zwischen den Modellen \\(m_x1\\) und \\(m_{x1x2}\\). Welcher Fall trifft zu? Was bedeutet das?6\n\nA. \\(b_{einf}\\) = \\(b_{mult}\\): Das Regressionsgewicht \\(b_1\\) ist im Modell \\(m_{x1}\\) entspricht dem Regressionsgewicht \\(b_1\\) im Modell \\(m_{x1x2}\\).\n\n\n\nB. \\(b_{einf}\\) &gt; \\(b_{mult}\\): Das Regressionsgewicht von \\(b_1\\) ist im Modell \\(m_{x1}\\) grösser als \\(b_1\\) im Modell \\(m_{x1x2}\\).\n\n\n\nC. \\(b_{einf}\\) &lt; \\(b_{mult}\\): Das Regressionsgewicht von \\(b_1\\) ist im Modell \\(m_{x1}\\) kleiner als \\(b_1\\) im Modell \\(m_{x1x2}\\).",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-12.html#footnotes",
    "href": "uebungen/uebung-12.html#footnotes",
    "title": "Übung 12",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden.↩︎\nEs werden beim Herunterladen zusätzliche Packages installiert, geben Sie dafür bei Aufforderung in der Konsole y ein.↩︎\nhttps://www.sapa-project.org/↩︎\nDies ist ein älterer Datensatz, heute werden sex und gender unterschieden und weitere Antwortkategorien gegeben z.B. d↩︎\nhttps://vincentarelbundock.github.io/Rdatasets/doc/psych/sat.act.html↩︎\nsiehe S. 635 in Eid et al. (2017)↩︎",
    "crumbs": [
      "Übungen",
      "Übung 12"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html",
    "href": "uebungen/uebung-13.html",
    "title": "Übung 13",
    "section": "",
    "text": "Aufgabe 13.0: Projektumgebung erstellen\nDer Projektordner enthält: - RProjekt repetition.RProj- Datensatzdataset_vacation.csvimdata`-Ordner des RProjekts",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.0-projektumgebung-erstellen",
    "href": "uebungen/uebung-13.html#aufgabe-13.0-projektumgebung-erstellen",
    "title": "Übung 13",
    "section": "",
    "text": "Laden Sie den Projektordner repetition herunter und entzippen Sie den Ordner.1\nOder laden Sie den Datensatz direkt hier herunter und speichern Sie ihn in einen selber erstellten Projektordner.\n\n\n\nÖffnen Sie das RProjekt repetition.\nErstellen Sie ein RNotebook namens uebung-13.",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#einführung",
    "href": "uebungen/uebung-13.html#einführung",
    "title": "Übung 13",
    "section": "Einführung",
    "text": "Einführung\nIn dieser Übung erhalten Sie einen Datensatz und mehrere Fragestellungen. Für jede Fragestellung ist es Ihre Aufgabe den Datensatz vorzuverarbeiten, die passende Analysemethode zu wählen und durchzuführen und die Fragestellung zum Schluss in wenigen Sätzen zu beantworten.\nLesen Sie zuerst den Studienbeschrieb und lesen Sie dann die Daten ein. Anschliessend können Sie für jede Fragestellung wie folgt vorgehen:\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\nc. Datenanalyse ausführen und Voraussetzungen prüfen\nd. Resultate beschreiben\n\n\n\n\n\n\n\nDatensatz dataset_vacation.csv\n\n\n\n\n\nBeschreibung der Studie\nIn der (fiktiven) Studie wurde untersucht, welchen Effekt eine Woche Ferien auf das Wohlbefinden hat. Dazu wurden 160 Personen zu drei Messzeitpunkten (time) befragt. Die Ferienwoche fand zu unterschiedlichen Jahreszeit statt (je 40 Personen im Frühling, Sommer, Herbst und Winter) (group). Alle 160 Personen wurden jeweils vor, während und nach den Ferien zu ihrem Energielevel (energy) und ihrer Schlafqualität (sleep) befragt. Weiter wurde an jedem Messzeitpunkt für jede Person einen Wert für ihre allgemeine Gesundheit (health) aus verschiedenen Tests (u.a. Blutdruck, Stresshormone, etc.) bestimmt. Zudem wurde von jeder Person erhoben, ob sie in einem “high stress” oder “low stress”-Job arbeitet (job).\nVariablen:\n\nid: Personenidentifikation\ngroup: Jahreszeit der Ferien\ntime: Messzeitpunkt vor (t1), während (t2) und nach (t3) den Ferien\nenergy: Energielevel (Fragebogendaten (kontinuierlich) mit -20: sehr wenig bis 20: sehr viel Energie)\nsleep: Schlafqualität (Fragebogendaten (kontinuierlich) mit 0: sehr schlecht bis 30: sehr gut)\nhealth: Gesundheitswert jeder Person (0: tiefer Gesundheitswert (viele Krankheitsanzeichen) bis 100: hoher Gesundheitswert (keine Krankheitsanzeichen))\n\n\n\n\nDaten einlesen\n\nLesen Sie den Datensatz dataset_vacation.csv ein und machen Sie sich mit ihm vertraut.\nFinden Sie alle nötigen Variablen?\nSind die Variablen richtig kodiert? (Die kategorialen Variablen sollten als factor kodiert sein. Dies kann mit mutate(variable = as.factor(variable)) erreicht werden.)\nWelche Variablen wurden within-subjects und welche between-subjects erhoben?\nGibt es fehlende Werte, die bereinigt werden müssen?\n\n\n# Packages laden\nlibrary(tidyverse)\n\n# Datensatz einlesen\nd_vacation &lt;- ___ \n\n\n___",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.1-gesundheit-und-jahreszeiten",
    "href": "uebungen/uebung-13.html#aufgabe-13.1-gesundheit-und-jahreszeiten",
    "title": "Übung 13",
    "section": "Aufgabe 13.1: Gesundheit und Jahreszeiten",
    "text": "Aufgabe 13.1: Gesundheit und Jahreszeiten\nWie unterscheiden sich die Gesundheitswerte vor den Ferien zwischen Personen in high-stress-Jobs und Personen in low-stress-Jobs?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\n\nd_vacation_1 &lt;- ___\n\nc. Datenanalyse ausführen und Voraussetzungen sicherstellen\n\n# Voraussetzungen testen\n____\n\n\n# Deskriptivstatistik\nd1_summary &lt;- ___\n\nd1_summary\n\n\n# Statistischer Test\n___\n\n\n# Effektgrösse berechnen\n___\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.2-schlaf-energie-und-gesundheit",
    "href": "uebungen/uebung-13.html#aufgabe-13.2-schlaf-energie-und-gesundheit",
    "title": "Übung 13",
    "section": "Aufgabe 13.2: Schlaf, Energie und Gesundheit",
    "text": "Aufgabe 13.2: Schlaf, Energie und Gesundheit\nWelchen Effekt haben Schlafqualität und Energielevel auf die Gesundheit während den Ferien?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\n\nd_vacation_2 &lt;- ___\n\nc. Datenanalyse ausführen und Voraussetzungen sicherstellen\n\n# Plots\n\n\n# Statistischer Test\nm2 &lt;- ___\n\n# Output ausgeben\nsummary(m2)\n\n\n# Modellannahmen prüfen\n____\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.3-jahreszeit-und-wohlbefinden",
    "href": "uebungen/uebung-13.html#aufgabe-13.3-jahreszeit-und-wohlbefinden",
    "title": "Übung 13",
    "section": "Aufgabe 13.3: Jahreszeit und Wohlbefinden",
    "text": "Aufgabe 13.3: Jahreszeit und Wohlbefinden\nWelchen Effekt hat die Jahreszeit der Ferien auf das Wohlbefinden (Energielevel und Schlaf) nach den Ferien?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\nWelche Datenpunkte müssen für diese Fragestellung in die Analyse einbezogen werden, und welche nicht? Erstellen Sie falls nötig einen neuen Datensatz (siehe Funktion filter()).\n\nd_vacation_3 &lt;- ___\n\nc. Datenanalyse ausführen und Voraussetzungen prüfen\n\n# Voraussetzungen prüfen\n___\n\n\n# Deskriptive Statistik\nd3_summary &lt;- ___ \nd3_summary\n\n\n# Statistischer Test\nm3_energy &lt;- ___\n\n\nm3_sleep &lt;- ___\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.4-energielevel-und-jahreszeit",
    "href": "uebungen/uebung-13.html#aufgabe-13.4-energielevel-und-jahreszeit",
    "title": "Übung 13",
    "section": "Aufgabe 13.4: Energielevel und Jahreszeit",
    "text": "Aufgabe 13.4: Energielevel und Jahreszeit\nUnterscheidet sich das Energielevel nach den Winterferien vom Mittel des Energielevels nach den Frühlings- & Herbstferien? \na. Datenanalyse festlegen\nb. Daten vorverarbeiten\nc. Datenanalyse ausführen und Voraussetzungen sicherstellen\n\n___\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.5-messzeitpunkt-und-wohlbefinden",
    "href": "uebungen/uebung-13.html#aufgabe-13.5-messzeitpunkt-und-wohlbefinden",
    "title": "Übung 13",
    "section": "Aufgabe 13.5: Messzeitpunkt und Wohlbefinden",
    "text": "Aufgabe 13.5: Messzeitpunkt und Wohlbefinden\nWelchen Effekt haben die Ferien auf das Wohlbefinden (Energielevel und Schlaf), d.h. unterscheidet sich das Wohlbefinden vor, während und nach den Ferien?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\n\n# Datensatz anschauen\n___\n\nc. Datenanalyse ausführen und Voraussetzungen sicherstellen\n\n# Deskriptive Statistik\n# Mittelwerte und Standardabweichungen berechnen\nd5_summary &lt;- ___ \nd5_summary\n\n\n___\n\nd. Resultate beschreiben\n\n\n\n\n\n\n\nInteressiert am Effekt von Ferien?\n\n\n\n\n\nDie Idee für diesen Übungsdatensatz stammt von diesem Artikel:\nBloom et al. (2010). Effects of vacation from work on health and well-being: Lots of fun, quickly gone. Work & Stress, 24(2), 196–216. https://doi.org/10.1080/02678373.2010.493385",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#zusatzaufgaben",
    "href": "uebungen/uebung-13.html#zusatzaufgaben",
    "title": "Übung 13",
    "section": "Zusatzaufgaben",
    "text": "Zusatzaufgaben\n\n\n\n\n\n\nZusatzaufgaben\n\n\n\nZusatzaufgaben müssen nicht gelöst werden.\n\n\na. Visualisieren Sie die obigen Ergebnisse, um den Resultateteil zu ergänzen.\nb. Lösen Sie die noch nicht gelösten Aufgaben und Zusatzaufgaben des Semesters.",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#herzliche-gratulation",
    "href": "uebungen/uebung-13.html#herzliche-gratulation",
    "title": "Übung 13",
    "section": "Herzliche Gratulation",
    "text": "Herzliche Gratulation\nSie haben alle Übungen durchgearbeitet!!",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#footnotes",
    "href": "uebungen/uebung-13.html#footnotes",
    "title": "Übung 13",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden.↩︎",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "appendix/faq.html",
    "href": "appendix/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Datensätze einlesen\nDer Datensatz kann nicht geöffnet werden mit dem vorgegebenen Code?\nDie zwei häufigsten Gründe sind",
    "crumbs": [
      "Anhang",
      "FAQ"
    ]
  },
  {
    "objectID": "appendix/faq.html#datensätze-einlesen",
    "href": "appendix/faq.html#datensätze-einlesen",
    "title": "FAQ",
    "section": "",
    "text": "Speicherort: Das File ist nicht in dem Ordner gespeichert in dem R sucht.\n\nÜberprüfen Sie im Files-Bereich (rechter unterer Quadrant), ob das File am richtigen Ort gespeichert wurde.\nÜberprüfen Sie, ob der Pfad in der Einlesefunktion stimmt.\n\nSeparators/Delimiters: Jedes File hat ein Kennzeichen für die nächste Spalte, z.B. Kommas, Semikolons, Tabs, etc. Das Problem beim Einlesen geschieht oft, wenn nach dem Herunterladen der .csv- Datensatz z.B. in Excel geöffnet wird. Beim Abspeichern mit Excel verändern sich die Separators (z.B. von , zu ;) und der vorgegebene Code kann nicht ausgeführt werden.\n\nVerwenden von Import Dataset, um sich den Code ausgeben zu lassen.\nDatensatz nochmals herunterladen und abspeichern ohne ihn in Excel (o.a. Programm) zu öffnen.\nVerändern des Argumentes, welches Separator/Delimiters spezifiziert (sep = ..., delim = ...).",
    "crumbs": [
      "Anhang",
      "FAQ"
    ]
  },
  {
    "objectID": "appendix/faq.html#variablen-und-funktionen",
    "href": "appendix/faq.html#variablen-und-funktionen",
    "title": "FAQ",
    "section": "Variablen und Funktionen",
    "text": "Variablen und Funktionen\nWelche Werte enthält eine Variable / ein Datensatz?\n\nUm die Werte einer Variable oder eines Datensatzes zu sehen, schauen Sie in unter Environment(rechter oberer Quadrant in _RStudio) nach. Dort können Sie auf den blauen Pfeil klicken und die Infos “ausklappen” oder Doppelklicken für eine Tabellenansicht.\nGeben Sie den Namen der Variable/des Datensatzes in der Console ein und drücken Sie EnterEnter.\nLaden Sie das {tidyverse} mit library(tidyverse) und nutzen Sie die Funktion glimpse() (in der Klammer muss der Datensatzname stehen).\n\nWelche Argumente braucht eine Funktion?\n\nGeben Sie den Funktionsnamen ein und klicken Sie in die folgenden Klammern. Drücken Sie TabTab um Vorschläge zu sehen.\nGeben Sie ?FUNKTIONSNAMEein.\nSuchen Sie im rechten unteren Quadranten von RStudio unter Help nach dem Funktionsnamen.\nGeben Sie in einer Suchmaschine den Funktionsnamen und Stichworte zu Ihrem Ziel ein.",
    "crumbs": [
      "Anhang",
      "FAQ"
    ]
  },
  {
    "objectID": "appendix/faq.html#die-funktion-summarise-ergibt-eine-fehlermeldung",
    "href": "appendix/faq.html#die-funktion-summarise-ergibt-eine-fehlermeldung",
    "title": "FAQ",
    "section": "Die Funktion summarise() ergibt eine Fehlermeldung",
    "text": "Die Funktion summarise() ergibt eine Fehlermeldung\n\nLaden Sie das {tidyverse} Package mit library(tidyverse)\nGehen Sie sicher, dass Sie summarise() und nicht summarize() verwenden.",
    "crumbs": [
      "Anhang",
      "FAQ"
    ]
  },
  {
    "objectID": "appendix/faq.html#packages",
    "href": "appendix/faq.html#packages",
    "title": "FAQ",
    "section": "Packages",
    "text": "Packages\nBeim Installieren eines Packages gibt es eine Fehlermeldung.\n\nVersuchen Sie alle 3 Arten, ein Package zu installieren.\n\nÜber die Konsole mit `install.packages(“PACKAGENAME”)\nÜber den Reiter Tools &gt; Install Packages... oben in RStudio.\nÜber das Panel Packages im rechten unteren Quadranten in RStudio. \n\n\nBeim Laden von {tidyverse} gibt es eine Fehlermeldung.\n\nSehr wahrscheinlich ist dies einfach eine Warnung (Warning) und keine Fehlermeldung (Error). Es gibt andere Packages, die dieselben Funktionsnamen verwenden, das kann zu Konflikten führen. Laden Sie trotzdem das {tidyverse}.",
    "crumbs": [
      "Anhang",
      "FAQ"
    ]
  },
  {
    "objectID": "appendix/faq.html#website",
    "href": "appendix/faq.html#website",
    "title": "FAQ",
    "section": "Website",
    "text": "Website\nDie Website lädt nicht.\n\nWahrscheinlich verwenden Sie einen relativ alten Browser. Versuchen Sie einen anderen Browser aus. Melden Sie sich sonst mit der Version Ihres Webbrowsers bei uns.\n\nDer Datensatz wird nicht heruntergeladen, sondern im Browserfenster oder im Programm numbers (Mac) geöffnet.\n\nMachen Sie einen Rechtsklick auf den Download-Link und wählen Sie save as....\nVerwenden Sie einen anderen Browser als Safari.",
    "crumbs": [
      "Anhang",
      "FAQ"
    ]
  },
  {
    "objectID": "appendix/webrconsole.html",
    "href": "appendix/webrconsole.html",
    "title": "WebR Konsole",
    "section": "",
    "text": "In der WebR-Konsole können Sie R-Code ausführen. Erstellte Variablen werden gespeichert, so lange das Browserfenster nicht geschlossen wird.\n\n Konsole Tipp Lösung\n\n\nGeben Sie hier Code ein.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPackages\nLaden Sie zuerst das {tidyverse} mit library(tidyverse).\nDatensätze\nEs stehen Ihnen folgende Datensätze zur Verfügung:\n\ncars\niris\n\nEs können weitere Datensätze durch das Laden von Packages genutzt werden:\n\npenguins aus {palmerpenguins}\n\n\n# Laden vom penguins-Datensatz aus dem {palmerpenguins} Package\nlibrary(palmerpenguins)\nd &lt;- penguins\n\n\n\n\nlibrary(tidyverse)\n\nglimpse(cars)\n\nRows: 50\nColumns: 2\n$ speed &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13…\n$ dist  &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34…\n\nplot(cars)",
    "crumbs": [
      "Anhang",
      "WebR Konsole"
    ]
  },
  {
    "objectID": "appendix/thanks.html",
    "href": "appendix/thanks.html",
    "title": "Danke",
    "section": "",
    "text": "Wir danken folgenden Personen herzlich für ihren Beitrag zu diesem Skript (alphabetische Reihenfolge).\n\nLiv Noelle Bachmann\nAnnika Naujoks\n\nund allen Studierenden HS24/FS25!",
    "crumbs": [
      "Anhang",
      "Danke"
    ]
  },
  {
    "objectID": "appendix/license.html",
    "href": "appendix/license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.",
    "crumbs": [
      "Anhang",
      "License"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.1-gesundheit-und-stress-im-job",
    "href": "uebungen/uebung-13.html#aufgabe-13.1-gesundheit-und-stress-im-job",
    "title": "Übung 13",
    "section": "Aufgabe 13.1: Gesundheit und Stress im Job",
    "text": "Aufgabe 13.1: Gesundheit und Stress im Job\nWie unterscheiden sich die Gesundheitswerte vor den Ferien zwischen Personen in high-stress-Jobs und Personen in low-stress-Jobs?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\n\nd_vacation_1 &lt;- ___\n\nc. Datenanalyse ausführen und Voraussetzungen sicherstellen\n\n# Voraussetzungen testen\n____\n\n\n# Deskriptivstatistik\nd1_summary &lt;- ___\n\nd1_summary\n\n\n# Statistischer Test\n___\n\n\n# Effektgrösse berechnen\n___\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.3-jahreszeit-und-wohlbefinden-nach-den-ferien",
    "href": "uebungen/uebung-13.html#aufgabe-13.3-jahreszeit-und-wohlbefinden-nach-den-ferien",
    "title": "Übung 13",
    "section": "Aufgabe 13.3: Jahreszeit und Wohlbefinden nach den Ferien",
    "text": "Aufgabe 13.3: Jahreszeit und Wohlbefinden nach den Ferien\nWelchen Effekt hat die Jahreszeit der Ferien auf Energielevel und Schlaf nach den Ferien?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\nWelche Datenpunkte müssen für diese Fragestellung in die Analyse einbezogen werden, und welche nicht? Erstellen Sie falls nötig einen neuen Datensatz (siehe Funktion filter()).\n\nd_vacation_3 &lt;- ___\n\nc. Datenanalyse ausführen und Voraussetzungen prüfen\n\n# Voraussetzungen prüfen\n___\n\n\n# Deskriptive Statistik\nd3_summary &lt;- ___ \nd3_summary\n\n\n# Statistischer Test\nm3_energy &lt;- ___\n\n\nm3_sleep &lt;- ___\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.3-einfluss-der-jahreszeit-der-ferien",
    "href": "uebungen/uebung-13.html#aufgabe-13.3-einfluss-der-jahreszeit-der-ferien",
    "title": "Übung 13",
    "section": "Aufgabe 13.3: Einfluss der Jahreszeit der Ferien",
    "text": "Aufgabe 13.3: Einfluss der Jahreszeit der Ferien\nWelchen Effekt hat die Jahreszeit der Ferien auf Energielevel und Schlaf nach den Ferien?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\nWelche Datenpunkte müssen für diese Fragestellung in die Analyse einbezogen werden, und welche nicht? Erstellen Sie falls nötig einen neuen Datensatz (siehe Funktion filter()).\n\nd_vacation_3 &lt;- ___\n\nc. Datenanalyse ausführen und Voraussetzungen prüfen\n\n# Voraussetzungen prüfen\n___\n\n\n# Deskriptive Statistik\nd3_summary &lt;- ___ \nd3_summary\n\n\n# Statistischer Test\nm3_energy &lt;- ___\n\n\nm3_sleep &lt;- ___\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  },
  {
    "objectID": "uebungen/uebung-13.html#aufgabe-13.3-einfluss-der-jahreszeit-auf-wohlbefinden-nach-den-ferien",
    "href": "uebungen/uebung-13.html#aufgabe-13.3-einfluss-der-jahreszeit-auf-wohlbefinden-nach-den-ferien",
    "title": "Übung 13",
    "section": "Aufgabe 13.3: Einfluss der Jahreszeit auf Wohlbefinden nach den Ferien",
    "text": "Aufgabe 13.3: Einfluss der Jahreszeit auf Wohlbefinden nach den Ferien\nWelchen Effekt hat die Jahreszeit der Ferien auf Energielevel und Schlaf nach den Ferien?\na. Datenanalyse festlegen\nb. Daten vorverarbeiten\nWelche Datenpunkte müssen für diese Fragestellung in die Analyse einbezogen werden, und welche nicht? Erstellen Sie falls nötig einen neuen Datensatz (siehe Funktion filter()).\n\nd_vacation_3 &lt;- ___\n\nc. Datenanalyse ausführen und Voraussetzungen prüfen\n\n# Voraussetzungen prüfen\n___\n\n\n# Deskriptive Statistik\nd3_summary &lt;- ___ \nd3_summary\n\n\n# Statistischer Test\nm3_energy &lt;- ___\n\n\nm3_sleep &lt;- ___\n\nd. Resultate beschreiben",
    "crumbs": [
      "Übungen",
      "Übung 13"
    ]
  }
]